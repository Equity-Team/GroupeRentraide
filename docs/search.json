[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Initiation à R dans le cadre d’une recherche épidémiologique",
    "section": "",
    "text": "1 Quelques notes\nCeci est un document en format livre qui divise par chapitres des opérations sur R pour faire des analyses statistiques de données de populations.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "0.Quelquesbases.html",
    "href": "0.Quelquesbases.html",
    "title": "2  Quelques Bases",
    "section": "",
    "text": "2.1 Installation de R\nPour utiliser R, il faut téléchargé R (le langage) et R studio (l’interface) :  - R : https://cran.r-project.org/  - R studio : https://posit.co/download/rstudio-desktop/",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Quelques Bases</span>"
    ]
  },
  {
    "objectID": "0.Quelquesbases.html#se-repérer-dans-r-studio",
    "href": "0.Quelquesbases.html#se-repérer-dans-r-studio",
    "title": "2  Quelques Bases",
    "section": "2.2 Se repérer dans R studio",
    "text": "2.2 Se repérer dans R studio\nIl y a généralement 4 fenêtres différentes que l’on peut réorganiser (options “Pane layout”)  Dans la fenêtre en haut à gauche, on rédige les scripts  La console sert à exécuter du code : soit provenant du script, soit du code taper directement dans la console  L’environnement permet de voir toutes les variables que l’on a créées / chargées et qui sont actuellement en mémoire",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Quelques Bases</span>"
    ]
  },
  {
    "objectID": "0.Quelquesbases.html#variables",
    "href": "0.Quelquesbases.html#variables",
    "title": "2  Quelques Bases",
    "section": "2.3 Variables",
    "text": "2.3 Variables\nPour créer une variable, on utilise “&lt;-”\n\nx &lt;- 10\n\nAinsi on a créé la variable x en lui assignant la valeur 10 et on peut la réutiliser par la suite\n\nx\n\n[1] 10\n\nx+2\n\n[1] 12\n\n\nOn peut également créer une variable à partir d’une autre\n\ny &lt;- x+2\ny\n\n[1] 12\n\n\nMais attention, si on modifie x par la suite, y ne sera pas modifié\n\nx &lt;-2\ny &lt;- x+2\ny\n\n[1] 4\n\nx &lt;- 3\ny\n\n[1] 4\n\n\nChaque variable est caractérisé par son type : numérique, entier, facteur, caractère  On peut connaître le type d’une variable en utilisant la fonction  class()\n\nclass(x)\n\n[1] \"numeric\"\n\n\n\ny &lt;- 3.2\nclass(y)\n\n[1] \"numeric\"\n\nz &lt;- \"2\"\nclass(z)\n\n[1] \"character\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Quelques Bases</span>"
    ]
  },
  {
    "objectID": "0.Quelquesbases.html#vecteurs",
    "href": "0.Quelquesbases.html#vecteurs",
    "title": "2  Quelques Bases",
    "section": "2.4 Vecteurs",
    "text": "2.4 Vecteurs\nLes vecteurs sont “une liste” d’éléments de même type. Il sont définis via la fonction  c() \n\nvec &lt;- c(1,2,3,4,5)\nclass(vec)\n\n[1] \"numeric\"\n\nvec\n\n[1] 1 2 3 4 5\n\n\n Attention  Si l’on mélange des éléments numériques et caractères, R les transforment tous en caractères\n\nvec &lt;- c(\"1\", 2, \"3\", 4)\nclass(vec)\n\n[1] \"character\"\n\nvec\n\n[1] \"1\" \"2\" \"3\" \"4\"\n\n\nOn peut aussi définir un vecteur à partir de variables\n\nx &lt;- 2\ny &lt;- x+8\nvec &lt;- c(x,y)\nvec\n\n[1]  2 10",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Quelques Bases</span>"
    ]
  },
  {
    "objectID": "0.Quelquesbases.html#dataframes",
    "href": "0.Quelquesbases.html#dataframes",
    "title": "2  Quelques Bases",
    "section": "2.5 Dataframes",
    "text": "2.5 Dataframes\nLes bases de données sont stockées sous forme de dataframe (ou tibble mais pour le moment on ne va utiliser que les dataframe)\n\ndf &lt;- data.frame(\"Identifiant\" = c(\"1\", \"2\", \"3\", \"4\", \"5\"), \n                 \"Age\" = c(38, 19, 45, 78, 31))\ndf\n\n  Identifiant Age\n1           1  38\n2           2  19\n3           3  45\n4           4  78\n5           5  31\n\n\nIl peut parfois être utile de créer un dataframe vide (qui ne contient que les noms de variables mais pas de données).  Pour cela il faut pour chaque colonne préciser son type\n\ndf &lt;- data.frame(\"Identifiant\" = character(), \n                 \"Age\" = numeric())\ndf\n\n[1] Identifiant Age        \n&lt;0 rows&gt; (or 0-length row.names)\n\n\nOn peut ensuite ajouter des observations en utilisant la fonction  rbind() mais pour cela il faut que les données soient au format database\n\ndf &lt;- rbind(df, data.frame(\"Identifiant\"=\"1\", \"Age\"=38))\ndf\n\n  Identifiant Age\n1           1  38",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Quelques Bases</span>"
    ]
  },
  {
    "objectID": "0.Quelquesbases.html#ouvrir-des-fichiers-de-données",
    "href": "0.Quelquesbases.html#ouvrir-des-fichiers-de-données",
    "title": "2  Quelques Bases",
    "section": "2.6 Ouvrir des fichiers de données",
    "text": "2.6 Ouvrir des fichiers de données\nOn peut ouvrir des fichiers de données de quasiment tous types en R : csv, excel, SAS, Stata, etc …  Mais la fonction à utiliser dépend de l’extension du fichier :  - CSV : read.csv() ou read.table()  - Excel : library(readxl) read_xlsx()  - SAS : library(haven) read_sas()  - Stata : library(haven) read_dta()   R Studio propose aussi un moyen interactif d’ouvrir les fichiers de données. Pour cela, il suffit de cliquer sur ‘Import dataset’ dans la partie Environnement, de selectionner le format, puis choisir le fichier que l’on souhaite importer. Cette méthode permet de visualiser le fichier et génère le code R permettant de l’ouvrir.   On peut aussi charger un dataframe enregistrer au format R. Deux formats peuvent être utilisés :  - .Rdata : chargé avec la fonction load()  - .rds : chargé avec la fonction readRDS()  Ces fichier peuvent également être importés en les ouvrant directement depuis l’explorateur de fichiers.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Quelques Bases</span>"
    ]
  },
  {
    "objectID": "0.Quelquesbases.html#premières-visualisation-de-tableaux-de-données",
    "href": "0.Quelquesbases.html#premières-visualisation-de-tableaux-de-données",
    "title": "2  Quelques Bases",
    "section": "2.7 Premières visualisation de tableaux de données",
    "text": "2.7 Premières visualisation de tableaux de données\nPour s’entrainer, il y a de nombreux dataframes exemples dans R que l’on peut charger avec la fonction data()\n\ndata(\"iris\")\n\nPour afficher le tableau de données en entier, on peut cliqué directement sur le nom dans l’environnement.   Pour afficher les premières lignes seulement, afin de voir à quoi ressemble les données, on peut utiliser la fonction head()\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\nhead(iris, n=10)\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1           5.1         3.5          1.4         0.2  setosa\n2           4.9         3.0          1.4         0.2  setosa\n3           4.7         3.2          1.3         0.2  setosa\n4           4.6         3.1          1.5         0.2  setosa\n5           5.0         3.6          1.4         0.2  setosa\n6           5.4         3.9          1.7         0.4  setosa\n7           4.6         3.4          1.4         0.3  setosa\n8           5.0         3.4          1.5         0.2  setosa\n9           4.4         2.9          1.4         0.2  setosa\n10          4.9         3.1          1.5         0.1  setosa\n\n\nPour avoir un résumé du dataframe avec nombre de variables, d’observations, type des variables et premières valeurs prises par chacune, on utilise la fonction str()\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\nPour avoir des statistiques descriptives sur toutes les variables du dataframe, on utilise la fonction summary()\n\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\nOn peut aussi utiliser la fonction skim() du package skimr\n\nlibrary(skimr)\nskim(iris)\n\n\nData summary\n\n\nName\niris\n\n\nNumber of rows\n150\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nSpecies\n0\n1\nFALSE\n3\nset: 50, ver: 50, vir: 50\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nSepal.Length\n0\n1\n5.84\n0.83\n4.3\n5.1\n5.80\n6.4\n7.9\n▆▇▇▅▂\n\n\nSepal.Width\n0\n1\n3.06\n0.44\n2.0\n2.8\n3.00\n3.3\n4.4\n▁▆▇▂▁\n\n\nPetal.Length\n0\n1\n3.76\n1.77\n1.0\n1.6\n4.35\n5.1\n6.9\n▇▁▆▇▂\n\n\nPetal.Width\n0\n1\n1.20\n0.76\n0.1\n0.3\n1.30\n1.8\n2.5\n▇▁▇▅▃\n\n\n\n\n\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Quelques Bases</span>"
    ]
  },
  {
    "objectID": "0.Quelquesbases.html#packages",
    "href": "0.Quelquesbases.html#packages",
    "title": "2  Quelques Bases",
    "section": "2.8 Packages",
    "text": "2.8 Packages\nDans l’exemple ci-dessus, nous avons fait appel à un package. Les packages sont très utiles en R. En effet, le R base qui est le langage R qui est chargé lorsque l’on ouvre R, ne permet pas de réaliser toutes les analyses.  Les packages constituent un ensemble de fonctions ayant en commun de permettre de réaliser un certain type d’analyse. Il peut également s’agir de fonction permettant une meilleure visualisation que celle obtenue avec les fonctions de R base.   R étant un langage open source, tout le monde peut créer des packages et les mettre à disposition des utilisateurs. Ains, il existe de très nombreux packages, dont plusieurs réalisent en fait les mêmes analyses.  Certains packages sont stockés sur le CRAN, ce sont en général les packages les plus stables, qui ont fait l’objet de plus de vérifications. D’autres sont stockés sur github.  Dans tous les cas, avant de pouvoir utiliser un package, il est nécéssaire de l’installer avec la fonction install.packages()\n\ninstall.packages(\"skimr\")\n\nWarning: package 'skimr' is in use and will not be installed\n\n\nCette opération est uniquement nécéssaire la première fois que l’on veut utiliser ce package sur un pc.  Ensuite, à chaque fois que l’on veut utiliser des fonctions de ce package dans un fichier, on le charge avec la fonction library()\n\nlibrary(skimr)\n\nUne fois le package chargé, on peut utilisé directement toutes les fonctions qu’il contient.  Tant que l’on ne ferme pas la session R studio, le package reste chargé.   Si on ne veut utilisé qu’une fois ou ponctuellement une fonction spécifique, il n’est pas nécéssaire de chargé tout le package. Dans ce cas, il faut préciser le nom du package avant la fonction\n\nskimr::skim(iris)\n\n\nData summary\n\n\nName\niris\n\n\nNumber of rows\n150\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nSpecies\n0\n1\nFALSE\n3\nset: 50, ver: 50, vir: 50\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nSepal.Length\n0\n1\n5.84\n0.83\n4.3\n5.1\n5.80\n6.4\n7.9\n▆▇▇▅▂\n\n\nSepal.Width\n0\n1\n3.06\n0.44\n2.0\n2.8\n3.00\n3.3\n4.4\n▁▆▇▂▁\n\n\nPetal.Length\n0\n1\n3.76\n1.77\n1.0\n1.6\n4.35\n5.1\n6.9\n▇▁▆▇▂\n\n\nPetal.Width\n0\n1\n1.20\n0.76\n0.1\n0.3\n1.30\n1.8\n2.5\n▇▁▇▅▃",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Quelques Bases</span>"
    ]
  },
  {
    "objectID": "0.Quelquesbases.html#ressources",
    "href": "0.Quelquesbases.html#ressources",
    "title": "2  Quelques Bases",
    "section": "2.9 Ressources",
    "text": "2.9 Ressources\nVoici une liste de ressources utiles pour commencer à utiliser R :   - FUN MOOC de Bruno Falissard et Christophe Lalanne : Introduction à la statistique avec R (nécéssite du temps car il faut regarder les vidéos)  - The Epidemiologist R Handbook. 2021. Batra, Neale, et al  Ces deux ressources ont la spécificité d’être conçues pour les épidémiologistes   Autres ressources plus générales :  - R for data science 2nd edition de Hadley Wickham, Mine Çetinkaya-Rundel et Garrett Grolemund (très complet)  - Statistics Globe : Learn R Programming (Tutorial & Examples) | Free Introduction par Joachim Schork  - Les sites OpenClassrooms, Coursera et Datacamp proposent également de nombreux cours de différents niveaux   Il y a bien sûr beaucoup d’autres ressources, nous avons cité ici celles qui nous ont été utiles quand nous avons appris R.   De plus, R étant un langage très utilisé, de nombreux forums permettent en général de trouver les réponses aux questions que l’on se pose. Le principal étant https://stackoverflow.com/",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Quelques Bases</span>"
    ]
  },
  {
    "objectID": "1.ManipulationTableaux.html",
    "href": "1.ManipulationTableaux.html",
    "title": "3  Manipulation Tableaux",
    "section": "",
    "text": "3.1 Opérateurs utiles\nCette deuxième séance est consacrée à la manipulation des bases de données ouvertes dans le format dataframe.  Pour cette séance, nous allons utiliser la base LE_65, qui contient les données Eurostat sur l’espérance de vie à 65 ans en Europe par sexe et années de 2013 à 2021. Vous pouvez la télécharger via le drive. Pour la suite, cette base de données sera stockée dans la variable df\nAvant de commencer, on charge les packages dont on aura besoin\nAvant toute chose, nous rappelons quelques opérateurs qui nous seront souvent utiles pour manipuler des données\n2==3\n\n[1] FALSE\n2&gt;3\n\n[1] FALSE\n\\(\\bullet\\) Comparateur de supériorité &gt;= : pour tester si une valeur est supérieure ou égale à une autre\n2&gt;=3\n\n[1] FALSE\n\\(\\bullet\\) Comparateur d’infériorité stricte &lt; : pour tester si une valeur est strictement inférieure à une autre\n2&lt;3\n\n[1] TRUE\n\\(\\bullet\\) Comparateur d’infériorité &lt;= : pour tester si une valeur est inférieure ou égale à une autre\n2&lt;=3\n\n[1] TRUE\n\\(\\bullet\\) Comparateur d’inégalité != : pour tester si deux valeurs sont différentes\n2!=3\n\n[1] TRUE\nD’une manière générale, la négation dans R se fait avec !\n\\(\\bullet\\) Indicateur de présence dans un vecteur %in% : pour tester si une valeur se trouve dans un vecteur\n2 %in% c(1,2,3,4)\n\n[1] TRUE\nPour tester qu’une valeur ne se trouve pas dans le vecteur, on rajoute la négation\n!(2 %in% c(1,2,3,4))\n\n[1] FALSE\n\\(\\bullet\\) Tester si une donnée est une valeur manquante (NA en R) is.na()\nis.na(2)\n\n[1] FALSE\nDe même pour vérifier qu’une donnée n’est pas manquante on ajoute la négation\n!is.na(NA)\n\n[1] FALSE\nOn peut aussi appliquer cette fonction à un vecteur, elle dira alors pour chaque entrée du vecteur si la donnée est manquante ou non\nis.na(c(14, 5, NA, 6, NA))\n\n[1] FALSE FALSE  TRUE FALSE  TRUE",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Manipulation Tableaux</span>"
    ]
  },
  {
    "objectID": "1.ManipulationTableaux.html#opérateurs-utiles",
    "href": "1.ManipulationTableaux.html#opérateurs-utiles",
    "title": "3  Manipulation Tableaux",
    "section": "",
    "text": "Comparateur d’égalité == : pour tester si deux valeurs sont égales\n\n\n\nComparateur de supériorité stricte &gt; : pour tester si une valeur est strictement supérieure à une autre\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.1.1 Opérations sur les vecteurs\n\\(\\bullet\\) Pour définir un vecteur par section on utilise “:”\n\nc(1:5)\n\n[1] 1 2 3 4 5\n\n\n\\(\\bullet\\) Pour définir un vecteur par section avec un pas spécifié on utilise la fonction seq()\n\nseq(from = 1, to = 100, by = 3)\n\n [1]   1   4   7  10  13  16  19  22  25  28  31  34  37  40  43  46  49  52  55\n[20]  58  61  64  67  70  73  76  79  82  85  88  91  94  97 100\n\n\n\\(\\bullet\\) Pour définir un vecteur par une répétitions de séquence on utilise rep() avec les options each ou times\n\nrep(c(1,3,5,7), each = 3)\n\n [1] 1 1 1 3 3 3 5 5 5 7 7 7\n\n\n\nrep(c(1,3,5,7), times = 3)\n\n [1] 1 3 5 7 1 3 5 7 1 3 5 7\n\n\n\\(\\bullet\\) Pour connaître la taille d’un vecteur, on utilise la fonction length()\n\nlength(c(1,3,5,7))\n\n[1] 4\n\n\n\\(\\bullet\\) Pour connaître la somme de tous les éléments d’un vecteur, on utilise la fonction sum()\n\nsum(c(1,5,2,3))\n\n[1] 11\n\n\n\\(\\bullet\\) Pour connaître la moyenne de tous les éléments d’un vecteur, on utilise la fonction mean()\n\nmean(c(1,2,3,4))\n\n[1] 2.5\n\n\n\\(\\bullet\\) Pour connaître la valeur maximale de tous les éléments d’un vecteur, on utilise la fonction max()\n\nmax(c(1,2,3,4))\n\n[1] 4\n\n\n\\(\\bullet\\) Pour connaître la valeur minimale de tous les éléments d’un vecteur, on utilise la fonction min()\n\nmin(c(1,2,3,4))\n\n[1] 1\n\n\n\\(\\bullet\\) Pour connaître le nombre de données manquantes d’un vecteur, on applique la fonction sum() à l’indicatrice des données manquantes\n\nsum(is.na(c(51,NA,1,2,NA)))\n\n[1] 2\n\n\nRemarque : de façon générale, la fonction sum() appliquée à un vecteur de booléens renvoie le nombre de valeurs TRUE\n\nsum(c(T,F,F,F))\n\n[1] 1",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Manipulation Tableaux</span>"
    ]
  },
  {
    "objectID": "1.ManipulationTableaux.html#informations-générales-de-la-base",
    "href": "1.ManipulationTableaux.html#informations-générales-de-la-base",
    "title": "3  Manipulation Tableaux",
    "section": "3.2 Informations générales de la base",
    "text": "3.2 Informations générales de la base\nPour connaître le noms des colonnes du tableau, on utilise la fonction colnames()\n\ncolnames(df)\n\n [1] \"DATAFLOW\"    \"LAST.UPDATE\" \"freq\"        \"unit\"        \"age\"        \n [6] \"sex\"         \"geo\"         \"TIME_PERIOD\" \"OBS_VALUE\"   \"OBS_FLAG\"   \n\n\nPour afficher les premières lignes du tableau, on utilise la fonction head()\n\nhead(df)\n\n             DATAFLOW       LAST.UPDATE freq unit age sex geo TIME_PERIOD\n1 ESTAT:TPS00026(1.0) 16/03/23 11:00:00    A   YR Y65   F  AL        2013\n2 ESTAT:TPS00026(1.0) 16/03/23 11:00:00    A   YR Y65   F  AL        2014\n3 ESTAT:TPS00026(1.0) 16/03/23 11:00:00    A   YR Y65   F  AL        2015\n4 ESTAT:TPS00026(1.0) 16/03/23 11:00:00    A   YR Y65   F  AL        2016\n5 ESTAT:TPS00026(1.0) 16/03/23 11:00:00    A   YR Y65   F  AL        2017\n6 ESTAT:TPS00026(1.0) 16/03/23 11:00:00    A   YR Y65   F  AL        2018\n  OBS_VALUE OBS_FLAG\n1      18.4         \n2      18.5         \n3      17.8         \n4      18.3         \n5      18.0         \n6      18.5         \n\n\nPour connaître le nombre d’observations présentes dans le tableau, on peut simplement regarder dans l’onglet environnement. Cependant, il peut parfois être utile d’avoir accès à ce nombre, pour cela on utilise nrow()\n\nnrow(df)\n\n[1] 1578\n\n\nDe même, pour le nombre de colonne, on utilise ncol()\n\nncol(df)\n\n[1] 10\n\n\nRemarque : on pourrait également obtenir ce nombre en regardant la taille du vecteur des noms de colonnes\n\nlength(colnames(df))\n\n[1] 10",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Manipulation Tableaux</span>"
    ]
  },
  {
    "objectID": "1.ManipulationTableaux.html#accès-aux-données-du-tableaux",
    "href": "1.ManipulationTableaux.html#accès-aux-données-du-tableaux",
    "title": "3  Manipulation Tableaux",
    "section": "3.3 Accès aux données du tableaux",
    "text": "3.3 Accès aux données du tableaux\n\n3.3.1 En utilisant les indices\nIl est possible d’afficher une ligne spécifique en utilisant son indice. Par exemple regardons la première ligne\n\ndf[1,]\n\n             DATAFLOW       LAST.UPDATE freq unit age sex geo TIME_PERIOD\n1 ESTAT:TPS00026(1.0) 16/03/23 11:00:00    A   YR Y65   F  AL        2013\n  OBS_VALUE OBS_FLAG\n1      18.4         \n\n\n En fait, pour afficher un élément du tableaux, on utilise les crochets [. , .], le premier élément dans le crochet correspond à la ligne, et le deuxième à la colonne.  \nSi je veux afficher la valeur de la neuvième colonne de la première observation, je fais\n\ndf[1,9]\n\n[1] 18.4\n\n\nSi je souhaite afficher toutes les colonnes, il suffit de ne rien mettre après la virgule\n\ndf[1,]\n\n             DATAFLOW       LAST.UPDATE freq unit age sex geo TIME_PERIOD\n1 ESTAT:TPS00026(1.0) 16/03/23 11:00:00    A   YR Y65   F  AL        2013\n  OBS_VALUE OBS_FLAG\n1      18.4         \n\n\nDe même si je veux toutes les lignes d’une colonne spécifiques, je ne mets rien avant la virgule\n\nhead(df[,9])\n\n[1] 18.4 18.5 17.8 18.3 18.0 18.5\n\n\nJe peux également accéder à une section de lignes ou de colonnes :\n\ndf[1:5, 9]\n\n[1] 18.4 18.5 17.8 18.3 18.0\n\n\nPermet d’afficher les observation 1 à 5 de la neuvième colonne\n\ndf[1, 7:9]\n\n  geo TIME_PERIOD OBS_VALUE\n1  AL        2013      18.4\n\n\nPermet d’afficher les valeurs des colonnes 7, 8 et 9 de la première ligne  Pour connaître les indices des colonnes qui nous intéresse, on peut utiliser colnames()\n\ncolnames(df)\n\n [1] \"DATAFLOW\"    \"LAST.UPDATE\" \"freq\"        \"unit\"        \"age\"        \n [6] \"sex\"         \"geo\"         \"TIME_PERIOD\" \"OBS_VALUE\"   \"OBS_FLAG\"   \n\n\nAinsi je sais que “OBS_VALUE” correspond à la neuvième colonne\n\n\n3.3.2 En utilisant le nom de la colonne\nIl est souvent plus pratique d’utiliser le nom de la colonne.\nPour accéder à une colonne spécifique via son nom, on utilise $ entre le nom de la base et le nom de la colonne\n\nhead(df$OBS_VALUE)\n\n[1] 18.4 18.5 17.8 18.3 18.0 18.5\n\n\nAinsi, on peut aussi accéder à une valeur d’une colonne de la façon suivante :\n\ndf$OBS_VALUE[1]\n\n[1] 18.4\n\n\nRemarque : cela revient à faire\n\ndf[1, 9]\n\n[1] 18.4\n\n\nvu précédemment.  \nOn peut accéder à plusieurs valeurs d’une colonne en utilisant la notation de section :\n\ndf$OBS_VALUE[1:5]\n\n[1] 18.4 18.5 17.8 18.3 18.0\n\n\nou en spécifiant des numéros précis, par exemple les observations 1, 3, 5 et 10\n\ndf$OBS_VALUE[c(1,3, 5, 10)]\n\n[1] 18.4 17.8 18.0 17.2\n\n\nIl est également possible de préciser entre guillemets le noms de colonnes à extraire\n\ndf[1:5, \"OBS_VALUE\"]\n\n[1] 18.4 18.5 17.8 18.3 18.0\n\n\nPour en sélectionner plusieurs, on rentre les noms dans un vecteur\n\ndf[1:5 ,c(\"geo\", \"TIME_PERIOD\", \"OBS_VALUE\")]\n\n  geo TIME_PERIOD OBS_VALUE\n1  AL        2013      18.4\n2  AL        2014      18.5\n3  AL        2015      17.8\n4  AL        2016      18.3\n5  AL        2017      18.0\n\n\n\nSélectionner plusieurs colonnes dans un nouveau tableau\n\nR de base\nPour créer un sous-tableaux en sélectionnant des colonnes spécifiques  je peux soit regarder leurs indices et les utiliser pour spécifier les colonnes que je souhaite\n\ndf_1_base &lt;- df[,6:9]\nhead(df_1_base)\n\n  sex geo TIME_PERIOD OBS_VALUE\n1   F  AL        2013      18.4\n2   F  AL        2014      18.5\n3   F  AL        2015      17.8\n4   F  AL        2016      18.3\n5   F  AL        2017      18.0\n6   F  AL        2018      18.5\n\n\nMais je peux aussi le faire en utilisant directement le nom des colonnes dans un vecteur\n\ndf_1_base2 &lt;- df[,c(\"sex\",\"geo\", \"TIME_PERIOD\", \"OBS_VALUE\")]\nhead(df_1_base2)\n\n  sex geo TIME_PERIOD OBS_VALUE\n1   F  AL        2013      18.4\n2   F  AL        2014      18.5\n3   F  AL        2015      17.8\n4   F  AL        2016      18.3\n5   F  AL        2017      18.0\n6   F  AL        2018      18.5\n\n\nUne autre façon de faire, est d’utiliser la fonction subset()\n\ndf_1_base3 &lt;- subset(df, select = c(\"sex\",\"geo\", \"TIME_PERIOD\", \"OBS_VALUE\"))\nhead(df_1_base3)\n\n  sex geo TIME_PERIOD OBS_VALUE\n1   F  AL        2013      18.4\n2   F  AL        2014      18.5\n3   F  AL        2015      17.8\n4   F  AL        2016      18.3\n5   F  AL        2017      18.0\n6   F  AL        2018      18.5\n\n\nAvec cette fonction il n’est pas nécéssaire de mettre les noms de variables entre guillements\n\ndf_1_base3 &lt;- subset(df, select = c(sex,geo, TIME_PERIOD, OBS_VALUE))\nhead(df_1_base3)\n\n  sex geo TIME_PERIOD OBS_VALUE\n1   F  AL        2013      18.4\n2   F  AL        2014      18.5\n3   F  AL        2015      17.8\n4   F  AL        2016      18.3\n5   F  AL        2017      18.0\n6   F  AL        2018      18.5\n\n\nEt on peut aussi utiliser les indices\n\ndf_1_base3 &lt;- subset(df, select = c(6:9))\nhead(df_1_base3)\n\n  sex geo TIME_PERIOD OBS_VALUE\n1   F  AL        2013      18.4\n2   F  AL        2014      18.5\n3   F  AL        2015      17.8\n4   F  AL        2016      18.3\n5   F  AL        2017      18.0\n6   F  AL        2018      18.5\n\n\n\n\nTidyverse\nEn tidyverse, on utilise la fonction select() du package dplyr\n\ndf_1_tidy &lt;- df %&gt;% \n  select(sex, geo, TIME_PERIOD, OBS_VALUE)\nhead(df_1_tidy)\n\n  sex geo TIME_PERIOD OBS_VALUE\n1   F  AL        2013      18.4\n2   F  AL        2014      18.5\n3   F  AL        2015      17.8\n4   F  AL        2016      18.3\n5   F  AL        2017      18.0\n6   F  AL        2018      18.5\n\n\n\n\n\nSélectionner plusieurs lignes dans un nouveau tableau\nIl arrive souvent que l’on veuille sélectionner des lignes spécifiques pour ne travailler que sur celles-ci. Nous pouvons appliquer une fonction pour filtrer ces lignes.   Par exemple, dans le tableau df on ne garde que les observations hommes/femmes confondus, i.e celles dont la valeur de “sex” est “T”\n\nR base\nPour sélectionner un ensemble de lignes en fonction d’une condition en R base, on fait une sélection en specifiant la conditions à la place des numéros de lignes\n\ndf_2_base &lt;- df[df$sex==\"T\",]\n\n\n\nTidyverse\nPour selectionner des lignes spécifiques en tidyverse, on utilise la fonction filter() du package dplyr\n\ndf_2_tidy &lt;- df %&gt;% \n  filter(sex==\"T\")\nhead(df_2_tidy)\n\n             DATAFLOW       LAST.UPDATE freq unit age sex geo TIME_PERIOD\n1 ESTAT:TPS00026(1.0) 16/03/23 11:00:00    A   YR Y65   T  AL        2013\n2 ESTAT:TPS00026(1.0) 16/03/23 11:00:00    A   YR Y65   T  AL        2014\n3 ESTAT:TPS00026(1.0) 16/03/23 11:00:00    A   YR Y65   T  AL        2015\n4 ESTAT:TPS00026(1.0) 16/03/23 11:00:00    A   YR Y65   T  AL        2016\n5 ESTAT:TPS00026(1.0) 16/03/23 11:00:00    A   YR Y65   T  AL        2017\n6 ESTAT:TPS00026(1.0) 16/03/23 11:00:00    A   YR Y65   T  AL        2018\n  OBS_VALUE OBS_FLAG\n1      17.5         \n2      17.6         \n3      17.1         \n4      17.6         \n5      17.5         \n6      17.8         \n\n\nRemarque : On peut combiner les fonctions select() et filter(), mais attention, l’ordre est important puisque dès qu’une manipulation est faite, elle est conservée dans la suite :\n\ndf_3_tidy &lt;- df %&gt;% \n  filter(sex==\"T\") %&gt;% \n  select(geo, TIME_PERIOD, OBS_VALUE)\n\nSelectionne les colonnes geo, TIME_PERIOD et OBS_VALUE et ne conserve que les données pour la population totale   En revanche\n\n#df_3_tidy &lt;- df %&gt;% \n#  select(geo, TIME_PERIOD, OBS_VALUE) %&gt;% \n#  filter(sex==\"T\")\n\nRetourne une erreur car on tente de filtrer des observations en fonction d’une variable (sex) qui n’est plus disponible dans notre table",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Manipulation Tableaux</span>"
    ]
  },
  {
    "objectID": "1.ManipulationTableaux.html#supprimer-une-colonne",
    "href": "1.ManipulationTableaux.html#supprimer-une-colonne",
    "title": "3  Manipulation Tableaux",
    "section": "3.4 Supprimer une colonne",
    "text": "3.4 Supprimer une colonne\n\n3.4.1 R base\nIl y a plusieurs façons de supprimer une colonne en R base  Dans tous les cas, cela marche comme pour une sélection de colonnes, mais au lieu de préciser les colonnes à garder, on spécifie les colonnes à supprimer  1) Avec les indices de la colonne\n\nhead(df_1_base)\n\n  sex geo TIME_PERIOD OBS_VALUE\n1   F  AL        2013      18.4\n2   F  AL        2014      18.5\n3   F  AL        2015      17.8\n4   F  AL        2016      18.3\n5   F  AL        2017      18.0\n6   F  AL        2018      18.5\n\ndf_1_remove &lt;- df_1_base[-c(5)] # Rq : cela marche aussi en mettant la virgule avant -c(5) df1_base[,-c(5)]\nhead(df_1_remove)\n\n  sex geo TIME_PERIOD OBS_VALUE\n1   F  AL        2013      18.4\n2   F  AL        2014      18.5\n3   F  AL        2015      17.8\n4   F  AL        2016      18.3\n5   F  AL        2017      18.0\n6   F  AL        2018      18.5\n\n\nPour supprimer plusieurs colonnes, on peut spécifier plusieurs indices\n\ndf_1_remove &lt;- df_1_base[-c(1,5)]\nhead(df_1_remove)\n\n  geo TIME_PERIOD OBS_VALUE\n1  AL        2013      18.4\n2  AL        2014      18.5\n3  AL        2015      17.8\n4  AL        2016      18.3\n5  AL        2017      18.0\n6  AL        2018      18.5\n\n\n\nAvec le nom de la colonne Pour supprimer une colonne via son nom, on peut faire une sélection de colonnes en indiquant qu’on veut sélectionner les colonnes dont le nom n’est pas dans un vecteur contenant le nom de la ou des colonnes à supprimer\n\n\ndf_1_remove &lt;- df_1_base[, !(names(df_1_base) %in% c(\"geo\", \"sex\"))]\nhead(df_1_remove)\n\n  TIME_PERIOD OBS_VALUE\n1        2013      18.4\n2        2014      18.5\n3        2015      17.8\n4        2016      18.3\n5        2017      18.0\n6        2018      18.5\n\n\nAttention : on ne peut pas supprimer une colonne en remplaçant l’indice par le nom, comme on peut le faire pour la sélection\n\n#df_1_base[-c(\"geo\")]\n\nrenvoie une erreur   On peut également supprimer une ou plusieurs lignes avec la fonction subset()\n\ndf_1_remove &lt;- subset(df_1_base, select = -c(geo, sex))\nhead(df_1_remove)\n\n  TIME_PERIOD OBS_VALUE\n1        2013      18.4\n2        2014      18.5\n3        2015      17.8\n4        2016      18.3\n5        2017      18.0\n6        2018      18.5\n\n\n\n\n3.4.2 Tidyverse\nPour supprimer une ou plusieurs colonnes en tidyverse, on utilise la même fonction que pour faire une sélection de colonnes select(). Cette fois, on spécifie les colonnes à supprimer en mettant “-” avant le vecteur contenant le nom des colonnes\n\nhead(df_1_tidy)\n\n  sex geo TIME_PERIOD OBS_VALUE\n1   F  AL        2013      18.4\n2   F  AL        2014      18.5\n3   F  AL        2015      17.8\n4   F  AL        2016      18.3\n5   F  AL        2017      18.0\n6   F  AL        2018      18.5\n\ndf_1_remove &lt;- df_1_tidy %&gt;% \n  select(-c(geo, sex))\nhead(df_1_remove)\n\n  TIME_PERIOD OBS_VALUE\n1        2013      18.4\n2        2014      18.5\n3        2015      17.8\n4        2016      18.3\n5        2017      18.0\n6        2018      18.5",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Manipulation Tableaux</span>"
    ]
  },
  {
    "objectID": "1.ManipulationTableaux.html#modifications-dans-un-tableau",
    "href": "1.ManipulationTableaux.html#modifications-dans-un-tableau",
    "title": "3  Manipulation Tableaux",
    "section": "3.5 Modifications dans un tableau",
    "text": "3.5 Modifications dans un tableau\n\n3.5.1 Modifier une valeur d’un tableau\nPour modifier une valeur précise, je peux le faire\n\ndf_1_base[1, \"geo\"]\n\n[1] \"AL\"\n\ndf_1_base[1, \"geo\"] &lt;- \"ALBANIA\"\ndf_1_base[1, \"geo\"]\n\n[1] \"ALBANIA\"\n\n\n\n\n3.5.2 Modifier une colonne entière\nJe peux souhaiter modifier toutes les valeurs d’une colonne, pour cela j’applique une fonction à cette colonne\n\nR base\nNous allons par exemple utiliser la fonction tolower pour mettre en minuscules les valeurs de geo\n\ndf_1_base$geo &lt;- tolower(df_1_base$geo)\nhead(df_1_base)\n\n  sex     geo TIME_PERIOD OBS_VALUE\n1   F albania        2013      18.4\n2   F      al        2014      18.5\n3   F      al        2015      17.8\n4   F      al        2016      18.3\n5   F      al        2017      18.0\n6   F      al        2018      18.5\n\n\n\n\nTidyverse\nPour appliquer une modification en tidyverse, on utilise la fonction mutate()\n\ndf_1_tidy &lt;- df_1_tidy %&gt;% \n  mutate(geo = tolower(geo))\n\nhead(df_1_tidy)\n\n  sex geo TIME_PERIOD OBS_VALUE\n1   F  al        2013      18.4\n2   F  al        2014      18.5\n3   F  al        2015      17.8\n4   F  al        2016      18.3\n5   F  al        2017      18.0\n6   F  al        2018      18.5\n\n\nL’avantage de mutate est que l’on peut modifier directement plusieurs colonnes\n\ndf_1_tidy &lt;- df_1_tidy %&gt;% \n  mutate(geo = toupper(geo),\n         sex = case_when(sex ==\"F\" ~ \"Female\",\n                         sex == \"M\" ~ \"Male\", \n                         sex == \"T\" ~ \"Total\"))\n\nhead(df_1_tidy)\n\n     sex geo TIME_PERIOD OBS_VALUE\n1 Female  AL        2013      18.4\n2 Female  AL        2014      18.5\n3 Female  AL        2015      17.8\n4 Female  AL        2016      18.3\n5 Female  AL        2017      18.0\n6 Female  AL        2018      18.5\n\n\n\n\n\n3.5.3 Convertir une colonne\nPour changer le type d’un vecteur on utilise les fonctions :  - as.numeric() pour convertir au format numérique  - as.character() pour convertir au format caractères  - as.factor() pour convertir en facteur \nUne colonne d’un tableau étant un vecteur, il suffit d’appliquer ces fonctions à la colonne que l’on souhaite transformer   En R de base  On modifie la colonne OBS_VALUE pour la passer en caractères puis on la repasse en numérique\n\nclass(df_1_base$OBS_VALUE)\n\n[1] \"numeric\"\n\ndf_1_base$OBS_VALUE &lt;- as.character(df_1_base$OBS_VALUE)\nclass(df_1_base$OBS_VALUE)\n\n[1] \"character\"\n\ndf_1_base$OBS_VALUE &lt;- as.numeric(df_1_base$OBS_VALUE)\n\nOn transforme la variable sex en facteur\n\nclass(df_1_base$sex)\n\n[1] \"character\"\n\ndf_1_base$sex &lt;- as.factor(df_1_base$sex)\nclass(df_1_base$sex)\n\n[1] \"factor\"\n\n\nEn tidyverse  On va modifier en une seule fois les variables OBS_VALUE en numérique et sex en facteur, puis on repasse la variable OBS_VALUE en numérique\n\nclass(df_1_tidy$OBS_VALUE)\n\n[1] \"numeric\"\n\nclass(df_1_tidy$sex)\n\n[1] \"character\"\n\ndf_1_tidy &lt;- df_1_tidy %&gt;% \n  mutate(OBS_VALUE = as.character(OBS_VALUE),\n         sex = as.factor(sex))\nclass(df_1_tidy$OBS_VALUE)\n\n[1] \"character\"\n\nclass(df_1_tidy$sex)\n\n[1] \"factor\"\n\ndf_1_tidy &lt;- mutate(df_1_tidy, OBS_VALUE=as.numeric(OBS_VALUE))",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Manipulation Tableaux</span>"
    ]
  },
  {
    "objectID": "1.ManipulationTableaux.html#créer-une-nouvelle-colonne",
    "href": "1.ManipulationTableaux.html#créer-une-nouvelle-colonne",
    "title": "3  Manipulation Tableaux",
    "section": "3.6 Créer une nouvelle colonne",
    "text": "3.6 Créer une nouvelle colonne\nOn peut créer des nouvelles colonnes en spécifiant les valeurs pour chaque observation dans un vecteur. Attention, il faut que la taille du vecteur soit égale au nombre de ligne du tableau. On peut aussi créer une nouvelle colonne en appliquant une fonction ou des opérations à une ou plusieurs autres variables.\n\n3.6.1 R base\nPour créer une colonne en R base, il suffit de la définir en lui assignant la valeur qu’elle doit prendre. Pour cela, on créer le vecteur Nom_de_la_base$Nom_nouvelle_colonne\n\ndf_1_base$Id &lt;- 1:nrow(df_1_base)\nsummary(df_1_base)\n\n sex         geo             TIME_PERIOD     OBS_VALUE           Id        \n F:526   Length:1578        Min.   :2010   Min.   :11.60   Min.   :   1.0  \n M:526   Class :character   1st Qu.:2012   1st Qu.:17.00   1st Qu.: 395.2  \n T:526   Mode  :character   Median :2015   Median :18.90   Median : 789.5  \n                            Mean   :2015   Mean   :18.64   Mean   : 789.5  \n                            3rd Qu.:2018   3rd Qu.:20.60   3rd Qu.:1183.8  \n                            Max.   :2021   Max.   :24.00   Max.   :1578.0  \n\nhead(df_1_base)\n\n  sex     geo TIME_PERIOD OBS_VALUE Id\n1   F albania        2013      18.4  1\n2   F      al        2014      18.5  2\n3   F      al        2015      17.8  3\n4   F      al        2016      18.3  4\n5   F      al        2017      18.0  5\n6   F      al        2018      18.5  6\n\n\n\ndf_1_base$Esp2 &lt;- df_1_base$OBS_VALUE**2\nhead(df_1_base)\n\n  sex     geo TIME_PERIOD OBS_VALUE Id   Esp2\n1   F albania        2013      18.4  1 338.56\n2   F      al        2014      18.5  2 342.25\n3   F      al        2015      17.8  3 316.84\n4   F      al        2016      18.3  4 334.89\n5   F      al        2017      18.0  5 324.00\n6   F      al        2018      18.5  6 342.25\n\n\n\n\n3.6.2 Tidyverse\nPour créer une colonne en tidyverse, on utilise la même fonction que pour modifier une colonne : mutate(). La différence étant qu’au lieu de rentrer le nom de la colonne à modifier, on entre le nom que l’on souhaite donner à la nouvelle colonne\n\ndf_1_tidy &lt;- df_1_tidy %&gt;% \n  mutate(Id = 1:nrow(df_1_tidy),\n         Esp2 = OBS_VALUE**2)\nsummary(df_1_tidy)\n\n     sex          geo             TIME_PERIOD     OBS_VALUE    \n Female:526   Length:1578        Min.   :2010   Min.   :11.60  \n Male  :526   Class :character   1st Qu.:2012   1st Qu.:17.00  \n Total :526   Mode  :character   Median :2015   Median :18.90  \n                                 Mean   :2015   Mean   :18.64  \n                                 3rd Qu.:2018   3rd Qu.:20.60  \n                                 Max.   :2021   Max.   :24.00  \n       Id              Esp2      \n Min.   :   1.0   Min.   :134.6  \n 1st Qu.: 395.2   1st Qu.:289.0  \n Median : 789.5   Median :357.2  \n Mean   : 789.5   Mean   :353.7  \n 3rd Qu.:1183.8   3rd Qu.:424.4  \n Max.   :1578.0   Max.   :576.0  \n\nhead(df_1_tidy)\n\n     sex geo TIME_PERIOD OBS_VALUE Id   Esp2\n1 Female  AL        2013      18.4  1 338.56\n2 Female  AL        2014      18.5  2 342.25\n3 Female  AL        2015      17.8  3 316.84\n4 Female  AL        2016      18.3  4 334.89\n5 Female  AL        2017      18.0  5 324.00\n6 Female  AL        2018      18.5  6 342.25\n\n\nPour la suite on supprime la colonne Esp2 dans les deux tableaux\n\ndf_1_base &lt;- df_1_base[, names(df_1_base) != \"Esp2\"]\n\ndf_1_tidy &lt;- select(df_1_tidy, -\"Esp2\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Manipulation Tableaux</span>"
    ]
  },
  {
    "objectID": "1.ManipulationTableaux.html#renommer-une-colonne",
    "href": "1.ManipulationTableaux.html#renommer-une-colonne",
    "title": "3  Manipulation Tableaux",
    "section": "3.7 Renommer une colonne",
    "text": "3.7 Renommer une colonne\n\n3.7.1 R base\nPour renommer une variable en R base, on modifie sa valeur dans le vecteur contenant les noms de colonnes, c’est à dire le vecteur obtenu avec la fonction colnames() On modifie la valeur de ce vecteur par l’indice de la variable à modifier  Par exemple, si je veux renommer ma variable TIME_PERIOD en Year\n\ncolnames(df_1_base)\n\n[1] \"sex\"         \"geo\"         \"TIME_PERIOD\" \"OBS_VALUE\"   \"Id\"         \n\n\nTIME_PERIOD est la 3ième valeur, je dois donc modifier *colnames(df_1_base)[3]\n\ncolnames(df_1_base)[3] &lt;- \"Year\"\nhead(df_1_base)\n\n  sex     geo Year OBS_VALUE Id\n1   F albania 2013      18.4  1\n2   F      al 2014      18.5  2\n3   F      al 2015      17.8  3\n4   F      al 2016      18.3  4\n5   F      al 2017      18.0  5\n6   F      al 2018      18.5  6\n\n\nou en indiquant qu’il faut modifier la colonne dont le nom est spécifié\n\ncolnames(df_1_base)[colnames(df_1_base)==\"Year\"] &lt;- \"TIME_PERIOD\"\nhead(df_1_base)\n\n  sex     geo TIME_PERIOD OBS_VALUE Id\n1   F albania        2013      18.4  1\n2   F      al        2014      18.5  2\n3   F      al        2015      17.8  3\n4   F      al        2016      18.3  4\n5   F      al        2017      18.0  5\n6   F      al        2018      18.5  6\n\n\nOn peut également faire cela en utilisant names() au lieu de colnames() exactement de la même façon\n\n\n3.7.2 Tidyverse\nPour renommer une fonction en tidyverse, on utilise la fonction rename(). On indique Nouveau_nom = ancien_nom\n\ndf_1_tidy &lt;- df_1_tidy %&gt;% \n  rename(Year = TIME_PERIOD)\nhead(df_1_tidy)\n\n     sex geo Year OBS_VALUE Id\n1 Female  AL 2013      18.4  1\n2 Female  AL 2014      18.5  2\n3 Female  AL 2015      17.8  3\n4 Female  AL 2016      18.3  4\n5 Female  AL 2017      18.0  5\n6 Female  AL 2018      18.5  6\n\n\nPour la suite je renomme la variable en TIME_PERIOD\n\ndf_1_tidy &lt;- df_1_tidy %&gt;% \n  rename(TIME_PERIOD = Year)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Manipulation Tableaux</span>"
    ]
  },
  {
    "objectID": "1.ManipulationTableaux.html#ordonner-la-base-en-fonction-dune-ou-plusieurs-colonnes",
    "href": "1.ManipulationTableaux.html#ordonner-la-base-en-fonction-dune-ou-plusieurs-colonnes",
    "title": "3  Manipulation Tableaux",
    "section": "3.8 Ordonner la base en fonction d’une ou plusieurs colonnes",
    "text": "3.8 Ordonner la base en fonction d’une ou plusieurs colonnes\n\n3.8.1 R base\nPour ordonner une base en fonction d’une variable en R base, il faut sélectionner les lignes dans l’ordre souhaité. Il faut donc d’abord trier le vecteur contenant la variable selon laquelle faire le tri \n\nVariables numériques\n Pour trier un vecteur en R, on utilise la fonction sort()\n\nsort(c(9,2,4,5,6))\n\n[1] 2 4 5 6 9\n\n\nPar défaut la fonction sort trie par ordre croissant, pour trier dans l’ordre décroissant, il faut préciser decreasing = T\n\nsort(c(9,2,4,5,6), decreasing = T)\n\n[1] 9 6 5 4 2\n\n\nUne autre fonction de trier un vecteur est d’utiliser la fonction order()   Attention  cette fonction renvoie les  indices  dans l’ordre croissant de leur valeur\n\norder(c(9,2,4,5,6))\n\n[1] 2 3 4 5 1\n\n\nPour avoir le vecteur trier dans l’ordre coissant, il faut donc faire\n\nc(9,2,4,5,6)[order(c(9,2,4,5,6))]\n\n[1] 2 4 5 6 9\n\n\nDe même que pour sort(), on précise decreasing = T pour trier dans l’ordre décroissant.   Cette façon de faire est moins adapter pour trier un vecteur, en revanche elle est très bien adaptée pour trier un data.frame. En effet, comme elle renvoie les indices triés dans l’ordre croissant de leur valeur, pour trier le dataframe, il suffit de faire une sélection de lignes en sélectionnant les lignes par ce vecetur d’indices triés. Les lignes seront donc sélectionnées dans l’ordre souhaité  \nPour trier notre tableau par odre croissant de l’espérance de vie à 65 ans, on applique la fonction order() à OBS_VALUE\n\ndf_1_base &lt;- df_1_base[order(df_1_base$OBS_VALUE),]\nhead(df_1_base)\n\n    sex geo TIME_PERIOD OBS_VALUE  Id\n584   M  bg        2021      11.6 584\n875   M  md        2010      11.9 875\n585   M  by        2011      12.0 585\n986   M  ru        2010      12.1 986\n889   M  me        2021      12.2 889\n985   M  rs        2021      12.2 985\n\n\nPour trier par ordre décroissant de l’espérance de vie à 65 ans, on précise decreasing = T\n\ndf_1_base &lt;- df_1_base[order(df_1_base$OBS_VALUE, decreasing = T),]\nhead(df_1_base)\n\n    sex geo TIME_PERIOD OBS_VALUE  Id\n222   F  fr        2014      24.0 222\n173   F  es        2019      23.9 173\n227   F  fr        2019      23.9 227\n219   F  fr        2011      23.8 219\n226   F  fr        2018      23.8 226\n231   F  fx        2011      23.8 231\n\n\nOn peut également ordonner par plusieurs variables en les précisants dans l’ordre de tri souhaité dans order()   Pour trier par années et par espérance de vie à 65 ans \n\n# Au préalable je tranforme TIME_PERIOD en variable numérique\ndf_1_base$TIME_PERIOD &lt;- as.numeric(df_1_base$TIME_PERIOD)\n\n\ndf_1_base &lt;- df_1_base[order(df_1_base$TIME_PERIOD, df_1_base$OBS_VALUE),]\nhead(df_1_base)\n\n     sex geo TIME_PERIOD OBS_VALUE   Id\n875    M  md        2010      11.9  875\n986    M  ru        2010      12.1  986\n1034   M  ua        2010      12.2 1034\n863    M  lv        2010      13.1  863\n1401   T  md        2010      13.6 1401\n573    M  bg        2010      13.8  573\n\n\nOn peut aussi trier par ordre croissant pour certaines variables et decroissant pour d’autres. Pour cela on met “-” devant les variables à trier par ordre décroissant.  Exemple : trier par années les plus récentes, par espérance de vie à 65 ans\n\ndf_1_base &lt;- df_1_base[order(-df_1_base$TIME_PERIOD, df_1_base$OBS_VALUE),]\nhead(df_1_base)\n\n    sex geo TIME_PERIOD OBS_VALUE  Id\n584   M  bg        2021      11.6 584\n889   M  me        2021      12.2 889\n985   M  rs        2021      12.2 985\n901   M  mk        2021      12.5 901\n973   M  ro        2021      12.5 973\n874   M  lv        2021      12.7 874\n\n\n\n\nVariables facteurs ou caractères\nOn peut aussi ordonner un vecteur selon les données d’une variable catégorielle (de type facteur), ou même d’une variable en caractère.Cela fonctionne exactement comme pour une variable numérique\n\nclass(df_1_base$sex)\n\n[1] \"factor\"\n\ndf_1_base &lt;- df_1_base[order(df_1_base$sex),]\nhead(df_1_base)\n\n    sex geo TIME_PERIOD OBS_VALUE  Id\n375   F  mk        2021      14.9 375\n459   F  rs        2021      15.1 459\n58    F  bg        2021      15.5  58\n363   F  me        2021      15.5 363\n9     F  al        2021      15.8   9\n447   F  ro        2021      16.4 447\n\n\n\nclass(df_1_base$geo)\n\n[1] \"character\"\n\ndf_1_base &lt;- df_1_base[order(df_1_base$geo),]\nhead(df_1_base)\n\n  sex geo TIME_PERIOD OBS_VALUE Id\n9   F  al        2021      15.8  9\n8   F  al        2020      17.7  8\n7   F  al        2019      18.7  7\n6   F  al        2018      18.5  6\n5   F  al        2017      18.0  5\n4   F  al        2016      18.3  4\n\n\n\n\n\n3.8.2 Tidyverse\n\nVariables numériques\nPour trier un tableau en tidyverse, on utilise la fonction arrange()   Exemple : pour trier notre tableau par odre croissant de l’espérance de vie à 65 ans, on applique la fonction arrange à OBS_VALUE\n\ndf_1_tidy &lt;- df_1_tidy %&gt;% \n  arrange(OBS_VALUE)\nhead(df_1_tidy)\n\n   sex geo TIME_PERIOD OBS_VALUE  Id\n1 Male  BG        2021      11.6 584\n2 Male  MD        2010      11.9 875\n3 Male  BY        2011      12.0 585\n4 Male  RU        2010      12.1 986\n5 Male  ME        2021      12.2 889\n6 Male  RS        2021      12.2 985\n\n\nPour trier par ordre décroissant, on applique la fonction desc() au nom de la variable\n\ndf_1_tidy &lt;- df_1_tidy %&gt;% \n  arrange(desc(OBS_VALUE))\nhead(df_1_tidy)\n\n     sex geo TIME_PERIOD OBS_VALUE  Id\n1 Female  FR        2014      24.0 222\n2 Female  ES        2019      23.9 173\n3 Female  FR        2019      23.9 227\n4 Female  FR        2011      23.8 219\n5 Female  FR        2018      23.8 226\n6 Female  FX        2011      23.8 231\n\n\nOn peut également trier selon plusieurs variables :  Exemple : trier par années les plus récentes, par espérance de vie à 65 ans\n\ndf_1_tidy &lt;- df_1_tidy %&gt;% \n  arrange(desc(TIME_PERIOD), OBS_VALUE)\nhead(df_1_tidy)\n\n   sex geo TIME_PERIOD OBS_VALUE  Id\n1 Male  BG        2021      11.6 584\n2 Male  ME        2021      12.2 889\n3 Male  RS        2021      12.2 985\n4 Male  MK        2021      12.5 901\n5 Male  RO        2021      12.5 973\n6 Male  LV        2021      12.7 874\n\n\n\n\nVariables facteurs ou caractères\nOn peut appliquer la fonction arrange() de la même façon que pour des variables numériques à des variables de type facteur ou caractère\n\nclass(df_1_tidy$sex)\n\n[1] \"factor\"\n\ndf_1_tidy &lt;- df_1_tidy %&gt;% \n  arrange(desc(sex))\nhead(df_1_tidy)\n\n    sex geo TIME_PERIOD OBS_VALUE   Id\n1 Total  BG        2021      13.6 1110\n2 Total  MK        2021      13.7 1427\n3 Total  RS        2021      13.7 1511\n4 Total  ME        2021      13.9 1415\n5 Total  RO        2021      14.6 1499\n6 Total  AL        2021      14.8 1061\n\n\n\nclass(df_1_tidy$geo)\n\n[1] \"character\"\n\ndf_1_tidy &lt;- df_1_tidy %&gt;% \n  arrange(geo)\nhead(df_1_tidy)\n\n    sex geo TIME_PERIOD OBS_VALUE   Id\n1 Total  AL        2021      14.8 1061\n2 Total  AL        2020      16.6 1060\n3 Total  AL        2019      18.1 1059\n4 Total  AL        2018      17.8 1058\n5 Total  AL        2017      17.5 1057\n6 Total  AL        2016      17.6 1056",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Manipulation Tableaux</span>"
    ]
  },
  {
    "objectID": "1.ManipulationTableaux.html#connaître-les-différentes-valeurs-prises-par-une-variable",
    "href": "1.ManipulationTableaux.html#connaître-les-différentes-valeurs-prises-par-une-variable",
    "title": "3  Manipulation Tableaux",
    "section": "3.9 Connaître les différentes valeurs prises par une variable",
    "text": "3.9 Connaître les différentes valeurs prises par une variable\nLa fonction unique() crée un vecteur qui contient chaque valeur prise par la variable, mais de façon unique\n\nunique(df$geo)\n\n [1] \"AL\"        \"AM\"        \"AT\"        \"AZ\"        \"BE\"        \"BG\"       \n [7] \"BY\"        \"CH\"        \"CY\"        \"CZ\"        \"DE\"        \"DK\"       \n[13] \"EA19\"      \"EA20\"      \"EE\"        \"EL\"        \"ES\"        \"EU27_2007\"\n[19] \"EU27_2020\" \"EU28\"      \"FI\"        \"FR\"        \"FX\"        \"GE\"       \n[25] \"HR\"        \"HU\"        \"IE\"        \"IS\"        \"IT\"        \"LI\"       \n[31] \"LT\"        \"LU\"        \"LV\"        \"MD\"        \"ME\"        \"MK\"       \n[37] \"MT\"        \"NL\"        \"NO\"        \"PL\"        \"PT\"        \"RO\"       \n[43] \"RS\"        \"RU\"        \"SE\"        \"SI\"        \"SK\"        \"SM\"       \n[49] \"TR\"        \"UA\"        \"UK\"        \"XK\"       \n\n\nPour savoir combien de valeurs différentes une variable prend, on peut donc regarder la taille du vecteur créer avec unique()\n\nlength(unique(df$geo))\n\n[1] 52\n\n\nLa variable geo prend 52 valeurs différentes   Si on veut savoir combien de fois chaque valeur est prise, on peut utiliser la fonction table()\n\ntable(df$geo)\n\n\n       AL        AM        AT        AZ        BE        BG        BY        CH \n       27        15        36        24        36        36        24        36 \n       CY        CZ        DE        DK      EA19      EA20        EE        EL \n       36        36        36        36        36         3        36        36 \n       ES EU27_2007 EU27_2020      EU28        FI        FR        FX        GE \n       36        27        36        27        36        36         9        24 \n       HR        HU        IE        IS        IT        LI        LT        LU \n       36        36        36        36        36        36        36        36 \n       LV        MD        ME        MK        MT        NL        NO        PL \n       36         9        36        36        36        36        36        36 \n       PT        RO        RS        RU        SE        SI        SK        SM \n       36        36        36         3        36        36        36         3 \n       TR        UA        UK        XK \n       30        27        27         3",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Manipulation Tableaux</span>"
    ]
  },
  {
    "objectID": "1.ManipulationTableaux.html#transposer-un-tableau",
    "href": "1.ManipulationTableaux.html#transposer-un-tableau",
    "title": "3  Manipulation Tableaux",
    "section": "3.10 Transposer un tableau",
    "text": "3.10 Transposer un tableau\nIl peut parfois être nécessaire de transposer un tableau, ou du moins de transformer des lignes en colonnes ou inversement.  \n\n3.10.1 Transformer des lignes en colonnes - pivot_wider()\nPar exemple, dans le tableau df, nous avons une ligne par sexe, par pays, par année :\n\nhead(df_1_tidy, 20)\n\n      sex geo TIME_PERIOD OBS_VALUE   Id\n1   Total  AL        2021      14.8 1061\n2   Total  AL        2020      16.6 1060\n3   Total  AL        2019      18.1 1059\n4   Total  AL        2018      17.8 1058\n5   Total  AL        2017      17.5 1057\n6   Total  AL        2016      17.6 1056\n7   Total  AL        2015      17.1 1055\n8   Total  AL        2014      17.6 1054\n9   Total  AL        2013      17.5 1053\n10   Male  AL        2021      13.9  535\n11   Male  AL        2020      15.6  534\n12   Male  AL        2019      17.5  533\n13   Male  AL        2018      17.2  532\n14   Male  AL        2017      17.0  531\n15   Male  AL        2016      16.9  530\n16   Male  AL        2015      16.4  529\n17   Male  AL        2014      16.7  528\n18   Male  AL        2013      16.6  527\n19 Female  AL        2021      15.8    9\n20 Female  AL        2020      17.7    8\n\n\nPour certaines analyses, il peut être préférable d’avoir une ligne par pays, par année et les espérances de vie pour chaque sexe comme variable. Cela reviendrait à diviser par 3 le nombre de lignes et à créer 3 variables OBS_VALUE_F, OBS_VALUE_M et OBS_VALUE_T.   Pour faire cela, on utilise la fonction pivot_wider() du package tidyr  Remarque : Ce nom vient du fait que l’on élargit le tableau en diminuant le nombre de lignes et augmentant le nombre de colonnes   Pour appliquer la fonction, il faut que toutes les autres variables soient identiques entre les lignes à regrouper. Ici, nous avons créé la variable Id qui est unique pour chaque ligne du tableau. Si on essaie d’appliquer directement la fonction pivot_wider() au tableau df_1_tidy, nous n’aurons pas d’erreur, mais la fonction ne fera pas le travail attendu\n\nhead(df_1_tidy %&gt;% \n  pivot_wider(names_from = sex,\n              values_from = OBS_VALUE))\n\n# A tibble: 6 × 6\n  geo   TIME_PERIOD    Id Total  Male Female\n  &lt;chr&gt;       &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 AL           2021  1061  14.8    NA     NA\n2 AL           2020  1060  16.6    NA     NA\n3 AL           2019  1059  18.1    NA     NA\n4 AL           2018  1058  17.8    NA     NA\n5 AL           2017  1057  17.5    NA     NA\n6 AL           2016  1056  17.6    NA     NA\n\n\nPour obtenir la transformation souhaitée, nous allons d’abord supprimer la colonne Id, puis appliquer pivot_wider()\n\ndf_1_tidy &lt;- df_1_tidy %&gt;% select(-Id)\ndf_1_wider &lt;- df_1_tidy %&gt;% \n  pivot_wider(names_from = sex,\n              values_from = OBS_VALUE)\n\nhead(df_1_wider)\n\n# A tibble: 6 × 5\n  geo   TIME_PERIOD Total  Male Female\n  &lt;chr&gt;       &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 AL           2021  14.8  13.9   15.8\n2 AL           2020  16.6  15.6   17.7\n3 AL           2019  18.1  17.5   18.7\n4 AL           2018  17.8  17.2   18.5\n5 AL           2017  17.5  17     18  \n6 AL           2016  17.6  16.9   18.3\n\nprint(c(nrow(df_1_wider), ncol(df_1_wider)))\n\n[1] 526   5\n\n\nIl est également possible d’attribuer un préfixe au nom des nouvelles variables, pour cela on utilise l’option names_prefix =\n\ndf_1_wider &lt;- df_1_tidy %&gt;% \n  pivot_wider(names_from = sex,\n              values_from = OBS_VALUE,\n              names_prefix = \"OBS_VALUE_\")\n\nhead(df_1_wider)\n\n# A tibble: 6 × 5\n  geo   TIME_PERIOD OBS_VALUE_Total OBS_VALUE_Male OBS_VALUE_Female\n  &lt;chr&gt;       &lt;int&gt;           &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1 AL           2021            14.8           13.9             15.8\n2 AL           2020            16.6           15.6             17.7\n3 AL           2019            18.1           17.5             18.7\n4 AL           2018            17.8           17.2             18.5\n5 AL           2017            17.5           17               18  \n6 AL           2016            17.6           16.9             18.3\n\nprint(c(nrow(df_1_wider), ncol(df_1_wider)))\n\n[1] 526   5\n\n\nLa fonction pivot_wider() propose de nombreuses options pour personnaliser le noms des colonnes et permet de repérer les colonnes sur lesquelles faire les transformations. Nous ne pouvons pas toutes les montrer ici.  \n\nTransformer plusieurs lignes en même temps\nIl est également possible de transformer plusieurs lignes d’un seul coup, s’il y a des combinaisons identiques.   Par exemple dans notre tableau, on peut garder une lignes par pays et créer une variable par sexe par année : Female_2016, Male_2016, Total_2016, Female_2017, Male_2017, Total_2017, etc …\n\ndf_1_wider_Sex_Year &lt;- df_1_tidy %&gt;% \n  pivot_wider(names_from = c(sex, TIME_PERIOD),\n              values_from = OBS_VALUE)\n\nkable(head(df_1_wider_Sex_Year)) # La fonction kable permet un meilleur affichage du tableau\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeo\nTotal_2021\nTotal_2020\nTotal_2019\nTotal_2018\nTotal_2017\nTotal_2016\nTotal_2015\nTotal_2014\nTotal_2013\nMale_2021\nMale_2020\nMale_2019\nMale_2018\nMale_2017\nMale_2016\nMale_2015\nMale_2014\nMale_2013\nFemale_2021\nFemale_2020\nFemale_2019\nFemale_2018\nFemale_2017\nFemale_2016\nFemale_2015\nFemale_2014\nFemale_2013\nTotal_2012\nTotal_2011\nTotal_2010\nMale_2012\nMale_2011\nMale_2010\nFemale_2012\nFemale_2011\nFemale_2010\n\n\n\n\nAL\n14.8\n16.6\n18.1\n17.8\n17.5\n17.6\n17.1\n17.6\n17.5\n13.9\n15.6\n17.5\n17.2\n17.0\n16.9\n16.4\n16.7\n16.6\n15.8\n17.7\n18.7\n18.5\n18.0\n18.3\n17.8\n18.5\n18.4\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nAM\nNA\nNA\n16.9\n16.8\n16.3\n16.0\n16.0\nNA\nNA\nNA\nNA\n15.3\n15.2\n14.7\n14.5\n14.5\nNA\nNA\nNA\nNA\n18.0\n18.0\n17.5\n17.2\n17.2\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nAT\n19.6\n19.6\n20.3\n20.1\n20.1\n20.2\n19.8\n20.3\n20.0\n18.0\n17.9\n18.7\n18.5\n18.5\n18.5\n18.1\n18.5\n18.2\n21.1\n21.0\n21.7\n21.6\n21.5\n21.7\n21.3\n21.8\n21.5\n19.8\n20.1\n19.8\n18.1\n18.1\n17.9\n21.3\n21.7\n21.4\n\n\nAZ\nNA\nNA\n17.4\n16.6\n16.4\nNA\n16.3\n15.6\n15.7\nNA\nNA\n16.5\n15.6\n15.6\nNA\n15.4\n14.5\n14.7\nNA\nNA\n18.1\n17.5\n17.2\nNA\n17.1\n16.5\n16.5\n15.3\nNA\n15.1\n14.0\nNA\n14.1\n16.4\nNA\n16.0\n\n\nBE\n20.4\n19.3\n20.6\n20.3\n20.3\n20.3\n20.0\n20.3\n19.7\n18.5\n17.6\n18.9\n18.6\n18.5\n18.4\n18.2\n18.4\n17.8\n22.1\n20.8\n22.1\n21.9\n21.9\n21.9\n21.5\n21.9\n21.4\n19.6\n19.9\n19.6\n17.7\n18.0\n17.6\n21.3\n21.6\n21.3\n\n\nBG\n13.6\n15.1\n16.3\n16.2\n16.1\n16.2\n16.0\n16.0\n16.2\n11.6\n12.9\n14.2\n14.2\n14.1\n14.2\n14.0\n14.1\n14.2\n15.5\n17.1\n18.1\n18.0\n17.8\n17.9\n17.6\n17.6\n17.9\n15.8\n15.8\n15.6\n13.9\n14.0\n13.8\n17.3\n17.3\n17.1\n\n\n\n\nprint(c(nrow(df_1_wider_Sex_Year), ncol(df_1_wider_Sex_Year)))\n\n[1] 52 37\n\n\nRemarque: l’ordre des variables crées dépend de l’odre dans lequel on entre le noms des colonnes\n\n\n\n3.10.2 Transformer des colonnes en lignes - pivot_longer()\nNous avons vu comment transformer des lignes en colonnes. Parfois, c’est l’opération inverse que nous aurons besoin d’effectuer. En effet, il est parfois préférable d’avoir une ligne par observation au lieu d’avoir toutes les informations sur la même lignes.  Pour cela, on utilise la fonction pivot_longer() du package tidyr  Remarque : le nom de cette fonction vient du fait qu’on allonge le tableau en augmentant le nombre de lignes et en diminuant le nombre de colonnes  \nPour l’exemple nous allons repartir du tableau df_1_wider créer précédemment. Et nous allons faire l’opération inverse, c’est à dire faire une ligne par sexe.  Pour cela, nous devons prendre les valeurs des trois variables OBS_VALUE_Total, OBS_VALUE_Male et OBS_VALUE_Female et n’en garder qu’une par ligne. Cela implique de supprimer ces variables mais d’en créé deux nouvelles : sex et OBS_VALUE\n\ndf_1_longer &lt;- df_1_wider %&gt;% \n  pivot_longer(cols = c(\"OBS_VALUE_Total\", \"OBS_VALUE_Male\", \"OBS_VALUE_Female\"),\n               names_to = \"sex\",\n               values_to = \"OBS_VALUE\")\n\nhead(df_1_longer)\n\n# A tibble: 6 × 4\n  geo   TIME_PERIOD sex              OBS_VALUE\n  &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;                &lt;dbl&gt;\n1 AL           2021 OBS_VALUE_Total       14.8\n2 AL           2021 OBS_VALUE_Male        13.9\n3 AL           2021 OBS_VALUE_Female      15.8\n4 AL           2020 OBS_VALUE_Total       16.6\n5 AL           2020 OBS_VALUE_Male        15.6\n6 AL           2020 OBS_VALUE_Female      17.7\n\n\nRemarque 1 : Les valeurs prises par la variable sex sont exactement les noms des colonnes à partir desquelles nous faisons la transformation. Ici, il serait préférable de ne garder que Total, Male et Female et d’enlever le préfixe OBS_VALUE. Pour cela, on peut utiliser l’option names_prefix\n\ndf_1_longer &lt;- df_1_wider %&gt;% \n  pivot_longer(cols = c(\"OBS_VALUE_Total\", \"OBS_VALUE_Male\", \"OBS_VALUE_Female\"),\n               names_to = \"sex\",\n               values_to = \"OBS_VALUE\",\n               names_prefix = \"OBS_VALUE_\")\n\nhead(df_1_longer)\n\n# A tibble: 6 × 4\n  geo   TIME_PERIOD sex    OBS_VALUE\n  &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;      &lt;dbl&gt;\n1 AL           2021 Total       14.8\n2 AL           2021 Male        13.9\n3 AL           2021 Female      15.8\n4 AL           2020 Total       16.6\n5 AL           2020 Male        15.6\n6 AL           2020 Female      17.7\n\nprint(c(nrow(df_1_longer), ncol(df_1_longer)))\n\n[1] 1578    4\n\n\nRemarque 2 : Dans cette exemple nous ne transformons que 3 colonnes, entrer les noms à la main n’est donc pas trop contraignant. Parfois, nous aurons besoins de tranformer un grand nombre de colonnes et nous ne voudrons donc pas à avoir toutes les spécifier manuellement. Une façon de faire serait alors de dire que l’on veut transformer toutes les colonnes dont le nom commence d’une certaine façon.   Dans cet exemple, on peut dire que l’on transforme toutes les colonnes qui commence par OBS_VALUE_ avec starts_with.\n\ndf_1_longer &lt;- df_1_wider %&gt;% \n  pivot_longer(cols = starts_with(\"OBS_VALUE_\"),\n               names_to = \"sex\",\n               values_to = \"OBS_VALUE\",\n               names_prefix = \"OBS_VALUE_\")\n\nhead(df_1_longer)\n\n# A tibble: 6 × 4\n  geo   TIME_PERIOD sex    OBS_VALUE\n  &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;      &lt;dbl&gt;\n1 AL           2021 Total       14.8\n2 AL           2021 Male        13.9\n3 AL           2021 Female      15.8\n4 AL           2020 Total       16.6\n5 AL           2020 Male        15.6\n6 AL           2020 Female      17.7\n\n\n\nTransformer plusieurs colonnes en même temps\nNous avons parfois des bases de données dont certaines variables contiennent plus d’une information. Si on les transforme directement en lignes comme précédemment, la variable indiquant à quoi/qui correspond la valeur contiendra alors une combinaison de valeurs.   Pour être plus explicite, si on repart du tableau df_1_wider_Sex_Year si on tranforme les colonnes en lignes, on aura une variable Name qui prendra en valeur les combinaisons Sexe et Année et une variable OBS_VALUE\n\ndf_1_longer_Sex_Year &lt;- df_1_wider_Sex_Year %&gt;% \n  pivot_longer(cols = c(starts_with(\"Total\"), starts_with(\"Male\"), starts_with(\"Female\")),\n               names_to = \"Sex_Year\",\n               values_to = \"OBS_VALUE\")\n\nhead(df_1_longer_Sex_Year)\n\n# A tibble: 6 × 3\n  geo   Sex_Year   OBS_VALUE\n  &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;\n1 AL    Total_2021      14.8\n2 AL    Total_2020      16.6\n3 AL    Total_2019      18.1\n4 AL    Total_2018      17.8\n5 AL    Total_2017      17.5\n6 AL    Total_2016      17.6\n\n\nSi l’on veut faire une variable Sex et une variable Year, on utilise names_pattern\n\ndf_1_longer_Sex_Year &lt;- df_1_wider_Sex_Year %&gt;% \n  pivot_longer(cols = c(starts_with(\"Total\"), starts_with(\"Male\"), starts_with(\"Female\")),\n               names_to = c(\"sex\",\"year\"),\n               names_pattern = \"(.*)_(.*)\",\n               values_to = \"OBS_VALUE\")\n\nhead(df_1_longer_Sex_Year)\n\n# A tibble: 6 × 4\n  geo   sex   year  OBS_VALUE\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt;\n1 AL    Total 2021       14.8\n2 AL    Total 2020       16.6\n3 AL    Total 2019       18.1\n4 AL    Total 2018       17.8\n5 AL    Total 2017       17.5\n6 AL    Total 2016       17.6\n\nprint(c(nrow(df_1_longer_Sex_Year), ncol(df_1_longer_Sex_Year)))\n\n[1] 1872    4",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Manipulation Tableaux</span>"
    ]
  },
  {
    "objectID": "1.ManipulationTableaux.html#travailler-sur-des-données-groupées",
    "href": "1.ManipulationTableaux.html#travailler-sur-des-données-groupées",
    "title": "3  Manipulation Tableaux",
    "section": "3.11 Travailler sur des données groupées",
    "text": "3.11 Travailler sur des données groupées\nOn peut vouloir regarder des statistiques sur des données groupées.  Par exemple, on s’intéresse à l’espérance de vie moyenne par sexe en Europe. Pour cela, on va devoir faire la moyenne pour les femmes, les hommes et la population totale de tous les pays\n\n3.11.1 Tidyverse\n\n\n3.11.2 Grouper selon une variable\nPour regrouper des observations selon les valeurs d’une ou plusieurs variables, on utilise la fonction group_by()\n\ndf_group &lt;- df %&gt;% \n  group_by(sex) %&gt;% \n  summarise(meanEsp = mean(OBS_VALUE))\n\ndf_group\n\n# A tibble: 3 × 2\n  sex   meanEsp\n  &lt;chr&gt;   &lt;dbl&gt;\n1 F        20.3\n2 M        16.9\n3 T        18.7\n\n\nSi l’on veut faire cet exercice correctement, il conviendrait de ne faire la moyenne que sur les observations qui correspondent à des pays. En effet, dans le tableau, nous avons déjà certaines observations de groupe, il faudrait donc les supprimer avant de faire la moyenne\n\nunique(df$geo) # indique les valeurs différentes prises par la variable geo\n\n [1] \"AL\"        \"AM\"        \"AT\"        \"AZ\"        \"BE\"        \"BG\"       \n [7] \"BY\"        \"CH\"        \"CY\"        \"CZ\"        \"DE\"        \"DK\"       \n[13] \"EA19\"      \"EA20\"      \"EE\"        \"EL\"        \"ES\"        \"EU27_2007\"\n[19] \"EU27_2020\" \"EU28\"      \"FI\"        \"FR\"        \"FX\"        \"GE\"       \n[25] \"HR\"        \"HU\"        \"IE\"        \"IS\"        \"IT\"        \"LI\"       \n[31] \"LT\"        \"LU\"        \"LV\"        \"MD\"        \"ME\"        \"MK\"       \n[37] \"MT\"        \"NL\"        \"NO\"        \"PL\"        \"PT\"        \"RO\"       \n[43] \"RS\"        \"RU\"        \"SE\"        \"SI\"        \"SK\"        \"SM\"       \n[49] \"TR\"        \"UA\"        \"UK\"        \"XK\"       \n\ndf_group &lt;- df %&gt;% \n  filter(!(geo %in% c(\"EA19\", \"EA20\", \"EU27_2007\", \"EU27_2020\", \"EU28\" ))) %&gt;% \n  group_by(sex) %&gt;% \n  summarise(meanEsp = mean(OBS_VALUE))\n\ndf_group\n\n# A tibble: 3 × 2\n  sex   meanEsp\n  &lt;chr&gt;   &lt;dbl&gt;\n1 F        20.2\n2 M        16.8\n3 T        18.6\n\n\nIl peut-être intéressant de savoir combien de données on été regroupées, pour cela on utilise n()\n\ndf_group &lt;- df %&gt;% \n  filter(!(geo %in% c(\"EA19\", \"EA20\", \"EU27_2007\", \"EU27_2020\", \"EU28\" ))) %&gt;% \n  group_by(sex) %&gt;% \n  summarise(meanEsp = mean(OBS_VALUE),\n            Nb_obs = n())\n\ndf_group\n\n# A tibble: 3 × 3\n  sex   meanEsp Nb_obs\n  &lt;chr&gt;   &lt;dbl&gt;  &lt;int&gt;\n1 F        20.2    483\n2 M        16.8    483\n3 T        18.6    483\n\n\n\n\n3.11.3 Grouper selon plusieurs variables\nPour regrouper les données selon plusieurs variables, il suffit de spécifier le noms de toutes les variables dans le group_by, par ordre de regroupement souhaité.   Par exemple, si l’on souhaite avoir l’espérance de vie moyenne par pays et par sexe à 65 ans et savoir sur combien d’années la moyenne est faite dans chaque pays (nombre de valeurs d’esperance de vie par pays), on peut faire :\n\ndf_group &lt;- df %&gt;% \n  filter(!(geo %in% c(\"EA19\", \"EA20\", \"EU27_2007\", \"EU27_2020\", \"EU28\" ))) %&gt;% \n  group_by(geo, sex) %&gt;% \n  summarise(meanEsp = mean(OBS_VALUE),\n            Nb_Years = n())\n\n`summarise()` has grouped output by 'geo'. You can override using the `.groups`\nargument.\n\ndf_group\n\n# A tibble: 141 × 4\n# Groups:   geo [47]\n   geo   sex   meanEsp Nb_Years\n   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;    &lt;int&gt;\n 1 AL    F        18.0        9\n 2 AL    M        16.4        9\n 3 AL    T        17.2        9\n 4 AM    F        17.6        5\n 5 AM    M        14.8        5\n 6 AM    T        16.4        5\n 7 AT    F        21.5       12\n 8 AT    M        18.2       12\n 9 AT    T        20.0       12\n10 AZ    F        16.9        8\n# ℹ 131 more rows",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Manipulation Tableaux</span>"
    ]
  },
  {
    "objectID": "2.InitiationGraphiques.html",
    "href": "2.InitiationGraphiques.html",
    "title": "4  Initiation Graphiques",
    "section": "",
    "text": "4.1 Simulation d’un jeu de données\nn &lt;- 5000\nid &lt;- 1:n\nx &lt;- rnorm(n, 50, 20)\nstatus &lt;- rbinom(n, size = 1, prob = 0.3)\ny &lt;- runif(n, min = 20, max = 80)\ncat &lt;- sample(c(\"Lung\", \"Liver\", \"Kidney\"), n, replace = T)\nz &lt;- runif(n, 0, 1)\n\ndf &lt;- data.frame(\"id\" = id,\n                 \"x\" = x,\n                 \"y\" = y,\n                 \"z\" = z,\n                 \"status\" = status,\n                 \"organ\" = cat)\n\ndf &lt;- mutate(df, status = as.factor(status))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Initiation Graphiques</span>"
    ]
  },
  {
    "objectID": "2.InitiationGraphiques.html#graphiques-avec-r-base",
    "href": "2.InitiationGraphiques.html#graphiques-avec-r-base",
    "title": "4  Initiation Graphiques",
    "section": "4.2 Graphiques avec R base",
    "text": "4.2 Graphiques avec R base\nEn général, on réalise les graphiques avec le package ggplot2. Cependant, les fonctions de R base peuvent être utiles quand on veut juste un apperçu rapide des données.  \nNuage de points\n\nplot(df$x, df$y)\n\n\n\n\n\n\n\n\nCourbe\n\nplot(sort(df$x), df$y, type = \"l\")\n\n\n\n\n\n\n\n\nHistogramme\n\nhist(df$x)\n\n\n\n\n\n\n\n\nBoxplot\n\nboxplot(df$x)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Initiation Graphiques</span>"
    ]
  },
  {
    "objectID": "2.InitiationGraphiques.html#graphiques-avec-ggplot2",
    "href": "2.InitiationGraphiques.html#graphiques-avec-ggplot2",
    "title": "4  Initiation Graphiques",
    "section": "4.3 Graphiques avec ggplot2",
    "text": "4.3 Graphiques avec ggplot2\nPour réaliser un graphique avec ggplot2, on commence par utilisé la fonction ggplot() dans laquelle on spécifie les données à utiliser. Ensuite, on rajoute la fonction pour choisir le type de graphique et on peut mettre d’autres fonctions pour le personnalisé. On utilise + pour enchaîner les fonctions graphiques.  On peut spécifier les données des axes soit dans la fonction ggplot(), soit dans la fonction du graphique. Dans les deux cas, cela se fait avec la fonction aes()   Les fonctions définissant les type de graphiques commencent par geom_\n\n4.3.1 Nuage de points avec geom_point()\n\nggplot(df, aes(x=x, y=y))+\n  geom_point()\n\n\n\n\n\n\n\n\nIci nous definissons l’aes dans geom_point()\n\nggplot(df)+\n  geom_point(aes(x=x, y=y))\n\n\n\n\n\n\n\n\n\nAjouter des couleurs\nOn peut ajouter des couleurs soit en fixant une couleurs si on veut juste modifier le noir qui est la couleur par défaut. Soit en colorant en fonction d’une variable.   Pour choisir la couleur, on utilise l’es arguments’argument col =.   Si on veut choisir une couleur fixe, on utilise définit col dans la fonction du type de graphique, à l’extérieur  de l’aes().  Par contre, si on veut définir les couleurs en fonction d’une variable, alors on le défini à l’intérieur de l’aes()\n\nggplot(df, aes(x=x, y=y))+\n  geom_point(col = \"lightblue\")\n\n\n\n\n\n\n\n\nCouleur en fonction de la variable organ\n\nggplot(df, aes(x=x, y=y, col = organ))+\n  geom_point()\n\n\n\n\n\n\n\n\nOn peut également colorer en fonction d’une variable continue et avoir un dégradé\n\nggplot(df, aes(x, y, col = z))+\n  geom_point()+\n  scale_color_continuous()\n\n\n\n\n\n\n\n\n\n\nForme des points\nOn peut définir la forme des points avec l’argument shape =. De même que pour les couleurs, si on le définit à l’extérieur de l’aes, la même forme s’appliquera à tous les points.  Si on le définit à l’intérieur de l’aes, la forme dépendra de la variable choisie \n\n\n\nLes différentes formes de points pouvant être utilisées\n\n\n\nggplot(df, aes(x=x, y=y))+\n  geom_point(shape = 3)\n\n\n\n\n\n\n\n\n\nggplot(df, aes(x=x, y=y, shape = organ))+\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nModifier la taille des points\nOn peut modifier la taille des points avec l’argument size = . De même que pour les couleurs, on la fixe à l’extérieur de l’aes ou on la laisse dépendre d’une variable à l’intérieur de l’aes\n\nggplot(df, aes(x=x, y=y))+\n  geom_point(size = 3)\n\n\n\n\n\n\n\n\n\nggplot(df, aes(x=x, y=y, size = status))+\n  geom_point()\n\nWarning: Using size for a discrete variable is not advised.\n\n\n\n\n\n\n\n\n\n\n\n\n4.3.2 Histogramme avec geom_histogram()\n\nggplot(df, aes(x))+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nAjouter des couleurs\nOn peut ajouter des couleurs soit en fixant une couleurs si on veut juste modifier le noir qui est la couleur par défaut. Soit en colorant en fonction d’une variable.   Pour choisir la couleur, on utilise les arguments col = ou fill = . Col est utilisé pour les points et les lignes et les bords des barplots. Pour colorer l’intérieur des barplots on utilise fil.   Si on veut choisir une couleur fixe, on utilise les arguments col ou fill dans la fonction du type de graphique, à l’extérieur  de l’aes().  Par contre, si on veut définir les couleurs en fonction d’une variable, alors on le défini à l’intérieur de l’aes()\n\nggplot(df, aes(x))+\n  geom_histogram(col = \"#7c1444\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nggplot(df, aes(x))+\n  geom_histogram(fill = \"#7c1444\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nOn peut mettre un effet de transparence avec l’argument alpha =\n\nggplot(df, aes(x))+\n  geom_histogram(fill = \"#7c1444\", alpha = 0.6)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nCouleurs en fonction d’une variable\n\nggplot(df, aes(x, fill = organ))+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n\n4.3.3 Boxplot avec geom_boxplot()\n\nggplot(df, aes(x))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\nOn peut l’avoir dans l’autre sens en utilisant coord_flip()\n\nggplot(df, aes(x))+\n  geom_boxplot()+\n  coord_flip()\n\n\n\n\n\n\n\n\nOn peut faire plusieurs boxplot selon les catégories d’une variables catégorielle sur le même graphique\n\nggplot(df, aes(organ, x))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nAjouter des couleurs\nPour les boxplots, les couleurs fonctionnent de la même façon que pour les histogrammes : col pour définir les couleurs des bords, des quartiles, des outliers, etc, et fill pour l’intérieur du boxplot\n\nggplot(df, aes(organ, x))+\n  geom_boxplot(col = \"firebrick\")\n\n\n\n\n\n\n\n\n\nggplot(df, aes(organ, x))+\n  geom_boxplot(fill = \"firebrick\")\n\n\n\n\n\n\n\n\n\nggplot(df, aes(organ, x, col = organ))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nggplot(df, aes(organ, x, fill = organ))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\nRemarque: on peut le faire en définissant uniquement une variable et la variable de couleur, mais dans ce cas les modalités n’apparaissent pas sur l’axe\n\nggplot(df, aes(x, fill = organ))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\nRemarque: on ne peut pas colorer que ce soit avec col ou fill en fonction d’une troisième variable\n\n\nAutres personnalisations\nAugmenter l’épaisseurs du boxplot avec size\n\nggplot(df, aes(organ, x))+\n  geom_boxplot(size = 1)\n\n\n\n\n\n\n\n\n\n\n\n4.3.4 Barplot avec geom_bar()\n\nggplot(df, aes(organ))+\n  geom_bar()\n\n\n\n\n\n\n\n\nAinsi on a le nombre d’observations qui prennent chaque modalité.   Une autre façon de faire :\n\ndf_bar &lt;- df %&gt;% \n  group_by(organ) %&gt;% \n  summarise(n=n())\n\nggplot(df_bar, aes(organ, n))+\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\nPour l’orienter dans l’autre sens on ajoute la fonction coord_flip()\n\nggplot(df_bar, aes(organ, n))+\n  geom_bar(stat = \"identity\")+\n  coord_flip()\n\n\n\n\n\n\n\n\n\nAjouter des couleurs\n\nggplot(df, aes(organ))+\n  geom_bar(col = \"red\")\n\n\n\n\n\n\n\n\n\nggplot(df, aes(organ))+\n  geom_bar(fill = \"orange\")\n\n\n\n\n\n\n\n\n\n\nSuperposer des modalités\n\nggplot(df, aes(organ, fill=status))+\n  geom_bar()\n\n\n\n\n\n\n\n\nOu\n\ndf_bar &lt;- df %&gt;% \n  group_by(organ, status) %&gt;% \n  summarise(n=n())\n\n`summarise()` has grouped output by 'organ'. You can override using the\n`.groups` argument.\n\nggplot(df_bar, aes(organ, n, fill = status))+\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\n\n\n\n4.3.5 Courbes avec geom_line()\n\nggplot(df, aes(x, y))+\n  geom_line()\n\n\n\n\n\n\n\n\n\nCouleurs de la courbe\n\nggplot(df, aes(x, y))+\n  geom_line(col = \"darkgreen\")\n\n\n\n\n\n\n\n\nSi on défini la couleur en fonction d’une variable catégorielle, alors on aura autant de courbes que de modalités\n\nggplot(df, aes(x, y, col = organ))+\n  geom_line()\n\n\n\n\n\n\n\n\n\n\nFormat de la courbe\nOn peut changer l’aspect de la courbe avec l’argument linetype\n\nggplot(df, aes(x, y))+\n  geom_line(linetype = \"dashed\")\n\n\n\n\n\n\n\n\n\n\n\nDifférents types de trait pouvant être utilisé avec l’argument linetype\n\n\nPour changer l’épaisseur du trait, on utilise l’argume linewidth\n\nggplot(df, aes(x, y))+\n  geom_line(linewidth = 0.8)\n\n\n\n\n\n\n\n\n\n\n\n4.3.6 Personnalisation des couleurs\nLorsque l’on définit des couleurs en fonction d’une variable, les couleurs sont mises par défaut.   On peut modifier cela en définissant nos propres couleurs avec la fonction scale_color_manual() ou scale_fill_manual()\n\nggplot(df, aes(organ, fill=status))+\n  geom_bar()+\n  scale_fill_manual(values = c(\"firebrick\", \"orange\"))\n\n\n\n\n\n\n\n\nOn peut indiquer clairement quelle couleur correspond à quelle modalité\n\nggplot(df, aes(organ, fill=status))+\n  geom_bar()+\n  scale_fill_manual(values = c(\"1\" = \"firebrick\", \n                               \"0\" = \"orange\"))\n\n\n\n\n\n\n\n\nOn peut aussi dans cette fonction renommer les modalités pour changer leur nom dans la légende\n\nggplot(df, aes(organ, fill=status))+\n  geom_bar()+\n  scale_fill_manual(values = c(\"1\" = \"firebrick\", \n                               \"0\" = \"orange\"),\n                    labels = c(\"0\" = \"Alive\",\n                               \"1\" = \"Dead\")) \n\n\n\n\n\n\n\n\nPour un dégradé de couleurs associé à une variable continue, on utilise la fonction scale_colour_gradient()\n\nggplot(df, aes(x, y, col = z))+\n  geom_point()+\n  scale_colour_gradient(low = \"black\", high = \"white\")\n\n\n\n\n\n\n\n\nOu si on veut spécifier plusieurs couleurs la fonction scale_colour_gradientn()\n\nggplot(df, aes(x, y, col = z))+\n  geom_point()+\n  scale_colour_gradientn(colours = c(\"darkred\", \"orange\", \"yellow\", \"white\"))\n\n\n\n\n\n\n\n\n\n\n4.3.7 Ajouter des lignes sur le graphique\nIl est parfois utile de rajouter une ligne horizontale ou verticale sur un graphique afin de mettre en avant une graduation. Cela se fait avec la fonction geom_hline pour une ligne horizontale, geom_vline() pour une ligne verticale ou geom_abline() pour définir une droite spécifique comme par exemple une droite de régression  \nLigne horizontale\n\nggplot(df, aes(x,y))+\n  geom_point()+\n  geom_hline(yintercept = 60, col=\"darkred\")\n\n\n\n\n\n\n\n\nLigne verticale\n\nggplot(df, aes(x,y))+\n  geom_point()+\n  geom_vline(xintercept = 0, col=\"darkred\")\n\n\n\n\n\n\n\n\nDroite\n\nggplot(df, aes(x,y))+\n  geom_point()+\n  geom_abline(slope=1, intercept = 20, col = \"darkred\", linetype = \"dashed\", linewidth = 1)\n\n\n\n\n\n\n\n\nDroite de régression  Pour ajouter une droite de régression, on peut utiliser les fonctions geom_smooth() ou stat_smooth() avec l’argument method = “lm” pour une régression linéaire par exemple. L’argument se permet de montrer ou non l’intervalle de confiance\n\nggplot(df, aes(x,y))+\n  geom_point()+\n  geom_smooth(method=\"lm\", se=T)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(df, aes(x,y))+\n  geom_point()+\n  stat_smooth(method=\"lm\", se=T)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n4.3.8 Noms des axes et titres\nPour modifier le nom des axes on utilse les fonctions xlab(), ylab() ou labs()\n\nggplot(df, aes(x=x, y=y))+\n  geom_point()+\n  xlab(\"New x name\")+\n  ylab(\"New y name\")\n\n\n\n\n\n\n\n\nou\n\nggplot(df, aes(x=x, y=y))+\n  geom_point()+\n  labs(x =\"New x name\",\n       y=\"New y name\")\n\n\n\n\n\n\n\n\nPour ajouter un titre, on utilise soit la fonction ggtitle, soit encore labs()\n\nggplot(df, aes(x=x, y=y))+\n  geom_point()+\n  ggtitle(\"Scatter plot of x and y\")\n\n\n\n\n\n\n\n\n\nggplot(df, aes(x=x, y=y))+\n  geom_point()+\n  labs(x =\"New x name\",\n       y=\"New y name\",\n       title = \"Scatter plot of x and y\")\n\n\n\n\n\n\n\n\nDans la fonction labs(), on peut aussi définir un sous-titre, une note de bas de page\n\nggplot(df, aes(x=x, y=y))+\n  geom_point()+\n  labs(x =\"New x name\",\n       y=\"New y name\",\n       title = \"My graph\",\n       subtitle = \"Scatter plot of x and y\",\n       caption = \"Source: R simulations\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Initiation Graphiques</span>"
    ]
  },
  {
    "objectID": "2.InitiationGraphiques.html#facets",
    "href": "2.InitiationGraphiques.html#facets",
    "title": "4  Initiation Graphiques",
    "section": "4.4 Facets",
    "text": "4.4 Facets\nPlutôt que de colorer par modalité, on peut parfois préférer faire un graphique par modalité d’une variable catégorielle. Pour cela, on utilise les fonctions facet_wrap() ou facet_grid()\n\nggplot(df, aes(x,y))+\n  geom_point(col = \"lightblue\")+\n  facet_wrap(~organ)\n\n\n\n\n\n\n\n\n\nggplot(df, aes(x,y))+\n  geom_point(col = \"lightblue\")+\n  facet_grid(~organ)\n\n\n\n\n\n\n\n\non peut aussi utiliser ces fonctions sur deux variables catégorielles. Cependant, dans ce ca les deux fonction ne vont pas retourner le même graphique   facet_wrap() fait un graphique par combinaison des modalités des deux variables\n\nggplot(df, aes(x,y))+\n  geom_point(col = \"lightblue\")+\n  facet_wrap(status~organ)\n\n\n\n\n\n\n\n\nfacet_grid() fait aussi un graphique par combinaison des modalités des deux variables, mais de façon plus organisée. En mettant les noms de la première variables à l’horizontale et ceux de la deuxième à la verticale\n\nggplot(df, aes(x,y))+\n  geom_point(col = \"lightblue\")+\n  facet_grid(status~organ)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Initiation Graphiques</span>"
    ]
  },
  {
    "objectID": "2.InitiationGraphiques.html#télécharger-un-graphique",
    "href": "2.InitiationGraphiques.html#télécharger-un-graphique",
    "title": "4  Initiation Graphiques",
    "section": "4.5 Télécharger un graphique",
    "text": "4.5 Télécharger un graphique\nPour télécharger le dernier graphique que l’on a exécuté on peut utiliser la fonction ggsave()\n\nggsave(\"RESULTS/plotS4.1.png\")\n\nSaving 7 x 5 in image\n\n\nPour télécharger un autre graphique, il faut le nommer puis y faire référence avec l’argument plot =  dans ggsave()\n\np &lt;- ggplot(df, aes(x, y, col = z))+\n  geom_point()+\n  scale_colour_gradientn(colours = c(\"darkred\", \"orange\", \"yellow\", \"white\"))\n\nggsave(\"RESULTS/plotS4.2.png\", plot = p)\n\nSaving 7 x 5 in image\n\n\nOn peut spécifier la taille de l’image avec les arguments width et height\n\nggsave(\"RESULTS/plotS4.3.png\", plot = p, width = 4000, height = 2800, units = \"px\")\n\nOn peut également le télécharger au format pdf, en changeant l’extansion du nom de fichier\n\nggsave(\"RESULTS/plotS4.3.pdf\", plot = p, width = 4000, height = 2800, units = \"px\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Initiation Graphiques</span>"
    ]
  },
  {
    "objectID": "2.InitiationGraphiques.html#ressources",
    "href": "2.InitiationGraphiques.html#ressources",
    "title": "4  Initiation Graphiques",
    "section": "4.6 Ressources",
    "text": "4.6 Ressources\nLes sites Datanovia et STHDA sont très bien faits et très complets pour tout ce qui concernent les graphiques en R  http://www.sthda.com/  https://www.datanovia.com/",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Initiation Graphiques</span>"
    ]
  },
  {
    "objectID": "3.PersonalisationGraphiques.html",
    "href": "3.PersonalisationGraphiques.html",
    "title": "5  Personnalisation graphiques avec ggplot2",
    "section": "",
    "text": "5.1 Personnalisation des axes\nNous allons partir d’un exemple de nuage de points et effectuer plusieurs étapes de personnalisation\nChanger le nom des axes avec xlab et ylab\nggplot(df, aes(x=TIME_PERIOD, y=OBS_VALUE))+\n  geom_point() + \n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")\nSpécifier la graduation des axes avec scale_x et scale_y\nggplot(df, aes(x=TIME_PERIOD, y=OBS_VALUE))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))\nSi la variable de l’axe des x est catégorielle, on utilise scale_x_discrete au lieu de scale_x_continuous\nPivoter les labels de l’axe des x avec theme et l’option angle dans axis.text.x\nggplot(df, aes(x=TIME_PERIOD, y=OBS_VALUE))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme(axis.text.x = element_text(angle = 30))\nChanger la taille de police du nom des axes dans axis.title\nggplot(df, aes(x=TIME_PERIOD, y=OBS_VALUE))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme(axis.text.x = element_text(angle = 30),\n        axis.title = element_text(size = 14))\nChanger la taille de police des labels\nggplot(df, aes(x=TIME_PERIOD, y=OBS_VALUE))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme(axis.text.x = element_text(angle = 30, size = 12),\n        axis.text.y = element_text(size = 13),\n        axis.title = element_text(size = 14))\nPour plus de détails sur la personnalisation des axes :  http://www.sthda.com/english/wiki/ggplot2-axis-ticks-a-guide-to-customize-tick-marks-and-labels en anglais  ou https://www.datanovia.com/en/fr/blog/ggplot-graduations-des-axes-definir-et-pivoter-les-textes/ en français",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Personnalisation graphiques avec ggplot2</span>"
    ]
  },
  {
    "objectID": "3.PersonalisationGraphiques.html#changer-le-fond-du-graphiques",
    "href": "3.PersonalisationGraphiques.html#changer-le-fond-du-graphiques",
    "title": "5  Personnalisation graphiques avec ggplot2",
    "section": "5.2 Changer le fond du graphiques",
    "text": "5.2 Changer le fond du graphiques\nOn peut changer le fond des graphiques en appliquant des themes. Il y en a des prédéfinis, mais il est aussi possible de tout faire manuellement   theme_classique ne laisse qu’un fond bland\n\nggplot(df, aes(x=TIME_PERIOD, y=OBS_VALUE))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_classic()+ # ATTENTION, il faut placer cette fonction avant theme() sinon elle annule ce qui est mis dans theme()\n  theme(axis.text.x = element_text(angle = 30, size = 12),\n        axis.text.y = element_text(size = 13),\n        axis.title = element_text(size = 14))\n\n\n\n\n\n\n\n\ntheme_bw change l’arrière plan gris en blanc\n\nggplot(df, aes(x=TIME_PERIOD, y=OBS_VALUE))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw()+ # ATTENTION, il faut placer cette fonction avant theme() sinon elle annule ce qui est mis dans theme()\n  theme(axis.text.x = element_text(angle = 30, size = 12),\n        axis.text.y = element_text(size = 13),\n        axis.title = element_text(size = 14))\n\n\n\n\n\n\n\n\nIl y a d’autres themes à essayer. On peut nous mêmes définir les caractéristiques de l’arrière plan en utilisant des arguments qui commence par “panel” dans la fonction theme()\n\nggplot(df, aes(x=TIME_PERIOD, y=OBS_VALUE))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme(axis.text.x = element_text(angle = 30, size = 12),\n        axis.text.y = element_text(size = 13),\n        axis.title = element_text(size = 14),\n        panel.background = element_rect(fill = \"white\", colour = \"red\", linetype = \"solid\"), # Fond blanc mais avec le cadre rouge autour\n        panel.grid.minor.y = element_blank(), # ne laisse que les graduations qui ont un label (supprime la graduation intermédiaire) pour l'axe des y\n        panel.grid.major = element_line(colour = \"grey\", linewidth = 1), # Graduations principales des deux axes en gris et assez grosses\n        panel.grid.minor.x = element_line(colour = \"lightblue\", linewidth = 0.5) # Graduations intermédiaires de l'axe x en bleu clair et fines\n        )  \n\n\n\n\n\n\n\n\nPour plus de détail sur les thèmes prédéfinis et les options de la fonction theme() : http://www.sthda.com/english/wiki/ggplot2-themes-and-background-colors-the-3-elements",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Personnalisation graphiques avec ggplot2</span>"
    ]
  },
  {
    "objectID": "3.PersonalisationGraphiques.html#colorer-en-fonction-dune-variable",
    "href": "3.PersonalisationGraphiques.html#colorer-en-fonction-dune-variable",
    "title": "5  Personnalisation graphiques avec ggplot2",
    "section": "5.3 Colorer en fonction d’une variable",
    "text": "5.3 Colorer en fonction d’une variable\nOn colore les points par pays\n\nggplot(df, aes(x=TIME_PERIOD, y=OBS_VALUE, col = geo))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw() \n\n\n\n\n\n\n\n\nPour plus de lisibilité on ne va garder que la France, le Danemark, l’Italie et l’Albanie\n\ndf1 &lt;- df %&gt;% \n  filter(geo %in% c(\"FR\", \"DK\", \"IT\", \"AL\" ))\n\n\nggplot(df1, aes(x=TIME_PERIOD, y=OBS_VALUE, col = geo))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw() \n\n\n\n\n\n\n\n\nSpécifier soi-même les couleurs\n\nggplot(df1, aes(x=TIME_PERIOD, y=OBS_VALUE, col = geo))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw()+\n  scale_color_manual(values = c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"firebrick\"))\n\n\n\n\n\n\n\n\nPour plus d’information sur la spécification des couleurs : http://www.sthda.com/english/wiki/ggplot2-colors-how-to-change-colors-automatically-and-manually",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Personnalisation graphiques avec ggplot2</span>"
    ]
  },
  {
    "objectID": "3.PersonalisationGraphiques.html#modifier-la-légende",
    "href": "3.PersonalisationGraphiques.html#modifier-la-légende",
    "title": "5  Personnalisation graphiques avec ggplot2",
    "section": "5.4 Modifier la légende",
    "text": "5.4 Modifier la légende\nChanger le titre de la légende\n\nggplot(df1, aes(x=TIME_PERIOD, y=OBS_VALUE, col = geo))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw()+\n  scale_color_manual(values = c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"firebrick\"))+\n  labs(col = \"Pays\")\n\n\n\n\n\n\n\n\nAugmenter la taille des points de couleur dans la légende\n\nggplot(df1, aes(x=TIME_PERIOD, y=OBS_VALUE, col = geo))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw()+\n  scale_color_manual(values = c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"firebrick\"))+\n  labs(col = \"Pays\")+\n  guides(colour = guide_legend(override.aes = list(size=5)))\n\n\n\n\n\n\n\n\nChanger la taille de police et la couleur de l’écriture de la légende\n\nggplot(df1, aes(x=TIME_PERIOD, y=OBS_VALUE, col = geo))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw()+\n  scale_color_manual(values = c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"firebrick\"))+\n  labs(col = \"Pays\")+\n  guides(colour = guide_legend(override.aes = list(size=5)))+\n  theme(legend.title = element_text(size = 13, color = \"purple\"),\n        legend.text = element_text(size = 10))\n\n\n\n\n\n\n\n\nChanger les noms des modalités dans la légende\n\nggplot(df1, aes(x=TIME_PERIOD, y=OBS_VALUE, col = geo))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw()+\n  scale_color_manual(values = c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"firebrick\"),\n                     labels = c(\"AL\" = \"Albanie\",\n                                \"DK\" = \"Danemark\",\n                                \"FR\" = \"France\",\n                                \"IT\" = \"Italie\"))+\n  labs(col = \"Pays\")+\n  guides(colour = guide_legend(override.aes = list(size=5)))+\n  theme(legend.title = element_text(size = 13, color = \"darkblue\"),\n        legend.text = element_text(size = 10))\n\n\n\n\n\n\n\n\nPour plus d’informations sur la personnalisation de la légende : https://www.datanovia.com/en/blog/ggplot-legend-title-position-and-labels/",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Personnalisation graphiques avec ggplot2</span>"
    ]
  },
  {
    "objectID": "3.PersonalisationGraphiques.html#forme-en-fonction-dune-variable",
    "href": "3.PersonalisationGraphiques.html#forme-en-fonction-dune-variable",
    "title": "5  Personnalisation graphiques avec ggplot2",
    "section": "5.5 Forme en fonction d’une variable",
    "text": "5.5 Forme en fonction d’une variable\nForme du point en fonction de la variable SEX avec shape\n\nggplot(df1, aes(x=TIME_PERIOD, y=OBS_VALUE, col = geo, shape = sex))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw()+\n  scale_color_manual(values = c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"firebrick\"))\n\n\n\n\n\n\n\n\nChanger le titre des légende et la taille des points\n\nggplot(df1, aes(x=TIME_PERIOD, y=OBS_VALUE, col = geo, shape = sex))+\n  geom_point(size = 3)+ # Augmenter la taille des points sur le graphique\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw()+\n  scale_color_manual(values = c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"firebrick\"))+\n  labs(col = \"Pays\", shape = \"Sexe\")+ # Titres dans la légende\n  guides(colour = guide_legend(override.aes = list(size=4)),  \n         shape = guide_legend(override.aes = list(size=4))) # Augmenter la taille des points dans la légende\n\n\n\n\n\n\n\n\nChanger l’ordre des variables dans la légende avec order\n\nggplot(df1, aes(x=TIME_PERIOD, y=OBS_VALUE, col = geo, shape = sex))+\n  geom_point(size = 3)+ \n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw()+\n  scale_color_manual(values = c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"firebrick\"))+\n  labs(col = \"Pays\", shape = \"Sexe\")+\n  guides(colour = guide_legend(override.aes = list(size=4), order = 2),  \n         shape = guide_legend(override.aes = list(size=4), order = 1))\n\n\n\n\n\n\n\n\nAfficher la légende des deux variables côte à côte avec legend.box\n\nggplot(df1, aes(x=TIME_PERIOD, y=OBS_VALUE, col = geo, shape = sex))+\n  geom_point(size = 3)+ \n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw()+\n  scale_color_manual(values = c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"firebrick\"))+\n  labs(col = \"Pays\", shape = \"Sexe\")+\n  guides(colour = guide_legend(override.aes = list(size=4), order = 2),  \n         shape = guide_legend(override.aes = list(size=4), order = 1))+\n  theme(legend.box = \"horizontal\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Personnalisation graphiques avec ggplot2</span>"
    ]
  },
  {
    "objectID": "3.PersonalisationGraphiques.html#un-graphique-par-modalité-de-variable-avec-facet_wrap",
    "href": "3.PersonalisationGraphiques.html#un-graphique-par-modalité-de-variable-avec-facet_wrap",
    "title": "5  Personnalisation graphiques avec ggplot2",
    "section": "5.6 Un graphique par modalité de variable avec facet_wrap()",
    "text": "5.6 Un graphique par modalité de variable avec facet_wrap()\nOn fait un graphique par sexe\n\nggplot(df1, aes(x=TIME_PERIOD, y=OBS_VALUE, col = geo))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw()+\n  scale_color_manual(values = c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"firebrick\"))+\n  facet_wrap(~sex)\n\n\n\n\n\n\n\n\nChanger le nom des modalités de la variable utilisée pour facet_wrap avec labeller\n\n# On doit définir préalablement les nouveaux labels\nsex.labs &lt;- c(\"Females\", \"Males\", \"Total population\")\nnames(sex.labs) &lt;- c(\"F\", \"M\", \"T\") # et leur attribuer en nom la modalité d'origine\n\nggplot(df1, aes(x=TIME_PERIOD, y=OBS_VALUE, col = geo))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw()+\n  scale_color_manual(values = c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"firebrick\"))+\n  facet_wrap(~sex,\n             labeller = labeller(sex = sex.labs)) # On renomme les modalités de sex par sex.labs\n\n\n\n\n\n\n\n\nChanger la couleur de l’arrière plan des labels\n\n# Pour relabel \nsex.labs &lt;- c(\"Females\", \"Males\", \"Total population\")\nnames(sex.labs) &lt;- c(\"F\", \"M\", \"T\") \n\nggplot(df1, aes(x=TIME_PERIOD, y=OBS_VALUE, col = geo))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw()+\n  scale_color_manual(values = c(\"#999999\", \"#E69F00\", \"#56B4E9\", \"firebrick\"))+\n  facet_wrap(~sex,\n             labeller = labeller(sex = sex.labs))+\n  theme(strip.background = element_rect(fill = \"lightblue\")) # Arrière plan des labels\n\n\n\n\n\n\n\n\nOn peut faire une forme par pays et une couleur par sexe en combinant shape et col\n\n# Pour relabel \nsex.labs &lt;- c(\"Females\", \"Males\", \"Total population\")\nnames(sex.labs) &lt;- c(\"F\", \"M\", \"T\") \n\nggplot(df1, aes(x=TIME_PERIOD, y=OBS_VALUE, shape = geo, col = sex))+\n  geom_point()+\n  xlab(\"Year\") +\n  ylab(\"Life expectancy at 65 (years)\")+\n  scale_x_continuous(breaks = seq(2010, 2021, 2))+\n  scale_y_continuous(limits = c(10,25))+\n  theme_bw()+\n  scale_color_manual(values = c( \"#E69F00\", \"#56B4E9\", \"firebrick\"))+\n  facet_wrap(~sex,\n             labeller = labeller(sex = sex.labs))+\n  theme(strip.background = element_rect(fill = \"grey\"))\n\n\n\n\n\n\n\n\nPour plus de détails sur la personnalisation des facets :  http://www.sthda.com/french/wiki/ggplot2-facet-diviser-un-graphique-en-plusieurs-panneaux-logiciel-r-et-visualisation-de-donnees  https://www.datanovia.com/en/blog/how-to-change-ggplot-facet-labels/",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Personnalisation graphiques avec ggplot2</span>"
    ]
  },
  {
    "objectID": "3.PersonalisationGraphiques.html#ressources",
    "href": "3.PersonalisationGraphiques.html#ressources",
    "title": "5  Personnalisation graphiques avec ggplot2",
    "section": "5.7 Ressources",
    "text": "5.7 Ressources\nD’une façon générale, les sites Datanovia et STHDA sont très bien faits et très complets pour tout ce qui concerne les graphiques avec R",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Personnalisation graphiques avec ggplot2</span>"
    ]
  },
  {
    "objectID": "4.PremieresAnalyses.sur.R.html",
    "href": "4.PremieresAnalyses.sur.R.html",
    "title": "6  Analyses Bivariées",
    "section": "",
    "text": "6.1 Simulation d’un jeu de données\nset.seed(15344250) # Toujours reproduire les mêmes simulations\nn &lt;- 5000\nid &lt;- 1:n\nx1 &lt;- rnorm(n, 50, 20) # simulation d'une loi normale de moyenne 50 et d'écart-type 20\nx2 &lt;- rnorm(n, 0,1) # simulation d'une loi normale centrée réduite\nz1 &lt;- rnorm(n, x1, 10) # simulation d'une loi normale de moyenne x et d'écart-type 10\nz2 &lt;- exp(x2) # z2 est égal à l'exponentielle de x2\ny &lt;- runif(n, min = 20, max = 80) # simulation d'une loi uniforme entre 20 et 80\n\nstatus &lt;- rbinom(n, size = 1, prob = 0.3) # Simulation d'une loi binomiale de taille n avec proba 0.5\n\ncat &lt;- sample(c(\"Lung\", \"Liver\", \"Kidney\"), n, prob = c(0.4, 0.1, 0.5), replace = T) # Tirage d'une vecteur aléatoire de taille n qui prend ses valeurs parmi \"Lung\" \"Liver\" et \"Kidney\"\nContinent &lt;- sample(c(\"Africa\", \"North America\", \"South America\", \"Asia\", \"Europe\", \"Oceania\"), n, replace = T)\n\n\ndf &lt;- data.frame(\"id\" = id,\n                 \"x1\" = x1,\n                 \"x2\" = x2,\n                 \"y\" = y,\n                 \"z1\" = z1,\n                 \"z2\" = z2,\n                 \"status\" = status,\n                 \"organ\" = cat,\n                 \"continent\" = Continent)\n\ndf &lt;- mutate(df, status = as.factor(status))\n\ndf$pH &lt;- with(df, ifelse(organ == \"Lung\", rnorm(n, mean = 6.7, sd =0.6),\n                              ifelse(organ == \"Liver\", rnorm(n, mean = 7.2, sd = 0.3),\n                                     rnorm(n, mean = 7, sd = 0.8))))",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Analyses Bivariées</span>"
    ]
  },
  {
    "objectID": "4.PremieresAnalyses.sur.R.html#analyse-de-corrélation-entre-2-variables",
    "href": "4.PremieresAnalyses.sur.R.html#analyse-de-corrélation-entre-2-variables",
    "title": "6  Analyses Bivariées",
    "section": "6.2 Analyse de corrélation entre 2 variables",
    "text": "6.2 Analyse de corrélation entre 2 variables\n\n6.2.1 Deux variables quantitatives\nJe vais utiliser les vecteurs x1, x2, y et z1 et z2. On s’attend à ce que les vecteurs x1 et y ainsi que les vecteurs x1 et x2 ne soient pas corrélés mais que les vecteurs x1 et z1 et les vecteurs x2 et z2 le soient   Le calcul d’un coefficient de corrélation dans R se fait avec la fonction cor() dans laquelle on précise quel coefficient l’on souhaite via l’argument method\n\n\n6.2.2 Travail préalable\nAvant de commencer, on peut tracer des graphiques pour visualiser la distribution de chaque variable, ainsi que la relation entre les deux variables à étudier.\nDistribution des variables\n\nggplot(df, aes(x1))+\n  geom_histogram(aes(y=after_stat(density)))+\n  geom_density()+\n  ggtitle(\"Distribution of x1\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nggplot(df, aes(x2))+\n  geom_histogram(aes(y=after_stat(density)))+\n  geom_density()+\n  ggtitle(\"Distribution of x2\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nggplot(df, aes(y))+\n  geom_histogram(aes(y=after_stat(density)))+\n  geom_density()+\n  ggtitle(\"Distribution of y\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nggplot(df, aes(z1))+\n  geom_histogram(aes(y=after_stat(density)))+\n  geom_density()+\n  ggtitle(\"Distribution of z1\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nggplot(df, aes(z2))+\n  geom_histogram(aes(y=after_stat(density)))+\n  geom_density()+\n  ggtitle(\"Distribution of z2\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nRemarque : On peut également regarder la normalité d’une distribution en traçant un qqplot (qui permet de comparer la distribution d’un échantillon à une distribution Normale). On le fait en utilisant la fonction qqnorm() de R base ou la fonction ggqqplot() du package ggpubr\n\nqqnorm(df$x1)\n\n\n\n\n\n\n\nlibrary(ggpubr)\nggqqplot(df$x1)\n\n\n\n\n\n\n\n\nx1 a bien l’air de suivre une loi normale\n\nqqnorm(df$y)\n\n\n\n\n\n\n\n\ny n’a pas l’air de suivre une loi normale\nRemarque 2 : Si on veut tester statistiquement la normalité de la distribution, on peut utiliser le test de Shapiro-Wilk dont l’hypothèse nulle est la normalité de la distribution\n\nshapiro.test(df$x1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  df$x1\nW = 0.99961, p-value = 0.4404\n\n\n\nshapiro.test(df$y)\n\n\n    Shapiro-Wilk normality test\n\ndata:  df$y\nW = 0.95769, p-value &lt; 2.2e-16\n\n\nRelation entre les variables\n\nggplot(df, aes(x1, x2))+\n  geom_point()+\n  ggtitle(\"Relation entre x1 et x2\")\n\n\n\n\n\n\n\n\n\nggplot(df, aes(x1, y))+\n  geom_point()+\n  ggtitle(\"Relation entre x1 et y\")\n\n\n\n\n\n\n\n\n\nggplot(df, aes(x1, z1))+\n  geom_point()+\n  ggtitle(\"Relation entre x1 et z1\")\n\n\n\n\n\n\n\n\n\nggplot(df, aes(x2, z2))+\n  geom_point()+\n  ggtitle(\"Relation entre x2 et z2\")\n\n\n\n\n\n\n\n\n\nCoefficient de corrélation de Pearson\nRappel : Le coefficient de corrélation de Pearson mesure une corrélation linéaire Il prend une valeur entre -1 (corrélation linéaire parfaite négative) et 1 (corrélation linéaire parfaite positive).  Ce coefficient ne peut être utilisé que sur des variables suivant une loi normale\n\ncor(df$x1, df$x2, method = \"pearson\")\n\n[1] -0.01583424\n\n\n\ncor(df$x1, df$z1, method = \"pearson\")\n\n[1] 0.8966091\n\n\nTest de la significativité du coefficient de corrélation avec la fonction cor.test() Rappel : L’hypothèse nulle est l’indépendence entre les deux variables \n\ncor.test(df$x1, df$x2, method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  df$x1 and df$x2\nt = -1.1196, df = 4998, p-value = 0.263\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.04353443  0.01189027\nsample estimates:\n        cor \n-0.01583424 \n\n\nOn ne rejette pas \\(H_0\\)\n\ncor.test(df$x1, df$z1, method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  df$x1 and df$z1\nt = 143.14, df = 4998, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8910350 0.9019128\nsample estimates:\n      cor \n0.8966091 \n\n\nOn rejette \\(H_0\\)   Cette fonction calcule directement le coefficient de corrélation et le test de significativité\n\n\nCoefficient de corrélation de Spearman\nRappel : Le coefficient de Spearman est l’équivalent non paramétrique du coefficient de Pearson, il est utilisé lorsque les variable ne suivent pas une distribution normale ou lorsque la relation entre les deux variables n’est pas linéaire (mais tout de même monotone)  Il s’agit d’une statistique de rang : pour la calculer on regarde les rangs associés aux deux variables et non leurs valeurs \n Dans notre exemple, ce coefficient est donc adapté pour étudier la corrélation entre x1 et y et entre X2 et Z2.\n\ncor(df$x1, df$y, method = \"spearman\")\n\n[1] 0.004370197\n\n\n\ncor(df$x2, df$z2, method = \"spearman\")\n\n[1] 1\n\n\nRemarque : on n’obtient pas à la même chose avec le coefficient de Pearson\n\ncor(df$x2, df$z2, method = \"pearson\")\n\n[1] 0.7712232\n\n\nDe même, pour étudier la significativité du coefficient dans notre échantillon, on utilise la fonction cor.test() en précisant method=“spearman”  L’hypothèse nulle du test est l’indépendence entre les deux variables\n\ncor.test(df$x1, df$y, method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  df$x1 and df$y\nS = 2.0742e+10, p-value = 0.7574\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n        rho \n0.004370197 \n\n\nOn ne rejette pas \\(H_0\\)\n\ncor.test(df$x2, df$z2, method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  df$x2 and df$z2\nS = 2.313e-06, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\nrho \n  1 \n\n\nOn rejette \\(H_0\\)\n\n\nTau de Kendall\nRappel :  Relativement similaire au coefficient de Spearman. Le tau de Kendall est à préférer dans des petits échantillons ou lorsqu’il y a beaucoup d’égalités de rangs\n\ncor(df$x1, df$y, method = \"kendall\")\n\n[1] 0.00289946\n\n\n\ncor(df$x2, df$z2, method = \"kendall\")\n\n[1] 1\n\n\nDe même, pour étudier la significativité du coefficient dans notre échantillon, on utilise la fonction cor.test() en précisant method=“spearman”. L’hypothèse nulle est toujours l’indépendance entre les deux variables.\n\ncor.test(df$x1, df$y, method = \"kendall\")\n\n\n    Kendall's rank correlation tau\n\ndata:  df$x1 and df$y\nz = 0.30743, p-value = 0.7585\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n       tau \n0.00289946 \n\n\nOn ne rejette pas \\(H_0\\)\n\ncor.test(df$x2, df$z2, method = \"kendall\")\n\n\n    Kendall's rank correlation tau\n\ndata:  df$x2 and df$z2\nz = 106.03, p-value &lt; 2.2e-16\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\ntau \n  1 \n\n\nOn rejette \\(H_0\\)\n\n\n\n6.2.3 Deux variables catégorielles\n\nTest du chi-2 d’indépendance\nPour étudier la corrélation entre deux variables qualitatives on utilise en général le test du chi-2  Attention : ce test ne fonctionne que pour des échantillons indépendants (non-appariés)   Avant de commencer, on peut faire un tableau de contingence avec la fonction table()\n\ntable(df$status, df$organ)\n\n   \n    Kidney Liver Lung\n  0   1737   349 1377\n  1    722   146  669\n\n\n\ntable(df$organ, df$continent)\n\n        \n         Africa Asia Europe North America Oceania South America\n  Kidney    411  431    375           447     403           392\n  Liver      73   81     83            79      96            83\n  Lung      380  307    345           341     323           350\n\n\nRappel l’hypothèse nulle du test du chi-2 est l’indépendence entre les deux variables  La fonction pour realiser le test du chi-2 est chisq.test()\n\nchisq.test(df$status, df$organ)\n\n\n    Pearson's Chi-squared test\n\ndata:  df$status and df$organ\nX-squared = 6.2391, df = 2, p-value = 0.04418\n\n\nAu seuil de 5% on rejette \\(H_0\\), mais au seuil de 1% on ne la rejette pas\n\nchisq.test(df$organ, df$continent)\n\n\n    Pearson's Chi-squared test\n\ndata:  df$organ and df$continent\nX-squared = 16.769, df = 10, p-value = 0.07964\n\n\nRemarque : Pour povoir réaliser un test du chi-2, il faut que les effectifs théoriques de chaque combinaisons de modalité soient supérieurs à 5. Si ce n’est pas le cas, il devrait y avoir un warning à l’exécution de la fonction “Chi-squared approximation may be incorrect”.   Il est possible de visualiser le tableau des effectifs théoriques en accédant à la données expected du test\n\nchisq.test(df$status, df$organ)$expected\n\n         df$organ\ndf$status    Kidney   Liver      Lung\n        0 1703.1034 342.837 1417.0596\n        1  755.8966 152.163  628.9404\n\n\nPlot avec test du chi-2\n\nlibrary(vcd)\n\nLoading required package: grid\n\nmosaic(~ status + organ,\n  direction = c(\"v\", \"h\"),\n  data = df,\n  shade = TRUE\n)\n\n\n\n\n\n\n\n\nRemarque : ici tout est gris car les effectifs ne dévient pas trop des effectifs théoriques. Quand les effectifs observés sont plus petits que les théoriques les barres sont colorées en rouge et quand ils sont plus grands en bleu\n\n\nTest exact de Fisher\nS’il y a un effectif théorique inférieur à 5, on peut soit regrouper des catégories pour n’avoir que des effectifs supérieurs à 5, soit utiliser un test exact de Fisher qui ne nécéssite pas cette hypothèse.   En R, ce test s’effectue avec la fonction fisher.test()\n\nfisher.test(df$status, df$organ)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  df$status and df$organ\np-value = 0.04505\nalternative hypothesis: two.sided\n\n\n\n\n\n6.2.4 Une v=Variable Quantitave et Une Variable Qualitative\n\nl’ANOVA (ANalysis Of VAriance)\nOn utilise l’ANOVA lorsque l’on souhaite expliquer une variable quantitative par une variable qualitative.\nDans notre exemple, on veut regarder si l’organe a une influence sur la variable x1.\n\nggplot(df, aes(x=organ, y=pH))+ geom_boxplot()\n\n\n\n\n\n\n\n\n\nRappel :\nOn note \\(Y_{i,k}\\) la variable aléatoire qui modélise la pH du \\(k-ième\\) individu pour l’organe \\(i\\).\nLe modèle de l’ANOVA s’écrit :\n\\[\nY_{i,k} = \\mu + \\alpha_i + E_{i,k}\n\\]\nAvec\noù \\(\\mu\\) décrit l’effet moyen et \\(\\alpha_i\\) represente l’effet du à la modalité i.\nUne anova à 1 facteur est donc une regression lineaire particulière.\n\nDans R :\nPremière methode : la commande lm\nLa commande à executer est la suivant :\n\\[\n\\text{lm}(\\text{Variable quantitative} \\sim \\text{Variable qualitative}, \\text{ data} = \\text{dataset} )\n\\]\n\n###---Methode lm---###\nMod.Anova &lt;- lm(pH ~organ, data = df)\nsummary(Mod.Anova)\n\n\nCall:\nlm(formula = pH ~ organ, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9381 -0.4234  0.0023  0.4366  3.1688 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  7.05267    0.01393 506.337  &lt; 2e-16 ***\norganLiver   0.14226    0.03403   4.181 2.95e-05 ***\norganLung   -0.35743    0.02067 -17.294  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6907 on 4997 degrees of freedom\nMultiple R-squared:  0.07167,   Adjusted R-squared:  0.0713 \nF-statistic: 192.9 on 2 and 4997 DF,  p-value: &lt; 2.2e-16\n\n\nPuis, la commande lm permet de créer une table de variance\n\nanova(Mod.Anova)\n\nAnalysis of Variance Table\n\nResponse: pH\n            Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \norgan        2  184.06  92.028   192.9 &lt; 2.2e-16 ***\nResiduals 4997 2383.94   0.477                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDeuxième méthode : la commande aov\n\naov.pH &lt;- aov(pH~organ, data=df)\nsummary(aov.pH)\n\n              Df Sum Sq Mean Sq F value Pr(&gt;F)    \norgan          2  184.1   92.03   192.9 &lt;2e-16 ***\nResiduals   4997 2383.9    0.48                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAttention :  Il faut verifer les hypothèses du modèle avant d’interpreter les résultats.\nInterprétation\n\nanova(Mod.Anova)\n\nAnalysis of Variance Table\n\nResponse: pH\n            Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \norgan        2  184.06  92.028   192.9 &lt; 2.2e-16 ***\nResiduals 4997 2383.94   0.477                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOn lit la p-value dans la colonne Pr(&gt;F), ici \\(p-value = 2.2e-16\\). Donc \\(p&lt;0.05\\), On rejette l’hypothèse que les moyennes des groupes sont toutes égales et on conclue qu’il y a une difference significative.\nVérification des hypothèses\n\nresidus &lt;- residuals(Mod.Anova)\nshapiro.test(residus)\n\n\n    Shapiro-Wilk normality test\n\ndata:  residus\nW = 0.99689, p-value = 1.129e-08\n\nqqnorm(residus)\nqqline(residus, col = \"red\")\n\n\n\n\n\n\n\n\nl’hypothèse de normalité des résidus est rejetée et l’Anova n’est pas adaptée ici.\n\n\nTest de Kruskal-wallis\nLorsque les conditions de l’anova ne sont pas remplies (non-normalité notamment), on peut utiliser un test non paramétrique de Kruskal-Wallis.\n\ntest &lt;- kruskal.test(pH ~ organ, data = df)\ntest\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  pH by organ\nKruskal-Wallis chi-squared = 426.36, df = 2, p-value &lt; 2.2e-16\n\n\nOn lit la p-value dans la colonne Pr(&gt;F), ici \\(p-value = 2.2e-16\\). Donc \\(p&lt;0.05\\), On rejette l’hypothèse que les moyennes des groupes sont toutes égales et on conclue qu’il y a une difference significative.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Analyses Bivariées</span>"
    ]
  },
  {
    "objectID": "4.PremieresAnalyses.sur.R.html#comparaison-de-deux-populations",
    "href": "4.PremieresAnalyses.sur.R.html#comparaison-de-deux-populations",
    "title": "6  Analyses Bivariées",
    "section": "6.3 Comparaison de deux populations",
    "text": "6.3 Comparaison de deux populations\n\n6.3.1 Comparaison de la moyenne de deux populations\n\nTest de Student\nPour comparer la moyenne de deux populations le test le plus utilisé est celui de Student ou t-test. Si les deux échantillons sont appariés, i.e. proviennent des mêmes individus, on utilise un test de Student apparié, sinon un test de Student simple.   L’hypothèse nulle de ce test est l’égalité des moyennes et lhypothèse alternative la non-égalité.    Attention :  Le test de Student ne peut-être utilisé que lorsque les deux échantillons suivent une loi normale. Pour tester la normalité se référer à la partie sur l’analyse de la corrélation entre deux variables quantitatives   pour ce test, il faut également vérifier l’égalité des variances dans les deux échantillons.  \n\nVérification des hypothèses\nPour vérifié la normalité, on peut regardé les qqplot ou le test de Shapiro comme vu précédemment.   Si les données sont normalement distribuées, on peut réaliser un test d’égalité des variances (test de Fisher) avec la fonction var.test()\n\nvar.test(df$x1, df$x2)\n\n\n    F test to compare two variances\n\ndata:  df$x1 and df$x2\nF = 419.7, num df = 4999, denom df = 4999, p-value &lt; 2.2e-16\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 397.0596 443.6263\nsample estimates:\nratio of variances \n          419.6976 \n\n\nIci on rejette l’hypothèse d’égalité. On ne devrait donc pas réaliser un test de Student.\n\n\nRéalisation du test de Student\nRemarque : Je réalise ici un test de Student entre x1 et x2 à titre d’exemple, mais en pratique je ne devrais pas le faire car il y a violation de l’hypothèse d’égalité des variances  \nEn R, ce test est réalisé par la fonction t.test().  Attention : PAr défaut la fonction t.test() réalise un test de Welch qui ne suppose pas l’égalité des variance (voir prochaine section) et est donc plus ‘prudent’. Pour forcer un test de Student, il faut préciser l’argument var.equal=T   Pour réalisé un test apparié, on précise l’argument paired = T\n\nt.test(df$x1, df$x2, var.equal = T)\n\n\n    Two Sample t-test\n\ndata:  df$x1 and df$x2\nt = 175.99, df = 9998, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 49.64996 50.76844\nsample estimates:\n  mean of x   mean of y \n50.22089115  0.01168916 \n\n\nIci on rejette l’hypothèse nulle : les moyennes des deux échantillons diffèrent  \nSi on suppose que dans mon tableau df, chaque ligne correspond à un individu, alors pour chaque ligne, les valeurs de x1 et x2 ont été mesurées sur un même individu. Les échantillons x1 et x2 sont doc apparié et il convient de le prendre en compte dans le test en réalisant un test de Student apparié\n\nt.test(df$x1, df$x2, paired = T)\n\n\n    Paired t-test\n\ndata:  df$x1 and df$x2\nt = 175.85, df = 4999, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 49.64946 50.76894\nsample estimates:\nmean difference \n        50.2092 \n\n\nDe même, H_0 est rejetée\n\n\n\nTest de Welch\nLorsque les deux échantillons suivent une loi normale mais que leurs variances diffèrent, on ne peut pas appliquer le test de Student. Le test de Welch est adapté à ce cas de figure.  Son hypothèse nulle est comme pour le test de Student, l’égalité des moyennes   Attention ! ce test ne fonctionne que dans le cas d’échantillons indépendant (non-appariés)   Pour réaliser ce test en R, on utilise comme pour le test de Student la fonction t.test(). Par défaut cette fonction réalise un test de Welch quand les échantillons sont indépendant, il n’est donc pas nécessaire de rajouter l’argument var.equal = F, mais on peut le mettre si on veut (il prend cette valeur par défaut)\n\nt.test(df$x1, df$x2)\n\n\n    Welch Two Sample t-test\n\ndata:  df$x1 and df$x2\nt = 175.99, df = 5022.8, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 49.64989 50.76851\nsample estimates:\n  mean of x   mean of y \n50.22089115  0.01168916 \n\n\n\nt.test(df$x1, df$x2, var.equal = F)\n\n\n    Welch Two Sample t-test\n\ndata:  df$x1 and df$x2\nt = 175.99, df = 5022.8, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 49.64989 50.76851\nsample estimates:\n  mean of x   mean of y \n50.22089115  0.01168916 \n\n\n\n\nTest des rangs signés de Wilcoxon\nLorsque les échantillons sont de petite taille et n’ont pas une distribution normale, le test de Wilcoxon peut être plus approprié que le test de Student pour comparer deux populations. Il s’agit d’un test non paramétrique qui comme le test de Spearman se base sur les rangs.   Nuance :  Le test de Wilcoxon ne compare pas la moyenne mais la médiane des deux échantillons  L’hypothèse nulle est l’égalité des médianes des deux échantillons   De même que pour le test de Student, il y a une version simple et une version appariée du test de Wilcoxon.  Remarque :  Le test des rangs signés de Wilcoxon (Wilcoxon rank sum test) est souvent appelé simplement test de Wilcoxon. Il est parfois aussi appelé test U de Mann-Whitney.   En R, la fonction wilcox.test() permet de réaliser ce test\n\nwilcox.test(df$x1, df$x2)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  df$x1 and df$x2\nW = 24825452, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0\n\n\nSi les mesures de x1 et x2 ont été faites sur les mêmes individus, et que chaque ligne du data-frame correspond à un individu, alors les données sont appariées et il convient de le prendre en compte dans le test en précisant l’argument paired = T\n\nwilcox.test(df$x1, df$x2, paired = T)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  df$x1 and df$x2\nV = 12499208, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Analyses Bivariées</span>"
    ]
  },
  {
    "objectID": "4.PremieresAnalyses.sur.R.html#extraire-les-données-des-tests",
    "href": "4.PremieresAnalyses.sur.R.html#extraire-les-données-des-tests",
    "title": "6  Analyses Bivariées",
    "section": "6.4 Extraire les données des tests",
    "text": "6.4 Extraire les données des tests\nSi l’on souhaite récupérer/ stockée une des données d’un test, par exemple la p-value ou la statistique de test, il est en géneral possible de les extraire directement en ajoutant \\(p.value* ou *\\)statistic   Par exemple\n\n# p-value\nwilcox.test(df$x1, df$x2)$p.value\n\n[1] 0\n\n\n\n# statistique du test de Wilcoxon entre x1 et x2\nwilcox.test(df$x1, df$x2)$statistic\n\n       W \n24825452 \n\n\n\n# p-value test de Pearson\ncor.test(df$x1, df$x2, method = \"pearson\")$p.value\n\n[1] 0.2629524",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Analyses Bivariées</span>"
    ]
  },
  {
    "objectID": "5.RegressionLineaire.html",
    "href": "5.RegressionLineaire.html",
    "title": "7  Regression Lineaire",
    "section": "",
    "text": "7.1 Import des données\nPour cette séance, nous allons utiliser le jeu de données NHANES disponible dans le package du même nom.  Il s’agit de données de santé provenant de l’enquête américaine National Health and Nutrition Examination Survey (NHANES). Il contient des données sociale, comportementales et de santé.   Une description des données est disponible dans le descriptif du package lien\nlibrary(NHANES)\ndata(\"NHANES\")\ndim(NHANES)\n\n[1] 10000    76\n\n#kable(head(NHANES))\nDans ces données il semble y avoir des doublons. Nous allons les supprimer en utilisant la fonction distinct() de dplyr. Cette fonction ne garde qu’une ligne pour un groupe de lignes qui sont absolument identiques\nNHANES &lt;- NHANES %&gt;% distinct()\ndim(NHANES)\n\n[1] 7832   76\nNous sommes passés de 10000 à 7155 observations\nRésumé des données\nsummary(NHANES)\n\n       ID           SurveyYr       Gender          Age          AgeDecade   \n Min.   :51624   2009_10:3568   female:3943   Min.   : 0.00    0-9   :1212  \n 1st Qu.:57388   2011_12:4264   male  :3889   1st Qu.:16.00    10-19 :1142  \n Median :62914                                Median :35.00    30-39 :1038  \n Mean   :62369                                Mean   :35.97    20-29 :1023  \n 3rd Qu.:67408                                3rd Qu.:54.00    40-49 :1010  \n Max.   :71915                                Max.   :80.00   (Other):2124  \n                                                              NA's   : 283  \n   AgeMonths          Race1           Race3               Education   \n Min.   :  0.0   Black   :1073   Asian   : 281   8th Grade     : 397  \n 1st Qu.:169.0   Hispanic: 538   Black   : 563   9 - 11th Grade: 712  \n Median :387.0   Mexican : 920   Hispanic: 317   High School   :1131  \n Mean   :403.1   White   :4626   Mexican : 451   Some College  :1695  \n 3rd Qu.:615.0   Other   : 675   White   :2510   College Grad  :1534  \n Max.   :959.0                   Other   : 142   NA's          :2363  \n NA's   :4271                    NA's    :3568                        \n      MaritalStatus         HHIncome     HHIncomeMid        Poverty     \n Divorced    : 516   more 99999 :1588   Min.   :  2500   Min.   :0.000  \n LivePartner : 438   75000-99999: 809   1st Qu.: 22500   1st Qu.:1.130  \n Married     :2940   25000-34999: 784   Median : 50000   Median :2.400  \n NeverMarried:1048   35000-44999: 691   Mean   : 54862   Mean   :2.664  \n Separated   : 148   45000-54999: 596   3rd Qu.: 87500   3rd Qu.:4.500  \n Widowed     : 384   (Other)    :2711   Max.   :100000   Max.   :5.000  \n NA's        :2358   NA's       : 653   NA's   :653      NA's   :578    \n   HomeRooms       HomeOwn             Work          Weight      \n Min.   : 1.000   Own  :4845   Looking   : 244   Min.   :  2.80  \n 1st Qu.: 5.000   Rent :2753   NotWorking:2290   1st Qu.: 54.35  \n Median : 6.000   Other: 184   Working   :3376   Median : 71.60  \n Mean   : 6.173   NA's :  50   NA's      :1922   Mean   : 69.67  \n 3rd Qu.: 7.000                                  3rd Qu.: 87.90  \n Max.   :13.000                                  Max.   :230.70  \n NA's   :54                                      NA's   :61      \n     Length          HeadCirc         Height           BMI       \n Min.   : 47.10   Min.   :34.20   Min.   : 83.6   Min.   :12.88  \n 1st Qu.: 75.15   1st Qu.:39.50   1st Qu.:155.8   1st Qu.:21.40  \n Median : 87.05   Median :41.30   Median :165.4   Median :25.83  \n Mean   : 84.89   Mean   :41.10   Mean   :160.9   Mean   :26.52  \n 3rd Qu.: 95.80   3rd Qu.:42.98   3rd Qu.:173.9   3rd Qu.:30.64  \n Max.   :112.20   Max.   :45.40   Max.   :200.4   Max.   :81.25  \n NA's   :7334     NA's   :7750    NA's   :317     NA's   :327    \n    BMICatUnder20yrs         BMI_WHO         Pulse           BPSysAve    \n UnderWeight:  47    12.0_18.5   :1070   Min.   : 40.00   Min.   : 76.0  \n NormWeight : 709    18.5_to_24.9:2261   1st Qu.: 66.00   1st Qu.:106.0  \n OverWeight : 180    25.0_to_29.9:2067   Median : 72.00   Median :116.0  \n Obese      : 197    30.0_plus   :2081   Mean   : 73.58   Mean   :118.1  \n NA's       :6699    NA's        : 353   3rd Qu.: 82.00   3rd Qu.:127.0  \n                                         Max.   :136.00   Max.   :226.0  \n                                         NA's   :1236     NA's   :1246   \n    BPDiaAve          BPSys1         BPDia1          BPSys2     \n Min.   :  0.00   Min.   : 72    Min.   :  0.0   Min.   : 76.0  \n 1st Qu.: 60.00   1st Qu.:106    1st Qu.: 60.0   1st Qu.:106.0  \n Median : 68.00   Median :116    Median : 68.0   Median :116.0  \n Mean   : 67.03   Mean   :119    Mean   : 67.9   Mean   :118.4  \n 3rd Qu.: 76.00   3rd Qu.:128    3rd Qu.: 76.0   3rd Qu.:128.0  \n Max.   :116.00   Max.   :232    Max.   :118.0   Max.   :226.0  \n NA's   :1246     NA's   :1497   NA's   :1497    NA's   :1404   \n     BPDia2           BPSys3          BPDia3        Testosterone    \n Min.   :  0.00   Min.   : 76.0   Min.   :  0.00   Min.   :   0.25  \n 1st Qu.: 60.00   1st Qu.:106.0   1st Qu.: 60.00   1st Qu.:  17.53  \n Median : 68.00   Median :116.0   Median : 68.00   Median :  40.69  \n Mean   : 67.19   Mean   :117.9   Mean   : 66.83   Mean   : 193.72  \n 3rd Qu.: 76.00   3rd Qu.:126.0   3rd Qu.: 76.00   3rd Qu.: 352.32  \n Max.   :118.00   Max.   :226.0   Max.   :116.00   Max.   :1795.60  \n NA's   :1404     NA's   :1400    NA's   :1400     NA's   :4354     \n   DirectChol       TotChol         UrineVol1       UrineFlow1     \n Min.   :0.390   Min.   : 1.530   Min.   :  0.0   Min.   : 0.0000  \n 1st Qu.:1.090   1st Qu.: 4.060   1st Qu.: 49.0   1st Qu.: 0.3970  \n Median :1.290   Median : 4.730   Median : 92.0   Median : 0.6820  \n Mean   :1.359   Mean   : 4.841   Mean   :117.1   Mean   : 0.9649  \n 3rd Qu.:1.580   3rd Qu.: 5.480   3rd Qu.:162.0   3rd Qu.: 1.2130  \n Max.   :4.030   Max.   :13.650   Max.   :510.0   Max.   :17.1670  \n NA's   :1296    NA's   :1296     NA's   :865     NA's   :1340     \n   UrineVol2       UrineFlow2     Diabetes     DiabetesAge        HealthGen   \n Min.   :  0.0   Min.   : 0.000   No  :7077   Min.   : 1.00   Excellent: 661  \n 1st Qu.: 50.0   1st Qu.: 0.482   Yes : 622   1st Qu.:40.00   Vgood    :1848  \n Median : 92.5   Median : 0.765   NA's: 133   Median :50.00   Good     :2272  \n Mean   :119.5   Mean   : 1.154               Mean   :49.07   Fair     : 829  \n 3rd Qu.:171.8   3rd Qu.: 1.507               3rd Qu.:60.00   Poor     : 155  \n Max.   :409.0   Max.   :13.692               Max.   :80.00   NA's     :2067  \n NA's   :6670    NA's   :6671                 NA's   :7315                    \n DaysPhysHlthBad  DaysMentHlthBad  LittleInterest   Depressed   \n Min.   : 0.000   Min.   : 0.000   None   :3837   None   :3937  \n 1st Qu.: 0.000   1st Qu.: 0.000   Several: 869   Several: 783  \n Median : 0.000   Median : 0.000   Most   : 343   Most   : 331  \n Mean   : 3.423   Mean   : 4.112   NA's   :2783   NA's   :2781  \n 3rd Qu.: 3.000   3rd Qu.: 4.000                                \n Max.   :30.000   Max.   :30.000                                \n NA's   :2074     NA's   :2072                                  \n  nPregnancies       nBabies         Age1stBaby    SleepHrsNight   \n Min.   : 1.000   Min.   : 0.000   Min.   :14.00   Min.   : 2.000  \n 1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.:19.00   1st Qu.: 6.000  \n Median : 3.000   Median : 2.000   Median :22.00   Median : 7.000  \n Mean   : 3.087   Mean   : 2.503   Mean   :22.48   Mean   : 6.904  \n 3rd Qu.: 4.000   3rd Qu.: 3.000   3rd Qu.:25.00   3rd Qu.: 8.000  \n Max.   :32.000   Max.   :12.000   Max.   :39.00   Max.   :12.000  \n NA's   :5840     NA's   :5986     NA's   :6375    NA's   :1935    \n SleepTrouble PhysActive  PhysActiveDays       TVHrsDay        CompHrsDay  \n No  :4430    No  :2853   Min.   :1.000   2_hr     :1082   0_to_1_hr:1194  \n Yes :1481    Yes :3521   1st Qu.:2.000   1_hr     : 741   0_hrs    : 953  \n NA's:1921    NA's:1458   Median :3.000   3_hr     : 727   1_hr     : 844  \n                          Mean   :3.753   0_to_1_hr: 526   2_hr     : 491  \n                          3rd Qu.:5.000   More_4_hr: 524   3_hr     : 298  \n                          Max.   :7.000   (Other)  : 528   (Other)  : 352  \n                          NA's   :4019    NA's     :3704   NA's     :3700  \n TVHrsDayChild   CompHrsDayChild Alcohol12PlusYr   AlcoholDay    \n Min.   :0.000   Min.   :0.000   No  :1087       Min.   : 1.000  \n 1st Qu.:1.000   1st Qu.:0.000   Yes :3892       1st Qu.: 1.000  \n Median :2.000   Median :1.000   NA's:2853       Median : 2.000  \n Mean   :1.979   Mean   :2.255                   Mean   : 2.947  \n 3rd Qu.:3.000   3rd Qu.:6.000                   3rd Qu.: 3.000  \n Max.   :6.000   Max.   :6.000                   Max.   :82.000  \n NA's   :7298    NA's   :7298                    NA's   :4160    \n  AlcoholYear     SmokeNow    Smoke100         Smoke100n       SmokeAge    \n Min.   :  0.00   No  :1307   No  :3055   Non-Smoker:3055   Min.   : 6.00  \n 1st Qu.:  3.00   Yes :1116   Yes :2423   Smoker    :2423   1st Qu.:15.00  \n Median : 24.00   NA's:5409   NA's:2354   NA's      :2354   Median :17.00  \n Mean   : 73.33                                             Mean   :17.75  \n 3rd Qu.:104.00                                             3rd Qu.:19.00  \n Max.   :364.00                                             Max.   :72.00  \n NA's   :3388                                               NA's   :5507   \n Marijuana   AgeFirstMarij   RegularMarij  AgeRegMarij    HardDrugs  \n No  :1573   Min.   : 1.00   No  :2679    Min.   : 5.00   No  :3547  \n Yes :2096   1st Qu.:15.00   Yes : 990    1st Qu.:15.00   Yes : 764  \n NA's:4163   Median :16.00   NA's:4163    Median :17.00   NA's:3521  \n             Mean   :17.02                Mean   :17.65              \n             3rd Qu.:18.00                3rd Qu.:19.00              \n             Max.   :48.00                Max.   :52.00              \n             NA's   :5737                 NA's   :6842               \n SexEver         SexAge      SexNumPartnLife  SexNumPartYear   SameSex    \n No  : 175   Min.   : 9.00   Min.   :   0.0   Min.   : 0.000   No  :4000  \n Yes :4137   1st Qu.:15.00   1st Qu.:   2.0   1st Qu.: 1.000   Yes : 312  \n NA's:3520   Median :17.00   Median :   5.0   Median : 1.000   NA's:3520  \n             Mean   :17.41   Mean   :  15.4   Mean   : 1.327              \n             3rd Qu.:19.00   3rd Qu.:  12.0   3rd Qu.: 1.000              \n             Max.   :50.00   Max.   :2000.0   Max.   :69.000              \n             NA's   :3699    NA's   :3552     NA's   :4172                \n      SexOrientation  PregnantNow  \n Bisexual    :  91   Yes    :  54  \n Heterosexual:3426   No     :1197  \n Homosexual  :  70   Unknown:  41  \n NA's        :4245   NA's   :6540",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regression Lineaire</span>"
    ]
  },
  {
    "objectID": "5.RegressionLineaire.html#régression-linéaire",
    "href": "5.RegressionLineaire.html#régression-linéaire",
    "title": "7  Regression Lineaire",
    "section": "7.2 Régression linéaire",
    "text": "7.2 Régression linéaire\nPour modéliser / étudier une variable continue en fonction d’une ou plusieurs autres variables, on peut réaliser une régression linéaire.   Rappel :  Les hypothèses de la régression linéaire sont :  - Linéarité de la relation entre la variable expliquée et la variable explicative  - Abscence de colinéarité des variables explicatives  - Variance constante des résidus (homoscédasticité)  - Normalité des résidus  - Indépendance des résidus  - Nullité de l’espérance des résidus (validée par construction) \n Pour réaliser une régression linéaire en R, on utilise la fonction lm(). Elle su’utilise de la façon suivante :  \\[lm(\\text{outcome_var } \\sim \\text{ } x1+x2+x3\\text{,  data} = \\text{dataset_name})\\]  Pour obtenir une sortie avec les informations principales de la régrression on utilise la fonction summary()  Par exemple, nous pouvons modéliser par une régression linéaire le lien entre l’IMC et l’âge, le sexe, l’ethnicité, le niveau d’éducation et le statut marital\n\nreg &lt;- lm(BMI ~ Gender + Age + Race1 + Education + MaritalStatus, data = NHANES)\nsummary(reg)\n\n\nCall:\nlm(formula = BMI ~ Gender + Age + Race1 + Education + MaritalStatus, \n    data = NHANES)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.567  -4.535  -1.072   3.191  52.375 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)               31.246189   0.649866  48.081  &lt; 2e-16 ***\nGendermale                -0.203258   0.182953  -1.111  0.26662    \nAge                        0.013282   0.006441   2.062  0.03923 *  \nRace1Hispanic             -1.727673   0.435659  -3.966 7.41e-05 ***\nRace1Mexican              -1.026818   0.399309  -2.571  0.01015 *  \nRace1White                -2.185602   0.278198  -7.856 4.74e-15 ***\nRace1Other                -3.984048   0.407448  -9.778  &lt; 2e-16 ***\nEducation9 - 11th Grade   -0.197181   0.430566  -0.458  0.64700    \nEducationHigh School       0.009719   0.411282   0.024  0.98115    \nEducationSome College     -0.046028   0.400777  -0.115  0.90857    \nEducationCollege Grad     -1.330056   0.408946  -3.252  0.00115 ** \nMaritalStatusLivePartner  -1.177454   0.442981  -2.658  0.00788 ** \nMaritalStatusMarried      -0.515094   0.320489  -1.607  0.10807    \nMaritalStatusNeverMarried -1.044403   0.377927  -2.764  0.00574 ** \nMaritalStatusSeparated     0.007168   0.623717   0.011  0.99083    \nMaritalStatusWidowed      -0.891085   0.469306  -1.899  0.05765 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.602 on 5400 degrees of freedom\n  (2416 observations deleted due to missingness)\nMultiple R-squared:  0.03659,   Adjusted R-squared:  0.03392 \nF-statistic: 13.67 on 15 and 5400 DF,  p-value: &lt; 2.2e-16\n\n\nOn peut exporter les coefficients dans un tableau avec la fonction tbl_regression() du package GTsummary\n\ntbl_regression(reg)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\nGender\n\n\n\n\n\n\n\n\n    female\n—\n—\n\n\n\n\n    male\n-0.20\n-0.56, 0.16\n0.3\n\n\nAge\n0.01\n0.00, 0.03\n0.039\n\n\nRace1\n\n\n\n\n\n\n\n\n    Black\n—\n—\n\n\n\n\n    Hispanic\n-1.7\n-2.6, -0.87\n&lt;0.001\n\n\n    Mexican\n-1.0\n-1.8, -0.24\n0.010\n\n\n    White\n-2.2\n-2.7, -1.6\n&lt;0.001\n\n\n    Other\n-4.0\n-4.8, -3.2\n&lt;0.001\n\n\nEducation\n\n\n\n\n\n\n\n\n    8th Grade\n—\n—\n\n\n\n\n    9 - 11th Grade\n-0.20\n-1.0, 0.65\n0.6\n\n\n    High School\n0.01\n-0.80, 0.82\n&gt;0.9\n\n\n    Some College\n-0.05\n-0.83, 0.74\n&gt;0.9\n\n\n    College Grad\n-1.3\n-2.1, -0.53\n0.001\n\n\nMaritalStatus\n\n\n\n\n\n\n\n\n    Divorced\n—\n—\n\n\n\n\n    LivePartner\n-1.2\n-2.0, -0.31\n0.008\n\n\n    Married\n-0.52\n-1.1, 0.11\n0.11\n\n\n    NeverMarried\n-1.0\n-1.8, -0.30\n0.006\n\n\n    Separated\n0.01\n-1.2, 1.2\n&gt;0.9\n\n\n    Widowed\n-0.89\n-1.8, 0.03\n0.058\n\n\n\nAbbreviation: CI = Confidence Interval\n\n\n\n\n\n\n\n\nUn avantage de cette fonction est qu’elle affiche les modalités de référence  \n\n7.2.1 Extraction des données de la régression\nPour extraire les coefficients, on utilise la commande reg$coefficients\n\nreg$coefficients\n\n              (Intercept)                Gendermale                       Age \n             31.246189483              -0.203258234               0.013282431 \n            Race1Hispanic              Race1Mexican                Race1White \n             -1.727672872              -1.026818143              -2.185601993 \n               Race1Other   Education9 - 11th Grade      EducationHigh School \n             -3.984048213              -0.197181112               0.009719181 \n    EducationSome College     EducationCollege Grad  MaritalStatusLivePartner \n             -0.046028296              -1.330055594              -1.177454414 \n     MaritalStatusMarried MaritalStatusNeverMarried    MaritalStatusSeparated \n             -0.515093942              -1.044402753               0.007168173 \n     MaritalStatusWidowed \n             -0.891084986 \n\n\nPour extraire les résidus, plusieurs options:  - utiliser la commande reg$residuals\n\nreg$residuals[1:10] # ici je n'affiche que les 10 premiers pour ne pas encombrer le document\n\n         1          3          6          7          8          9         11 \n 3.4164429  2.0820561 -0.5731473 -5.5028475 -4.6076547 -2.8323055 -4.2643776 \n        12         14         15 \n-1.8310198 -0.2502747 -3.3089004 \n\n\n\nutiliser les fonctions residuals() ou resid()\n\n\nresiduals(reg)[1:10]\n\n         1          3          6          7          8          9         11 \n 3.4164429  2.0820561 -0.5731473 -5.5028475 -4.6076547 -2.8323055 -4.2643776 \n        12         14         15 \n-1.8310198 -0.2502747 -3.3089004 \n\nresid(reg)[1:10]\n\n         1          3          6          7          8          9         11 \n 3.4164429  2.0820561 -0.5731473 -5.5028475 -4.6076547 -2.8323055 -4.2643776 \n        12         14         15 \n-1.8310198 -0.2502747 -3.3089004 \n\n\nPour extraire les valeurs prédites de chaque observation, comme pour les résidus, il y a 2 options:  - utiliser la commande reg$fitted.values\n\nreg$fitted.values[1:10]\n\n       1        3        6        7        8        9       11       12 \n28.80356 28.48794 27.81315 29.17285 28.29765 28.86231 30.48438 28.43102 \n      14       15 \n28.79027 29.14890 \n\n\n\nutiliser les fonctions fitted() ou fitted.values()\n\n\nfitted(reg)[1:10]\n\n       1        3        6        7        8        9       11       12 \n28.80356 28.48794 27.81315 29.17285 28.29765 28.86231 30.48438 28.43102 \n      14       15 \n28.79027 29.14890 \n\nfitted.values(reg)[1:10]\n\n       1        3        6        7        8        9       11       12 \n28.80356 28.48794 27.81315 29.17285 28.29765 28.86231 30.48438 28.43102 \n      14       15 \n28.79027 29.14890 \n\n\nOn peut obtenir un tableau avec le résumé des coefficients (estimation, écart-type p-value, t-test) avec la fonction tidy() du package broom. Les bornes de l’intervalle de confiance à 95% peuvent être ajoutées en utilisant l’argument conf.int=TRUE. Pour un autre niveau de confiance, on peut ajouter l’argument conf.level = 0.99\n\ntab_summary &lt;- tidy(reg, conf.int = T)\nhead(tab_summary)\n\n# A tibble: 6 × 7\n  term          estimate std.error statistic  p.value  conf.low conf.high\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    31.2      0.650       48.1  0        30.0        32.5   \n2 Gendermale     -0.203    0.183       -1.11 2.67e- 1 -0.562       0.155 \n3 Age             0.0133   0.00644      2.06 3.92e- 2  0.000656    0.0259\n4 Race1Hispanic  -1.73     0.436       -3.97 7.41e- 5 -2.58       -0.874 \n5 Race1Mexican   -1.03     0.399       -2.57 1.02e- 2 -1.81       -0.244 \n6 Race1White     -2.19     0.278       -7.86 4.74e-15 -2.73       -1.64  \n\n\n\n\n7.2.2 Données manquantes\nPar défaut, la fonction lm() supprime les observations pour lesquelless il y a une donnée manquante pour au moins une des variables du modèle.   Pour savoir combien d’observations ont été utilisées pour ajuster le modèle, on peut regarder la longueur du vecteur des résidus ou bien de celui des valeurs prédites\n\nlength(reg$residuals)\n\n[1] 5416\n\nlength(reg$fitted.values)\n\n[1] 5416\n\n\nAinsi dans cet exemple, sur les 7832 observations de notre jeu de données, seulement 5416 ont des données complètes sur les variables considérées et sont donc prises en compte pour ajuster le modèle.   La fonction na.omit() permet de ne garder que les observations qui n’ont aucune donnée manquante. Pour obtenir le tableau de données utilisé dans la régression, nous pouvons appliquer cette fonction à nos données en ne sélectionnant que les variables utilisées dans la régression\n\ndataReg &lt;- na.omit(NHANES %&gt;% select(c(BMI,  Gender , Age, Race1, Education, MaritalStatus)))\ndim(dataReg)\n\n[1] 5416    6\n\nhead(dataReg)\n\n# A tibble: 6 × 6\n    BMI Gender   Age Race1 Education      MaritalStatus\n  &lt;dbl&gt; &lt;fct&gt;  &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;        \n1  32.2 male      34 White High School    Married      \n2  30.6 female    49 White Some College   LivePartner  \n3  27.2 female    45 White College Grad   Married      \n4  23.7 male      66 White Some College   Married      \n5  23.7 male      58 White College Grad   Divorced     \n6  26.0 male      54 White 9 - 11th Grade Married      \n\n\n\n\n7.2.3 Visualisation graphique des coefficients\nPour visualiser graphiquement les coefficients de la régression, on peut réaliser un forestplot\n\n# Extraire les coefficients et les intervalles de confiance\ntab_summary &lt;- tidy(reg, conf.int = TRUE)\n\nggplot(tab_summary, aes(x = estimate, y = term)) +\n  geom_point(size = 2) +  # Ajouter les points pour les coefficients\n  geom_errorbar(aes(xmin = conf.low, xmax = conf.high), width = 0.2) +  # Ajouter les barres d'erreur pour les intervalles de confiance\n  geom_vline(xintercept = 0, col = \"red\") + # Ajout de la ligne des 0\n  labs(x = \"Coefficients\", y = \"Estimation\") +  \n  theme_minimal()  # Utiliser un thème minimaliste\n\n\n\n\n\n\n\n\nMême graphique sans l’intercept\n\ntab_summary &lt;- tidy(reg, conf.int = TRUE) %&gt;% \n  filter(term!=\"(Intercept)\")\n\nggplot(tab_summary, aes(x = estimate, y = term)) +\n  geom_point(size = 2) +  # Ajouter les points pour les coefficients\n  geom_errorbar(aes(xmin = conf.low, xmax = conf.high), width = 0.2) +  # Ajouter les barres d'erreur pour les intervalles de confiance\n  geom_vline(xintercept = 0, col = \"red\") + # Ajout de la ligne des 0\n  labs(x = \"Coefficients\", y = \"Estimation\") +  \n  theme_minimal()  # Utiliser un thème minimaliste\n\n\n\n\n\n\n\n\nLe package ggstats propose une fonction permettant d’obtenir un joli forrest plot : ggcoef_model()\n\nggstats::ggcoef_model(reg)\n\n\n\n\n\n\n\n\n*Ressource : https://larmarange.github.io/ggstats/articles/ggcoef_model.html#quick-coefficients-plot\n\n\n7.2.4 Modèles emboités\nConsidérons maintenant le même modèle de régression, auquel on ajoute la variable du revenu (HHIncomeMid). Pour ce faire on peut utiliser la fonction lm() comme précédemment en ajoutant HHIncomeMid\n\nreg2 &lt;- lm(BMI ~ Gender + Age + Race1 + Education + MaritalStatus + HHIncomeMid, data = NHANES)\nsummary(reg2)\n\n\nCall:\nlm(formula = BMI ~ Gender + Age + Race1 + Education + MaritalStatus + \n    HHIncomeMid, data = NHANES)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.174  -4.476  -1.053   3.219  51.643 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                3.196e+01  6.890e-01  46.380  &lt; 2e-16 ***\nGendermale                -1.075e-01  1.915e-01  -0.561 0.574550    \nAge                        1.035e-02  6.749e-03   1.534 0.125026    \nRace1Hispanic             -1.872e+00  4.676e-01  -4.005  6.3e-05 ***\nRace1Mexican              -1.404e+00  4.262e-01  -3.294 0.000994 ***\nRace1White                -2.373e+00  2.955e-01  -8.031  1.2e-15 ***\nRace1Other                -4.136e+00  4.338e-01  -9.535  &lt; 2e-16 ***\nEducation9 - 11th Grade   -8.220e-02  4.646e-01  -0.177 0.859585    \nEducationHigh School       1.893e-01  4.410e-01   0.429 0.667803    \nEducationSome College      2.752e-01  4.350e-01   0.633 0.526981    \nEducationCollege Grad     -9.353e-01  4.551e-01  -2.055 0.039912 *  \nMaritalStatusLivePartner  -1.045e+00  4.705e-01  -2.220 0.026470 *  \nMaritalStatusMarried      -3.412e-01  3.400e-01  -1.004 0.315645    \nMaritalStatusNeverMarried -1.110e+00  3.967e-01  -2.799 0.005141 ** \nMaritalStatusSeparated     6.782e-03  6.666e-01   0.010 0.991883    \nMaritalStatusWidowed      -9.150e-01  4.911e-01  -1.863 0.062501 .  \nHHIncomeMid               -1.257e-05  3.363e-06  -3.738 0.000188 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.598 on 4939 degrees of freedom\n  (2876 observations deleted due to missingness)\nMultiple R-squared:  0.04232,   Adjusted R-squared:  0.03922 \nF-statistic: 13.64 on 16 and 4939 DF,  p-value: &lt; 2.2e-16\n\n\nUne autre façon de faire est d’utiliser la fonction update(). Cette fonction permet d’ajouter une ou plusieurs variables à un modèle déjà ajusté.  \\[ \\text{update (objet_ancien_model,  }.\\sim. + \\text{ nouvelle_var)}\\]\n\nreg2bis &lt;- update(reg, .~.+HHIncomeMid)\nsummary(reg2bis)\n\n\nCall:\nlm(formula = BMI ~ Gender + Age + Race1 + Education + MaritalStatus + \n    HHIncomeMid, data = NHANES)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.174  -4.476  -1.053   3.219  51.643 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                3.196e+01  6.890e-01  46.380  &lt; 2e-16 ***\nGendermale                -1.075e-01  1.915e-01  -0.561 0.574550    \nAge                        1.035e-02  6.749e-03   1.534 0.125026    \nRace1Hispanic             -1.872e+00  4.676e-01  -4.005  6.3e-05 ***\nRace1Mexican              -1.404e+00  4.262e-01  -3.294 0.000994 ***\nRace1White                -2.373e+00  2.955e-01  -8.031  1.2e-15 ***\nRace1Other                -4.136e+00  4.338e-01  -9.535  &lt; 2e-16 ***\nEducation9 - 11th Grade   -8.220e-02  4.646e-01  -0.177 0.859585    \nEducationHigh School       1.893e-01  4.410e-01   0.429 0.667803    \nEducationSome College      2.752e-01  4.350e-01   0.633 0.526981    \nEducationCollege Grad     -9.353e-01  4.551e-01  -2.055 0.039912 *  \nMaritalStatusLivePartner  -1.045e+00  4.705e-01  -2.220 0.026470 *  \nMaritalStatusMarried      -3.412e-01  3.400e-01  -1.004 0.315645    \nMaritalStatusNeverMarried -1.110e+00  3.967e-01  -2.799 0.005141 ** \nMaritalStatusSeparated     6.782e-03  6.666e-01   0.010 0.991883    \nMaritalStatusWidowed      -9.150e-01  4.911e-01  -1.863 0.062501 .  \nHHIncomeMid               -1.257e-05  3.363e-06  -3.738 0.000188 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.598 on 4939 degrees of freedom\n  (2876 observations deleted due to missingness)\nMultiple R-squared:  0.04232,   Adjusted R-squared:  0.03922 \nF-statistic: 13.64 on 16 and 4939 DF,  p-value: &lt; 2.2e-16\n\n\nPour comparer deux modèles emboîtés, on peut réaliser une ANOVA.    Attention  Pour pouvoir comparer les modèles, ils doivent avoir été ajustés en utilisant les mêmes observations ! S’il y avait des données manquantes pour la nouvelle variable, le second modèle risque d’avoir été ajusté sur moins de données. Pour pouvoir comparer les modèles il faut donc réajuster la première régression sur les observations qui n’ont pas de données manquante pour HHIncomeMid  Nous allons utiliser la fonction na.omit() pour obtenir le dataset utilisé dans la deuxième régression. Nous pourrons ensuite réajuster le premier modèle sur ce nouveau dataset.\n\n# Récupérer uniquement les obseravtions utilisées pour ajuster le modèle\ndataReg &lt;- na.omit(NHANES %&gt;% select(c(BMI,  Gender , Age, Race1, Education, MaritalStatus, HHIncomeMid)))\n\n# Réajustement de la première régression sur ces données uniquement\nreg_bis &lt;- lm(BMI ~ Gender + Age + Race1 + Education + MaritalStatus, data = dataReg)\n# Vérification\nlength(reg_bis$residuals)==length(reg2bis$residuals)\n\n[1] TRUE\n\n\nNous pouvons maintenant réalisé l’anova afin de savoir si l’ajout du revenu améliore significativement le modèle. Pour ce faire, nous utilisons la fonction anova()  \\[ \\text{anova(modele1, modele2)}\\] avec modele1 le modele avec le moins de variables\n\nanova(reg_bis, reg2bis)\n\nAnalysis of Variance Table\n\nModel 1: BMI ~ Gender + Age + Race1 + Education + MaritalStatus\nModel 2: BMI ~ Gender + Age + Race1 + Education + MaritalStatus + HHIncomeMid\n  Res.Df    RSS Df Sum of Sq     F    Pr(&gt;F)    \n1   4940 215613                                 \n2   4939 215005  1    608.16 13.97 0.0001878 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nRappel : L’anova teste H0: modèle 1 préféré VS H1: l’ajout de la variable améliore significativement le modèle\n\n\n7.2.5 Qualité de la régression\nLa sortie de summary(reg) nous donne le R2 et le R2 ajusté. On peut accéder directement à ces valeurs en tant qu’élément de l’a’objet retourné par la fonction summary(), donc via le symbole “$”\n\nsummary(reg)$r.squared #R2\n\n[1] 0.03659117\n\nsummary(reg)$adj.r.squared\n\n[1] 0.03391503\n\n\nLa fonction summary() ne donne en revanche pas l’aic ni le bic du modèle. Pour les obtenir, on peut utiliser les fonction AIC() et BIC()\n\nAIC(reg)\n\n[1] 35832.71\n\nBIC(reg)\n\n[1] 35944.86\n\n\nRemarque : Plus l’AIC / le BIC est faible, meilleur est le modèle   Remarque 2 : On peut passer plusieurs modèles comme argument de ces fonctions. On obtient alors un dataset avec une ligne par modèle et deux colonnes (“df” correspondant au nombre de paramètre et “AIC”)\n\nAIC(reg_bis, reg2bis)\n\n        df      AIC\nreg_bis 17 32796.95\nreg2bis 18 32784.95\n\n\n\n\n7.2.6 Vérification des hypothèses\nIl y a plusieurs façons de faire le diagnostique de la régression. Je vais présenté ici des façons manuelles et utiliser le package olsrr, mais d’autres packages existent. De plus, nous allons nous concentrer sur des analyses graphiques.\n\nHomoscédasticité et linéarité\nPour vérifier l’homoscédasticité (constance de la variance des résidus), on peut faire un graphe des résidus (en général on préfère les résidus studentisés) en fonction des valeurs prédites  Ce graphique peut également permettre de déterminer si l’on a oublié une variable carrée, sinusoidale, etc en fonction de la forme/tendance que prennent les résidus.   Rappel : S’il y a homoscedasticité, le nuage de point ne devrait pas avoir de tendance   Remarque : On peut utiliser ce même graphique pour visualiser les outliers étant donné qu’ils sont définis en fonction de leur résidus studentisés.   Rappel 2 : On peut obtenir les résidus avec les fonctions residuals() ou resid() ou la commande reg$residuals , les résidus studentisés avec la fonction rstudent() et les valeurs prédites avec la commande reg.fitted   Avec ggplot2\n\nn &lt;- length(reg$residuals)\np &lt;- length(reg$coeff)\n\nggplot(reg, aes(x=.fitted, y=rstudent(reg)))+\n      geom_point()+\n      geom_hline(yintercept = qt(0.975, n-1-p), col = \"red\")+ # 1 variable dans le modèle + l'intercept = length(reg$coeff) seuil haut pour déterminer les outliers\n      geom_hline(yintercept = -qt(0.975, n-1-p), col = \"red\")+ # seuil bas pour déterminer les outliers\n      geom_hline(yintercept = 0, col = \"blue\")+\n      labs(title = \"Homoscédasticité et outliers\", x = \"Fitted values\", y = \"Studentized residuals\")+\n      theme_classic()\n\n\n\n\n\n\n\n\nRamarque : au lieu d’utiliser les quantiles de la loi de Student, on peut utiliser les approximations -2 et 2 comme seuil pour détecter les outliers. C’est le choix fait notamment par défaut dans le package olsrr.   Avec olssr: le graphique des résidus n’affiche pas les lignes de seuils des outliers, il sert donc juste à verifié l’homoscédasticité. Il est donné par la fonction ols_plot_resid_fit()\n\nols_plot_resid_fit(reg)\n\n\n\n\n\n\n\n\n\n\nNormalité des résidus\nPour vérifier la normalité des résidus, on peut tracer leur qqplot.   Avec ggplot\n\nggplot(data = data.frame(residuals = resid(reg)), aes(sample = resid(reg))) +\n      stat_qq() +  # Tracé des quantiles\n      stat_qq_line(col = \"red\") +  # Ajout de la ligne de référence\n      labs(title = \"Normalité des résidus\", x = \"Quantiles théoriques\", y = \"Quantiles des résidus\") +\n      theme_classic()\n\n\n\n\n\n\n\n\nAvec olsrr\n\nols_plot_resid_qq(reg)\n\n\n\n\n\n\n\n\n\n\nObservations levier et outliers\n\nOutliers\nComme évoqué précédemment, pour visualisé les outliers, on peut utilisé le même graphe que pour l’hoscédasticité en ajoutant les lignes de seuil.   Rappel : Les outliers sont les observations dans les résidus studentisés sont supérieurs ou inférieurs à deux valeurs seuil.  Les seuils sont les quantiles 0.975 d’une loi de Student de paramètre \\((n, n-p-1)\\) et son inverse, avec \\(n\\) le nombre d’observations ayant servi pour l’ajustement, et \\(p\\) le nombre de paramètre (nombre de variables explicative + l’intercept)  Les seuils \\(-2\\) et \\(2\\) sont souvent utilisés comme approximation (c’est notamment le cas dans le package olssr).   On peut obtenir les numéros de ligne des observations outliers en utilisant la fonction which(). Cette fonction prend en argument une condition sur un vecteur et renvoie les numéros des entrées vérifiant la condition.\n\nn &lt;- length(reg$residuals)\np &lt;- length(reg$coeff)\nqt(0.975, n-1-p)\n\n[1] 1.960403\n\nwhich(rstudent(reg)&gt;qt(0.975, n-1-p) | rstudent(reg)&lt; -qt(0.975, n-1-p))\n\n  34   75   90  145  176  181  187  211  212  245  250  261  340  392  400  405 \n  24   51   64  107  128  133  138  156  157  178  182  190  245  282  289  292 \n 406  415  453  524  535  568  588  602  663  670  735  738  742  751  771  812 \n 293  299  324  365  374  394  409  419  460  466  512  515  519  526  540  564 \n 882  930  980  984  996  998 1013 1041 1069 1076 1080 1094 1118 1128 1139 1175 \n 614  644  671  675  687  688  698  719  740  746  749  758  773  779  786  810 \n1237 1256 1262 1264 1274 1364 1406 1469 1523 1534 1542 1560 1677 1714 1719 1728 \n 853  863  867  869  875  937  964 1009 1046 1053 1058 1066 1141 1169 1174 1181 \n1764 1780 1787 1813 1833 1838 1843 1883 1887 1898 1928 2055 2071 2079 2159 2176 \n1203 1214 1219 1238 1253 1257 1262 1290 1293 1300 1323 1412 1423 1428 1491 1503 \n2206 2215 2228 2263 2322 2367 2375 2409 2446 2472 2508 2528 2538 2603 2662 2704 \n1521 1526 1536 1565 1607 1638 1644 1669 1697 1718 1737 1751 1757 1799 1840 1867 \n2719 2758 2769 2857 2895 2929 2998 3083 3109 3126 3166 3168 3197 3207 3223 3255 \n1875 1906 1913 1977 2000 2024 2069 2122 2140 2152 2180 2182 2198 2204 2218 2240 \n3268 3361 3374 3427 3446 3473 3488 3504 3552 3558 3595 3599 3742 3743 3783 3806 \n2251 2317 2326 2364 2377 2395 2404 2411 2440 2443 2470 2474 2579 2580 2611 2626 \n3807 3832 3928 4026 4027 4059 4072 4087 4131 4133 4356 4438 4534 4572 4691 4692 \n2627 2644 2704 2762 2763 2786 2798 2811 2847 2849 2998 3060 3124 3150 3240 3241 \n4786 4787 4788 4949 4968 4969 5038 5039 5040 5060 5061 5102 5103 5166 5167 5175 \n3293 3294 3295 3402 3416 3417 3464 3465 3466 3478 3479 3502 3503 3544 3545 3551 \n5282 5307 5308 5314 5323 5352 5405 5430 5440 5470 5573 5580 5587 5591 5630 5646 \n3620 3639 3640 3643 3650 3670 3716 3733 3741 3761 3835 3841 3845 3846 3870 3883 \n5647 5648 5689 5706 5809 5836 5849 5853 5862 5884 5898 5906 5931 5932 5933 5966 \n3884 3885 3916 3927 3993 4013 4023 4027 4031 4049 4061 4068 4089 4090 4091 4110 \n6021 6063 6064 6117 6121 6122 6123 6238 6364 6373 6446 6459 6508 6520 6645 6683 \n4149 4178 4179 4210 4214 4215 4216 4295 4384 4390 4443 4453 4487 4491 4579 4599 \n6695 6860 6886 6887 6910 6911 6936 6945 6980 6997 7007 7021 7024 7048 7057 7062 \n4608 4735 4754 4755 4770 4771 4787 4794 4821 4834 4836 4845 4846 4861 4863 4865 \n7063 7084 7198 7289 7307 7335 7336 7337 7338 7509 7614 7626 7627 7628 7723 7724 \n4866 4881 4961 5024 5038 5058 5059 5060 5061 5186 5267 5274 5275 5276 5334 5335 \n7774 7803 \n5373 5389 \n\n\nSi on veut savoir à quelles observations cela correspond, on peut filtrer le jeu de données sur ces observations avec la fonction slice() qui permet directement de filtrer sur les numéros de ligne.   Attention : Il faut filtrer le jeu de données qui a effectivement servi pour ajuster la régression, c’est à dire celui sans donnée manquante. Sinon les numéros de lignes ne correspondent pas.\n\noutliers &lt;- dataReg %&gt;% \n  slice(which(rstudent(reg)&gt;qt(0.975, n-1-p) | rstudent(reg)&lt; -qt(0.975, n-1-p)))\n\n\n\nLeviers\nPour obtenir les leviers de chaque observation, on utilise la fonction hatvalues() qui prend l’objet de régression en argument\n\nhatvalues(reg)[1:10] # ici je n'affiche que les 10 premiers pour ne pas encombrer le document\n\n          1           3           6           7           8           9 \n0.001695559 0.003236305 0.001023860 0.001285104 0.002943260 0.001958299 \n         11          12          14          15 \n0.003549380 0.001940784 0.001732438 0.001404735 \n\n\nPour obtenir les observations qui peuvent être considérer comme levier, on peut utiliser la fonction which() et utiliser le seuil 2p/n. Ceci est le seuil le plus souvent utilisé, il est notamment utilisé par défaut par le package olsrr. Pour être plus précis, on peut aussi différencier 2 cas :  - Si \\(n-p&gt;12\\) et \\(p&gt;6\\), alors \\(seuil = 3p/n\\)  - sinon \\(seuil = 2p/n\\)  Rappel : n est le nombre d’observations dans le modèle et p est le nombre de paramètres (nombre de variables explicatives et intercept)\n\nseuil &lt;- ifelse((n-p)&gt;12 & p&gt;6, 3*p/n, 2*p/n)\nwhich(hatvalues(reg)&gt;seuil)\n\n  22   84  178  183  195  497  574  587  737  846  933 1351 1383 1394 1409 1500 \n  15   59  130  135  143  349  398  408  514  591  646  930  950  957  967 1029 \n1523 1560 1601 1717 1907 1946 1992 2184 2276 2446 2512 2569 2609 2737 2828 2842 \n1046 1066 1095 1172 1307 1338 1368 1507 1573 1697 1740 1776 1803 1890 1956 1966 \n3000 3142 3348 3418 3508 3586 3599 3709 3710 3977 3980 4091 4662 5076 5077 5142 \n2071 2164 2305 2358 2414 2465 2474 2555 2556 2735 2738 2814 3217 3483 3484 3530 \n5199 5365 5524 5745 5852 5938 5987 6090 6198 6547 6603 6604 6647 6860 6871 6931 \n3568 3682 3804 3949 4026 4093 4127 4196 4269 4513 4557 4558 4580 4735 4741 4783 \n6992 7192 7222 7309 7312 7459 7463 7476 7773 7806 \n4829 4958 4980 5040 5042 5144 5148 5160 5372 5392 \n\n\n\nGraphique des observations leviers avec ggplot2\n\nggplot(reg, aes(x= hatvalues(reg), y = rstudent(reg)))+\n  geom_point()+\n  geom_vline(xintercept = 2*p/n, col = \"red\")+\n  labs(x=\"Levier\",\n       y = \"Residus studentisés\")\n\n\n\n\n\n\n\n\nLe package olsrr permet d’obtenir un graphique avec les outliers et les observations leviers, ainsi que les numéros de ligne de ces observations en utilisant la fonction ols_plot_resid_lev()\n\nols_plot_resid_lev(reg)\n\n\n\n\n\n\n\n\nRemarque: Dans cet exemple ce n’est pas très lisible car nous avons beaucoup de données, mais ce graphique est vraiment pratique quand il y a moins de données.\n\n\nObservations influentes\nOn obtiens les observations influentes en regardant les distances de Cook.  Les distances de Cook sont données par la fonction cook.distance()\n\ncooks.distance(reg)[1:10] # ici je n'affiche que les 10 premiers pour ne pas encombrer le document\n\n           1            3            6            7            8            9 \n2.847096e-05 2.024495e-05 4.832033e-07 5.593676e-05 9.011885e-05 2.261147e-05 \n          11           12           14           15 \n9.320071e-05 9.365212e-06 1.561222e-07 2.211311e-05 \n\n\nIl existe plusieurs seuils pour considérer qu’une observation est influente : - distance de Cook supérieure au quantile 95% de la loi de Fisher(p,n-p) avec \\(n\\) le nombre d’observations dans le modèle et \\(p\\) le nombre de paramètres. ce seuil est statistiquement robuste, mais il peut être trop conservateur quand il y a beaucoup d’observations  - distance de Cook supérieure à \\(4/n\\) (seuil par défaut dans olsrr) ou \\(4/(n-k-1)\\) avec \\(k\\) nombre de variables expplicatives (\\(k=p-1\\)) (la version \\(n-k-1\\) est à préférer s’il y a beaucoup de variables explicatives) - distance de Cook supérieure à \\(1/n\\) ou \\(1/(n-k-1)\\) - distance de Cook supérieure à 1   Pour obtenir les observations influentes (pour un seuil donné), on peut de nouveau utiliser la fonction which()\n\nseuil = qf(0.95, p,n-p)\nwhich(cooks.distance(reg)&gt;seuil)\n\nnamed integer(0)\n\n\n\nseuil = 4/n\nwhich(cooks.distance(reg)&gt;seuil)\n\n  34   75   88   90  145  161  176  211  212  245  261  340  392  400  405  406 \n  24   51   63   64  107  118  128  156  157  178  190  245  282  289  292  293 \n 415  453  497  524  535  568  588  602  670  735  738  742  763  771  812  882 \n 299  324  349  365  374  394  409  419  466  512  515  519  535  540  564  614 \n 919  930  959  984  998 1013 1041 1069 1076 1080 1094 1128 1139 1157 1175 1215 \n 636  644  656  675  688  698  719  740  746  749  758  779  786  799  810  837 \n1227 1256 1262 1264 1274 1291 1351 1364 1394 1409 1469 1523 1540 1542 1560 1602 \n 845  863  867  869  875  888  930  937  957  967 1009 1046 1057 1058 1066 1096 \n1706 1714 1764 1774 1780 1784 1787 1813 1833 1838 1846 1883 1887 1948 1974 1985 \n1163 1169 1203 1209 1214 1217 1219 1238 1253 1257 1264 1290 1293 1339 1360 1363 \n2040 2068 2071 2159 2206 2241 2263 2322 2329 2341 2367 2375 2409 2432 2446 2448 \n1400 1422 1423 1491 1521 1545 1565 1607 1613 1620 1638 1644 1669 1687 1697 1699 \n2485 2505 2507 2508 2522 2528 2538 2576 2583 2603 2609 2704 2719 2769 2828 2857 \n1725 1734 1736 1737 1746 1751 1757 1780 1786 1799 1803 1867 1875 1913 1956 1977 \n2888 2895 2929 2991 2998 3000 3027 3109 3126 3151 3166 3168 3207 3223 3255 3268 \n1994 2000 2024 2064 2069 2071 2090 2140 2152 2169 2180 2182 2204 2218 2240 2251 \n3274 3287 3374 3418 3427 3441 3446 3504 3508 3552 3558 3559 3599 3667 3783 3786 \n2257 2268 2326 2358 2364 2375 2377 2411 2414 2440 2443 2444 2474 2522 2611 2613 \n3787 3788 3832 3928 4026 4027 4059 4072 4087 4094 4095 4133 4248 4356 4403 4418 \n2614 2615 2644 2704 2762 2763 2786 2798 2811 2817 2818 2849 2931 2998 3035 3046 \n4438 4505 4510 4534 4548 4572 4662 4691 4692 4786 4787 4788 4914 4919 4949 4968 \n3060 3103 3105 3124 3131 3150 3217 3240 3241 3293 3294 3295 3377 3381 3402 3416 \n4969 5038 5039 5040 5047 5060 5061 5102 5103 5166 5167 5175 5207 5208 5282 5314 \n3417 3464 3465 3466 3470 3478 3479 3502 3503 3544 3545 3551 3573 3574 3620 3643 \n5323 5352 5405 5430 5440 5580 5587 5591 5630 5646 5647 5648 5706 5836 5849 5853 \n3650 3670 3716 3733 3741 3841 3845 3846 3870 3883 3884 3885 3927 4013 4023 4027 \n5862 5884 5886 5898 5906 5932 5933 5966 6021 6063 6064 6113 6114 6117 6198 6238 \n4031 4049 4051 4061 4068 4090 4091 4110 4149 4178 4179 4207 4208 4210 4269 4295 \n6373 6446 6459 6520 6575 6645 6683 6695 6860 6871 6886 6887 6910 6911 6936 6945 \n4390 4443 4453 4491 4537 4579 4599 4608 4735 4741 4754 4755 4770 4771 4787 4794 \n6956 6997 7007 7021 7024 7048 7057 7084 7175 7198 7289 7307 7419 7463 7509 7774 \n4803 4834 4836 4845 4846 4861 4863 4881 4945 4961 5024 5038 5114 5148 5186 5373 \n7803 \n5389 \n\n\nCet exemple illustre que le seuil choisi peut largement changer le nombre d’observations considérées comme influentes  \nGraphique des distances de Cook Avec ggplot2 (une version possible)\n\nggplot(reg, aes(seq_along(.cooksd), .cooksd))+\n  geom_bar(stat=\"identity\", position=\"identity\")+\n  geom_hline(yintercept = 4/n, col = \"red\")\n\n\n\n\n\n\n\n\nAvec olsrr, on utilise la fonction ols_plot_cooksd_chart() avec en argument l’objet de la régression. On peut choisir la méthode utilisée pour le seuil avec l’argument type =  (regarder dans la documentation les numéros des différentes méthodes). Si on préfère rentrer le seuil à la main, on peut le faire avec l’argument threshold =.\n\nols_plot_cooksd_chart(reg,type = 1, threshold = NULL, print_plot = TRUE)\n\n\n\n\n\n\n\n\n\n\nObservations problématiques\nLes observations problématiques sont celles qui sont outlier ou levier et qui sont en plus influentes.  Pour obtenir ces observations, on peut utiliser la fonction intersect() appliquée aux vecteurs de ces trois types d’observations\n\nn &lt;- length(reg$residuals)\np &lt;- length(reg$coeff)\n\noutliers &lt;- which(rstudent(reg)&gt;qt(0.975, n-1-p) | rstudent(reg)&lt; -qt(0.975, n-1-p))\n\nseuil &lt;- ifelse((n-p)&gt;12 & p&gt;6, 3*p/n, 2*p/n)\nleviers &lt;- which(hatvalues(reg)&gt;seuil) \n\nseuil = 4/n\ninfluentes &lt;- which(cooks.distance(reg)&gt;seuil)\n\nintersect(influentes, c(outliers,leviers))\n\n  [1]   24   51   64  107  128  156  157  178  190  245  282  289  292  293  299\n [16]  324  349  365  374  394  409  419  466  512  515  519  540  564  614  644\n [31]  675  688  698  719  740  746  749  758  779  786  810  863  867  869  875\n [46]  930  937  957  967 1009 1046 1058 1066 1169 1203 1214 1219 1238 1253 1257\n [61] 1290 1293 1423 1491 1521 1565 1607 1638 1644 1669 1697 1737 1751 1757 1799\n [76] 1803 1867 1875 1913 1956 1977 2000 2024 2069 2071 2140 2152 2180 2182 2204\n [91] 2218 2240 2251 2326 2358 2364 2377 2411 2414 2440 2443 2474 2611 2644 2704\n[106] 2762 2763 2786 2798 2811 2849 2998 3060 3124 3150 3217 3240 3241 3293 3294\n[121] 3295 3402 3416 3417 3464 3465 3466 3478 3479 3502 3503 3544 3545 3551 3620\n[136] 3643 3650 3670 3716 3733 3741 3841 3845 3846 3870 3883 3884 3885 3927 4013\n[151] 4023 4027 4031 4049 4061 4068 4090 4091 4110 4149 4178 4179 4210 4269 4295\n[166] 4390 4443 4453 4491 4579 4599 4608 4735 4741 4754 4755 4770 4771 4787 4794\n[181] 4834 4836 4845 4846 4861 4863 4881 4961 5024 5038 5148 5186 5373 5389\n\n\n Attention :  Il s’agit des numéros de ligne dans le data sans donnée manquante (obtenu avec na.omit()), ils ne correspondent donc pas forcément aux numéros de lignes dans le dataset que vous avez donner en argument de la fonction lm() !   Voici comment obtenir les observations problématiques du premier model (reg):\n\n# D'abord on ne garde que les données utilisées pour ajuster le modèle\ndataReg &lt;- na.omit(NHANES %&gt;% select(c(BMI,  Gender , Age, Race1, Education, MaritalStatus)))\n# Ensuite on filtre les observations via leur numéro de ligne\nDataPb &lt;- dataReg %&gt;% \n  slice(intersect(influentes, c(outliers,leviers)))\n\n# Dimensions\ndim(DataPb)\n\n[1] 194   6\n\n# Premières observations problématiques\nkable(head(DataPb))\n\n\n\n\nBMI\nGender\nAge\nRace1\nEducation\nMaritalStatus\n\n\n\n\n46.69\nfemale\n28\nBlack\nHigh School\nNeverMarried\n\n\n40.70\nfemale\n50\nOther\nHigh School\nMarried\n\n\n48.91\nfemale\n31\nWhite\nCollege Grad\nNeverMarried\n\n\n51.33\nfemale\n68\nBlack\n9 - 11th Grade\nWidowed\n\n\n48.22\nmale\n61\nWhite\n8th Grade\nMarried\n\n\n41.79\nfemale\n56\nWhite\nSome College\nWidowed\n\n\n\n\n\n\n\n\nColinéarité\nPour détecter un problème de colinéarité des variables explicatives, on peut regarder le facteur d’inflation de la variance (VIF) qui mesure l’inflation de la variance des paramètres estimés, due à la multicollinéarité entre les variable explicative.  Un VIF = 1 signifie qu’il n’y a pas de corrélation entre la variable considérée et les autres et donc la variance du coefficient n’est pas augmentée. Un VIF supérieur à 5 indique un problème de corrélation et un VIF supérieur à 10 indique un problème très important.   On peut obtenir les VIF avec la fonction ols_vif_tol() du package olsrr\n\nols_vif_tol(reg)\n\n                   Variables Tolerance      VIF\n1                 Gendermale 0.9624750 1.038988\n2                        Age 0.6544262 1.528056\n3              Race1Hispanic 0.6960117 1.436757\n4               Race1Mexican 0.5776379 1.731188\n5                 Race1White 0.4432034 2.256300\n6                 Race1Other 0.6508998 1.536335\n7    Education9 - 11th Grade 0.3834519 2.607889\n8       EducationHigh School 0.2904722 3.442670\n9      EducationSome College 0.2344217 4.265817\n10     EducationCollege Grad 0.2380133 4.201445\n11  MaritalStatusLivePartner 0.5564523 1.797099\n12      MaritalStatusMarried 0.3151684 3.172907\n13 MaritalStatusNeverMarried 0.3626850 2.757214\n14    MaritalStatusSeparated 0.7835570 1.276231\n15      MaritalStatusWidowed 0.5670643 1.763468\n\n\nCette fonction donne le VIF de chaque modalité.  \nUne façon d’obtenir les VIF par variable et non par modalité, est d’utiliser la fonction vif() du package car\n\nlibrary(car)\nvif(reg)\n\n                  GVIF Df GVIF^(1/(2*Df))\nGender        1.038988  1        1.019308\nAge           1.528056  1        1.236146\nRace1         1.322326  4        1.035541\nEducation     1.290620  4        1.032404\nMaritalStatus 1.639081  5        1.050655\n\n\nCette méthode est à privilégiée  \nRegardons les VIF de la deuxième régression (celle avec le revenu)\n\nvif(reg2)\n\n                  GVIF Df GVIF^(1/(2*Df))\nGender        1.043409  1        1.021474\nAge           1.527128  1        1.235770\nRace1         1.291975  4        1.032540\nEducation     1.500259  4        1.052012\nMaritalStatus 1.769873  5        1.058752\nHHIncomeMid   1.395653  1        1.181378\n\n\nDans les deux cas il n’y a pas l’air d’y avoir de problème de multicolinéarité\n\n\nPackage olssr\nRemarque générale sur le package olssr: les graphiques de ce package sont faits avec ggplot2. Cela permet de pouvoir facilement y apporter quelques modifications sur le thème, la personnalisation des axes, etc …  Exemple de personnalisation du qqplot des résidus obtenu avec olssr\n\nols_plot_resid_qq(reg)+\n  theme_bw()+\n  labs(x=\"Quantiles theoriques\",\n       y = \"Quantiles observés\", \n       title = \"QQplot des résidus\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regression Lineaire</span>"
    ]
  },
  {
    "objectID": "5.RegressionLineaire.html#ressources",
    "href": "5.RegressionLineaire.html#ressources",
    "title": "7  Regression Lineaire",
    "section": "7.3 Ressources",
    "text": "7.3 Ressources\nVérification des hypothèses :  - cours théorique de l’EPFL  - Bookdown de Teodor Tiplica Cours de régression linéaire avec R - mélange de la théorie et de la pratique  - STHDA tutoriel sur le diagnostique de régression linéaire en R   Package olssr : lien vers la documentation les différentes vignettes proposent des exemples   Didactic modeling process: Linear regression by Oscar Daniel Rivera Baena Application R Shiny comme tutoriel sur la régression linéaire avec R",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Regression Lineaire</span>"
    ]
  },
  {
    "objectID": "6.RegressionLogistique.html",
    "href": "6.RegressionLogistique.html",
    "title": "8  Regression Logistique",
    "section": "",
    "text": "8.1 Import des données\nPour cette séance, nous allons utiliser le jeu de données NHANES disponible dans le package du même nom.  Il s’agit de données de santé provenant de l’enquête américaine National Health and Nutrition Examination Survey (NHANES). Il contient des données sociale, comportementales et de santé.   Une description des données est disponible dans le descriptif du package lien\nlibrary(NHANES)\ndata(\"NHANES\")\ndim(NHANES)\n\n[1] 10000    76\nDans ces données il semble y avoir des doublons. Nous allons les supprimer en utilisant la fonction distinct() de dplyr. Cette fonction ne garde qu’une ligne pour un groupe de lignes qui sont absolument identiques\nNHANES &lt;- NHANES %&gt;% distinct()\ndim(NHANES)\n\n[1] 7832   76\nNous sommes passés de 10000 à 7155 observations\nRésumé des données\nsummary(NHANES)\n\n       ID           SurveyYr       Gender          Age          AgeDecade   \n Min.   :51624   2009_10:3568   female:3943   Min.   : 0.00    0-9   :1212  \n 1st Qu.:57388   2011_12:4264   male  :3889   1st Qu.:16.00    10-19 :1142  \n Median :62914                                Median :35.00    30-39 :1038  \n Mean   :62369                                Mean   :35.97    20-29 :1023  \n 3rd Qu.:67408                                3rd Qu.:54.00    40-49 :1010  \n Max.   :71915                                Max.   :80.00   (Other):2124  \n                                                              NA's   : 283  \n   AgeMonths          Race1           Race3               Education   \n Min.   :  0.0   Black   :1073   Asian   : 281   8th Grade     : 397  \n 1st Qu.:169.0   Hispanic: 538   Black   : 563   9 - 11th Grade: 712  \n Median :387.0   Mexican : 920   Hispanic: 317   High School   :1131  \n Mean   :403.1   White   :4626   Mexican : 451   Some College  :1695  \n 3rd Qu.:615.0   Other   : 675   White   :2510   College Grad  :1534  \n Max.   :959.0                   Other   : 142   NA's          :2363  \n NA's   :4271                    NA's    :3568                        \n      MaritalStatus         HHIncome     HHIncomeMid        Poverty     \n Divorced    : 516   more 99999 :1588   Min.   :  2500   Min.   :0.000  \n LivePartner : 438   75000-99999: 809   1st Qu.: 22500   1st Qu.:1.130  \n Married     :2940   25000-34999: 784   Median : 50000   Median :2.400  \n NeverMarried:1048   35000-44999: 691   Mean   : 54862   Mean   :2.664  \n Separated   : 148   45000-54999: 596   3rd Qu.: 87500   3rd Qu.:4.500  \n Widowed     : 384   (Other)    :2711   Max.   :100000   Max.   :5.000  \n NA's        :2358   NA's       : 653   NA's   :653      NA's   :578    \n   HomeRooms       HomeOwn             Work          Weight      \n Min.   : 1.000   Own  :4845   Looking   : 244   Min.   :  2.80  \n 1st Qu.: 5.000   Rent :2753   NotWorking:2290   1st Qu.: 54.35  \n Median : 6.000   Other: 184   Working   :3376   Median : 71.60  \n Mean   : 6.173   NA's :  50   NA's      :1922   Mean   : 69.67  \n 3rd Qu.: 7.000                                  3rd Qu.: 87.90  \n Max.   :13.000                                  Max.   :230.70  \n NA's   :54                                      NA's   :61      \n     Length          HeadCirc         Height           BMI       \n Min.   : 47.10   Min.   :34.20   Min.   : 83.6   Min.   :12.88  \n 1st Qu.: 75.15   1st Qu.:39.50   1st Qu.:155.8   1st Qu.:21.40  \n Median : 87.05   Median :41.30   Median :165.4   Median :25.83  \n Mean   : 84.89   Mean   :41.10   Mean   :160.9   Mean   :26.52  \n 3rd Qu.: 95.80   3rd Qu.:42.98   3rd Qu.:173.9   3rd Qu.:30.64  \n Max.   :112.20   Max.   :45.40   Max.   :200.4   Max.   :81.25  \n NA's   :7334     NA's   :7750    NA's   :317     NA's   :327    \n    BMICatUnder20yrs         BMI_WHO         Pulse           BPSysAve    \n UnderWeight:  47    12.0_18.5   :1070   Min.   : 40.00   Min.   : 76.0  \n NormWeight : 709    18.5_to_24.9:2261   1st Qu.: 66.00   1st Qu.:106.0  \n OverWeight : 180    25.0_to_29.9:2067   Median : 72.00   Median :116.0  \n Obese      : 197    30.0_plus   :2081   Mean   : 73.58   Mean   :118.1  \n NA's       :6699    NA's        : 353   3rd Qu.: 82.00   3rd Qu.:127.0  \n                                         Max.   :136.00   Max.   :226.0  \n                                         NA's   :1236     NA's   :1246   \n    BPDiaAve          BPSys1         BPDia1          BPSys2     \n Min.   :  0.00   Min.   : 72    Min.   :  0.0   Min.   : 76.0  \n 1st Qu.: 60.00   1st Qu.:106    1st Qu.: 60.0   1st Qu.:106.0  \n Median : 68.00   Median :116    Median : 68.0   Median :116.0  \n Mean   : 67.03   Mean   :119    Mean   : 67.9   Mean   :118.4  \n 3rd Qu.: 76.00   3rd Qu.:128    3rd Qu.: 76.0   3rd Qu.:128.0  \n Max.   :116.00   Max.   :232    Max.   :118.0   Max.   :226.0  \n NA's   :1246     NA's   :1497   NA's   :1497    NA's   :1404   \n     BPDia2           BPSys3          BPDia3        Testosterone    \n Min.   :  0.00   Min.   : 76.0   Min.   :  0.00   Min.   :   0.25  \n 1st Qu.: 60.00   1st Qu.:106.0   1st Qu.: 60.00   1st Qu.:  17.53  \n Median : 68.00   Median :116.0   Median : 68.00   Median :  40.69  \n Mean   : 67.19   Mean   :117.9   Mean   : 66.83   Mean   : 193.72  \n 3rd Qu.: 76.00   3rd Qu.:126.0   3rd Qu.: 76.00   3rd Qu.: 352.32  \n Max.   :118.00   Max.   :226.0   Max.   :116.00   Max.   :1795.60  \n NA's   :1404     NA's   :1400    NA's   :1400     NA's   :4354     \n   DirectChol       TotChol         UrineVol1       UrineFlow1     \n Min.   :0.390   Min.   : 1.530   Min.   :  0.0   Min.   : 0.0000  \n 1st Qu.:1.090   1st Qu.: 4.060   1st Qu.: 49.0   1st Qu.: 0.3970  \n Median :1.290   Median : 4.730   Median : 92.0   Median : 0.6820  \n Mean   :1.359   Mean   : 4.841   Mean   :117.1   Mean   : 0.9649  \n 3rd Qu.:1.580   3rd Qu.: 5.480   3rd Qu.:162.0   3rd Qu.: 1.2130  \n Max.   :4.030   Max.   :13.650   Max.   :510.0   Max.   :17.1670  \n NA's   :1296    NA's   :1296     NA's   :865     NA's   :1340     \n   UrineVol2       UrineFlow2     Diabetes     DiabetesAge        HealthGen   \n Min.   :  0.0   Min.   : 0.000   No  :7077   Min.   : 1.00   Excellent: 661  \n 1st Qu.: 50.0   1st Qu.: 0.482   Yes : 622   1st Qu.:40.00   Vgood    :1848  \n Median : 92.5   Median : 0.765   NA's: 133   Median :50.00   Good     :2272  \n Mean   :119.5   Mean   : 1.154               Mean   :49.07   Fair     : 829  \n 3rd Qu.:171.8   3rd Qu.: 1.507               3rd Qu.:60.00   Poor     : 155  \n Max.   :409.0   Max.   :13.692               Max.   :80.00   NA's     :2067  \n NA's   :6670    NA's   :6671                 NA's   :7315                    \n DaysPhysHlthBad  DaysMentHlthBad  LittleInterest   Depressed   \n Min.   : 0.000   Min.   : 0.000   None   :3837   None   :3937  \n 1st Qu.: 0.000   1st Qu.: 0.000   Several: 869   Several: 783  \n Median : 0.000   Median : 0.000   Most   : 343   Most   : 331  \n Mean   : 3.423   Mean   : 4.112   NA's   :2783   NA's   :2781  \n 3rd Qu.: 3.000   3rd Qu.: 4.000                                \n Max.   :30.000   Max.   :30.000                                \n NA's   :2074     NA's   :2072                                  \n  nPregnancies       nBabies         Age1stBaby    SleepHrsNight   \n Min.   : 1.000   Min.   : 0.000   Min.   :14.00   Min.   : 2.000  \n 1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.:19.00   1st Qu.: 6.000  \n Median : 3.000   Median : 2.000   Median :22.00   Median : 7.000  \n Mean   : 3.087   Mean   : 2.503   Mean   :22.48   Mean   : 6.904  \n 3rd Qu.: 4.000   3rd Qu.: 3.000   3rd Qu.:25.00   3rd Qu.: 8.000  \n Max.   :32.000   Max.   :12.000   Max.   :39.00   Max.   :12.000  \n NA's   :5840     NA's   :5986     NA's   :6375    NA's   :1935    \n SleepTrouble PhysActive  PhysActiveDays       TVHrsDay        CompHrsDay  \n No  :4430    No  :2853   Min.   :1.000   2_hr     :1082   0_to_1_hr:1194  \n Yes :1481    Yes :3521   1st Qu.:2.000   1_hr     : 741   0_hrs    : 953  \n NA's:1921    NA's:1458   Median :3.000   3_hr     : 727   1_hr     : 844  \n                          Mean   :3.753   0_to_1_hr: 526   2_hr     : 491  \n                          3rd Qu.:5.000   More_4_hr: 524   3_hr     : 298  \n                          Max.   :7.000   (Other)  : 528   (Other)  : 352  \n                          NA's   :4019    NA's     :3704   NA's     :3700  \n TVHrsDayChild   CompHrsDayChild Alcohol12PlusYr   AlcoholDay    \n Min.   :0.000   Min.   :0.000   No  :1087       Min.   : 1.000  \n 1st Qu.:1.000   1st Qu.:0.000   Yes :3892       1st Qu.: 1.000  \n Median :2.000   Median :1.000   NA's:2853       Median : 2.000  \n Mean   :1.979   Mean   :2.255                   Mean   : 2.947  \n 3rd Qu.:3.000   3rd Qu.:6.000                   3rd Qu.: 3.000  \n Max.   :6.000   Max.   :6.000                   Max.   :82.000  \n NA's   :7298    NA's   :7298                    NA's   :4160    \n  AlcoholYear     SmokeNow    Smoke100         Smoke100n       SmokeAge    \n Min.   :  0.00   No  :1307   No  :3055   Non-Smoker:3055   Min.   : 6.00  \n 1st Qu.:  3.00   Yes :1116   Yes :2423   Smoker    :2423   1st Qu.:15.00  \n Median : 24.00   NA's:5409   NA's:2354   NA's      :2354   Median :17.00  \n Mean   : 73.33                                             Mean   :17.75  \n 3rd Qu.:104.00                                             3rd Qu.:19.00  \n Max.   :364.00                                             Max.   :72.00  \n NA's   :3388                                               NA's   :5507   \n Marijuana   AgeFirstMarij   RegularMarij  AgeRegMarij    HardDrugs  \n No  :1573   Min.   : 1.00   No  :2679    Min.   : 5.00   No  :3547  \n Yes :2096   1st Qu.:15.00   Yes : 990    1st Qu.:15.00   Yes : 764  \n NA's:4163   Median :16.00   NA's:4163    Median :17.00   NA's:3521  \n             Mean   :17.02                Mean   :17.65              \n             3rd Qu.:18.00                3rd Qu.:19.00              \n             Max.   :48.00                Max.   :52.00              \n             NA's   :5737                 NA's   :6842               \n SexEver         SexAge      SexNumPartnLife  SexNumPartYear   SameSex    \n No  : 175   Min.   : 9.00   Min.   :   0.0   Min.   : 0.000   No  :4000  \n Yes :4137   1st Qu.:15.00   1st Qu.:   2.0   1st Qu.: 1.000   Yes : 312  \n NA's:3520   Median :17.00   Median :   5.0   Median : 1.000   NA's:3520  \n             Mean   :17.41   Mean   :  15.4   Mean   : 1.327              \n             3rd Qu.:19.00   3rd Qu.:  12.0   3rd Qu.: 1.000              \n             Max.   :50.00   Max.   :2000.0   Max.   :69.000              \n             NA's   :3699    NA's   :3552     NA's   :4172                \n      SexOrientation  PregnantNow  \n Bisexual    :  91   Yes    :  54  \n Heterosexual:3426   No     :1197  \n Homosexual  :  70   Unknown:  41  \n NA's        :4245   NA's   :6540\nPour modéliser / étudier une variable binaire en fonction d’une ou plusieurs autres variables, on peut réaliser une régression logistique.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Logistique</span>"
    ]
  },
  {
    "objectID": "6.RegressionLogistique.html#préparation",
    "href": "6.RegressionLogistique.html#préparation",
    "title": "8  Regression Logistique",
    "section": "8.2 Préparation",
    "text": "8.2 Préparation\nAvant de commencer il faut s’assurer que nos variables sont correctement codées. La modalité de réference doit être la première modalité de notre variable facteur.  De plus, pour la variable d’outcome binaire, dans la plupart des cas, les deux modalités doivent être codées en 0 et 1.\n\nclass(NHANES$Diabetes)\n\n[1] \"factor\"\n\nlevels(NHANES$Diabetes)\n\n[1] \"No\"  \"Yes\"\n\n\nMeme si R peut gérer les facteurs Oui/Non, il est préférable de recoder en OUI = 1 et NON = 0 pour être sûr que R traite bien le Non en 0. Dans notre cas, c’est déjà le cas mais voici en rappel la commande pour recoder.\n\nNHANES$Diabetes.lvl &lt;- ifelse(NHANES$Diabetes == \"Yes\", 1, 0)\nfreq(NHANES$Diabetes)\n\n       n    % val%\nNo  7077 90.4 91.9\nYes  622  7.9  8.1\nNA   133  1.7   NA\n\n\nLors de la régression les observations manquantes seront exclus lors du calcul du modèle.\nDescription\n\ntbl_summary(data=NHANES, \n            by= Diabetes, \n            include = c(Gender, Age, Race1, Education, MaritalStatus)) %&gt;%\n  add_p() %&gt;%\n  bold_labels() %&gt;%\n  modify_spanning_header(\n    update = all_stat_cols() ~ \"Diabete\"\n  )\n\n133 missing rows in the \"Diabetes\" column have been removed.\n\n\nWarning: The `update` argument of `modify_spanning_header()` is deprecated as of\ngtsummary 2.0.0.\nℹ Use `modify_spanning_header(...)` input instead. Dynamic dots allow for\n  syntax like `modify_spanning_header(!!!list(...))`.\nℹ The deprecated feature was likely used in the gtsummary package.\n  Please report the issue at &lt;https://github.com/ddsjoberg/gtsummary/issues&gt;.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nDiabete\n\np-value2\n\n\nNo\nN = 7,0771\nYes\nN = 6221\n\n\n\n\nGender\n\n\n\n\n0.2\n\n\n    female\n3,579 (51%)\n298 (48%)\n\n\n\n\n    male\n3,498 (49%)\n324 (52%)\n\n\n\n\nAge\n32 (15, 51)\n62 (51, 70)\n&lt;0.001\n\n\nRace1\n\n\n\n\n&lt;0.001\n\n\n    Black\n939 (13%)\n121 (19%)\n\n\n\n\n    Hispanic\n486 (6.9%)\n45 (7.2%)\n\n\n\n\n    Mexican\n834 (12%)\n62 (10.0%)\n\n\n\n\n    White\n4,216 (60%)\n336 (54%)\n\n\n\n\n    Other\n602 (8.5%)\n58 (9.3%)\n\n\n\n\nEducation\n\n\n\n\n&lt;0.001\n\n\n    8th Grade\n307 (6.3%)\n90 (15%)\n\n\n\n\n    9 - 11th Grade\n621 (13%)\n90 (15%)\n\n\n\n\n    High School\n1,005 (21%)\n126 (21%)\n\n\n\n\n    Some College\n1,506 (31%)\n189 (31%)\n\n\n\n\n    College Grad\n1,419 (29%)\n115 (19%)\n\n\n\n\n    Unknown\n2,219\n12\n\n\n\n\nMaritalStatus\n\n\n\n\n&lt;0.001\n\n\n    Divorced\n437 (9.0%)\n78 (13%)\n\n\n\n\n    LivePartner\n417 (8.6%)\n21 (3.4%)\n\n\n\n\n    Married\n2,596 (53%)\n344 (56%)\n\n\n\n\n    NeverMarried\n991 (20%)\n57 (9.4%)\n\n\n\n\n    Separated\n128 (2.6%)\n20 (3.3%)\n\n\n\n\n    Widowed\n295 (6.1%)\n89 (15%)\n\n\n\n\n    Unknown\n2,213\n13\n\n\n\n\n\n1 n (%); Median (Q1, Q3)\n\n\n2 Pearson’s Chi-squared test; Wilcoxon rank sum test",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Logistique</span>"
    ]
  },
  {
    "objectID": "6.RegressionLogistique.html#calcul-de-la-régression",
    "href": "6.RegressionLogistique.html#calcul-de-la-régression",
    "title": "8  Regression Logistique",
    "section": "8.3 Calcul de la régression",
    "text": "8.3 Calcul de la régression\nLa fonction permettant de réaliser une régression logistique, ainsi que la plupart des modèles de régression généralisés est glm()   Le type de régression réalisée est spécifié avec les argument family et link.   Pour une regression logistique, la famille est binomial et le lien log   Le reste des arguments est similaire à la fonction lm()  \n\n\\[\nglm(\\text{Variable Binaire} \\sim \\text{x}_1 + \\text{x}_2 +\\text{x}_3, \\text{ family = binomial, data }= \\text{Dataset})\n\\]\n\nExemple\n\nreg.log &lt;- glm(Diabetes.lvl ~ Gender + Age + Race1 + Education + MaritalStatus, family = binomial, data = NHANES) \nsummary(reg.log)\n\n\nCall:\nglm(formula = Diabetes.lvl ~ Gender + Age + Race1 + Education + \n    MaritalStatus, family = binomial, data = NHANES)\n\nCoefficients:\n                           Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)               -4.004556   0.308722 -12.971  &lt; 2e-16 ***\nGendermale                 0.279626   0.094567   2.957  0.00311 ** \nAge                        0.057380   0.003474  16.518  &lt; 2e-16 ***\nRace1Hispanic             -0.291916   0.211310  -1.381  0.16714    \nRace1Mexican              -0.251640   0.194380  -1.295  0.19547    \nRace1White                -0.886189   0.128409  -6.901 5.15e-12 ***\nRace1Other                -0.155254   0.189690  -0.818  0.41309    \nEducation9 - 11th Grade   -0.369399   0.183350  -2.015  0.04393 *  \nEducationHigh School      -0.422582   0.174118  -2.427  0.01522 *  \nEducationSome College     -0.281872   0.167027  -1.688  0.09149 .  \nEducationCollege Grad     -0.711511   0.179108  -3.973 7.11e-05 ***\nMaritalStatusLivePartner  -0.707662   0.267017  -2.650  0.00804 ** \nMaritalStatusMarried      -0.287169   0.145067  -1.980  0.04775 *  \nMaritalStatusNeverMarried -0.355132   0.198771  -1.787  0.07400 .  \nMaritalStatusSeparated    -0.128768   0.285637  -0.451  0.65213    \nMaritalStatusWidowed      -0.483216   0.189786  -2.546  0.01089 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 3816.0  on 5464  degrees of freedom\nResidual deviance: 3291.1  on 5449  degrees of freedom\n  (2367 observations deleted due to missingness)\nAIC: 3323.1\n\nNumber of Fisher Scoring iterations: 6\n\n\nAttention : les coefficients affichés correspondent aux log odds-ratio et non aux odds-ratio.   On peut exporter les coefficients dans un tableau avec la fonction tbl_regression() du package GTsummary\n\ntbl_regression(reg.log)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nlog(OR)\n95% CI\np-value\n\n\n\n\nGender\n\n\n\n\n\n\n\n\n    female\n—\n—\n\n\n\n\n    male\n0.28\n0.09, 0.47\n0.003\n\n\nAge\n0.06\n0.05, 0.06\n&lt;0.001\n\n\nRace1\n\n\n\n\n\n\n\n\n    Black\n—\n—\n\n\n\n\n    Hispanic\n-0.29\n-0.71, 0.12\n0.2\n\n\n    Mexican\n-0.25\n-0.64, 0.13\n0.2\n\n\n    White\n-0.89\n-1.1, -0.63\n&lt;0.001\n\n\n    Other\n-0.16\n-0.53, 0.21\n0.4\n\n\nEducation\n\n\n\n\n\n\n\n\n    8th Grade\n—\n—\n\n\n\n\n    9 - 11th Grade\n-0.37\n-0.73, -0.01\n0.044\n\n\n    High School\n-0.42\n-0.76, -0.08\n0.015\n\n\n    Some College\n-0.28\n-0.61, 0.05\n0.091\n\n\n    College Grad\n-0.71\n-1.1, -0.36\n&lt;0.001\n\n\nMaritalStatus\n\n\n\n\n\n\n\n\n    Divorced\n—\n—\n\n\n\n\n    LivePartner\n-0.71\n-1.3, -0.20\n0.008\n\n\n    Married\n-0.29\n-0.57, 0.00\n0.048\n\n\n    NeverMarried\n-0.36\n-0.75, 0.03\n0.074\n\n\n    Separated\n-0.13\n-0.71, 0.41\n0.7\n\n\n    Widowed\n-0.48\n-0.86, -0.11\n0.011\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio\n\n\n\n\n\n\n\n\nUn avantage de cette fonction est qu’elle affiche les modalités de référence.\nIl faut ajouter l’option exponentiate = TRUE pour afficher les OR plutôt que les log(OR) :\n\ntbl_regression(reg.log,exponentiate = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR\n95% CI\np-value\n\n\n\n\nGender\n\n\n\n\n\n\n\n\n    female\n—\n—\n\n\n\n\n    male\n1.32\n1.10, 1.59\n0.003\n\n\nAge\n1.06\n1.05, 1.07\n&lt;0.001\n\n\nRace1\n\n\n\n\n\n\n\n\n    Black\n—\n—\n\n\n\n\n    Hispanic\n0.75\n0.49, 1.12\n0.2\n\n\n    Mexican\n0.78\n0.53, 1.13\n0.2\n\n\n    White\n0.41\n0.32, 0.53\n&lt;0.001\n\n\n    Other\n0.86\n0.59, 1.24\n0.4\n\n\nEducation\n\n\n\n\n\n\n\n\n    8th Grade\n—\n—\n\n\n\n\n    9 - 11th Grade\n0.69\n0.48, 0.99\n0.044\n\n\n    High School\n0.66\n0.47, 0.92\n0.015\n\n\n    Some College\n0.75\n0.54, 1.05\n0.091\n\n\n    College Grad\n0.49\n0.35, 0.70\n&lt;0.001\n\n\nMaritalStatus\n\n\n\n\n\n\n\n\n    Divorced\n—\n—\n\n\n\n\n    LivePartner\n0.49\n0.29, 0.82\n0.008\n\n\n    Married\n0.75\n0.57, 1.00\n0.048\n\n\n    NeverMarried\n0.70\n0.47, 1.03\n0.074\n\n\n    Separated\n0.88\n0.49, 1.51\n0.7\n\n\n    Widowed\n0.62\n0.43, 0.90\n0.011\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Logistique</span>"
    ]
  },
  {
    "objectID": "6.RegressionLogistique.html#les-tests",
    "href": "6.RegressionLogistique.html#les-tests",
    "title": "8  Regression Logistique",
    "section": "8.4 Les tests",
    "text": "8.4 Les tests\n\n8.4.1 Test de nullité de chaque coefficient\nDans les sorties de summary() et tbl_regression, pour chaque coefficient, on a la p-valeur associée au test de nullité de ce coefficient (associé à la modalité et non pas à la variable pour les variables catégorielles).\n\n\n8.4.2 Test de l’effet global d’une variable\nPour les variables continues, le test de l’effet global est le même que celui de nullité du coefficient donné dans la fonction summary()   Pour les variables catégorielles, on peut tester si elle un un effet sur la probabilité d’observer Y=Yref sachant les autres variables dans le modèle avec le test de type III. On peut obtenir ce test avec la fonction Anova() du package car ( avec un A majuscule à ne pas confondre anova())\n\nAnova(reg.log, type = \"III\")\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: Diabetes.lvl\n              LR Chisq Df Pr(&gt;Chisq)    \nGender           8.783  1  0.0030400 ** \nAge            304.433  1  &lt; 2.2e-16 ***\nRace1           60.569  4  2.203e-12 ***\nEducation       19.095  4  0.0007527 ***\nMaritalStatus   11.337  5  0.0450975 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n8.4.3 Test de nullité de tous les coefficients\nPour tester que les coefficients sont non tous nuls, on peut réaliser trois tests: le test du rapport de vraisemblance, le test de Wald et le test du score. Nous présentons ici uniquement le test du rapport de vraisemblance.   Le test du rapport de vraisemblance s’obtient avec la fonction anova() ( avec un a minuscule cette fois ) pour comparer notre modèle au modèle nul (i.e. avec juste l’intercept). Attention, le modèle nul doit être ajusté sur les mêmes données que le modèle étudié…\n\ndataReg &lt;- na.omit(NHANES %&gt;% select(c(Diabetes.lvl,  Gender , Age, Race1, Education, MaritalStatus)))\nM0 &lt;- glm(Diabetes.lvl ~ 1, family = binomial, data = dataReg)\nsummary(M0)\n\n\nCall:\nglm(formula = Diabetes.lvl ~ 1, family = binomial, data = dataReg)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.07800    0.04302  -48.31   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 3816  on 5464  degrees of freedom\nResidual deviance: 3816  on 5464  degrees of freedom\nAIC: 3818\n\nNumber of Fisher Scoring iterations: 4\n\nanova(reg.log, M0, test = \"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: Diabetes.lvl ~ Gender + Age + Race1 + Education + MaritalStatus\nModel 2: Diabetes.lvl ~ 1\n  Resid. Df Resid. Dev  Df Deviance  Pr(&gt;Chi)    \n1      5449     3291.1                           \n2      5464     3816.0 -15  -524.84 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIci, on rejette H0 au seuil de 95%, les coefficients sont non tous nuls\nRappel Odd-ratio\nexemple extrait de https://larmarange.github.io/\nPour comprendre la notion de côte (odd en anglais), on peut se référer aux paris sportifs. Par exemple, lorsque les trois quarts des parieurs parient que le cheval A va remporter la course, on dit alors que ce cheval à une côte de trois contre un (trois personnes parient qu’il va gagner contre une personne qu’il va perdre). Prenons un autre cheval B: si les deux tiers pensent que le cheval B va perdre (donc un tiers pense qu’il va gagner), on dira alors que sa côte est de un contre deux (une personne pense qu’il va gagner contre deux qu’il va perdre).   Si l’on connait la proportion ou probabilité \\(p\\) d’avoir vécu ou de vivre un évènement donné (ici gagner la course), la côte (l’odd) s’obtient avec la formule suivante : \\(p/(1-p)\\).  \nLa côte du cheval A est bien \\(0.75/(1-0.75) = 6\\) est celle du cheval B \\((1/3)/(2/3)=1/2=0.5\\).\nPour comparer deux côtes (par exemple pour savoir si le cheval A a une probabilité plus élevée de remporter la course que le cheval B, selon les parieurs), on calculera tout simplement le rapport des côtes ou odds ratio (OR) : \\(OR_{A/B} ) = Odds_{A}/Odds_{B}=3/0.5=6\\).\nL’odds ratio est donc égal à 1 si les deux côtes sont identiques, est supérieur à 1 si le cheval A une probabilité supérieure à celle du cheval B, et inférieur à 1 si c’est probabilité est inférieure.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Logistique</span>"
    ]
  },
  {
    "objectID": "6.RegressionLogistique.html#extraction-des-données-de-la-régression",
    "href": "6.RegressionLogistique.html#extraction-des-données-de-la-régression",
    "title": "8  Regression Logistique",
    "section": "8.5 Extraction des données de la régression",
    "text": "8.5 Extraction des données de la régression\nPour extraire les coefficients, on utilise la commande reg$coefficients\n\ncoef &lt;- reg.log$coefficients\ncoef\n\n              (Intercept)                Gendermale                       Age \n               -4.0045560                 0.2796260                 0.0573795 \n            Race1Hispanic              Race1Mexican                Race1White \n               -0.2919157                -0.2516401                -0.8861893 \n               Race1Other   Education9 - 11th Grade      EducationHigh School \n               -0.1552541                -0.3693989                -0.4225817 \n    EducationSome College     EducationCollege Grad  MaritalStatusLivePartner \n               -0.2818723                -0.7115113                -0.7076618 \n     MaritalStatusMarried MaritalStatusNeverMarried    MaritalStatusSeparated \n               -0.2871693                -0.3551318                -0.1287680 \n     MaritalStatusWidowed \n               -0.4832160 \n\n\nPour obtenir les OR, il suffit de passer à l’exponentielle les coefficients. cela se fait avec la fonction exp()\n\nOR &lt;- exp(coef)\nOR\n\n              (Intercept)                Gendermale                       Age \n               0.01823238                1.32263509                1.05905765 \n            Race1Hispanic              Race1Mexican                Race1White \n               0.74683146                0.77752448                0.41222363 \n               Race1Other   Education9 - 11th Grade      EducationHigh School \n               0.85619756                0.69114965                0.65535269 \n    EducationSome College     EducationCollege Grad  MaritalStatusLivePartner \n               0.75437004                0.49090174                0.49279509 \n     MaritalStatusMarried MaritalStatusNeverMarried    MaritalStatusSeparated \n               0.75038466                0.70108105                0.87917791 \n     MaritalStatusWidowed \n               0.61679657 \n\n\nPour extraire les résidus, plusieurs options:\n\nUtiliser la commande reg$residuals\n\n\nreg.log$residuals[1:10] # ici je n'affiche que les 10 premiers pour ne pas encombrer le document\n\n        1         3         6         7         8         9        11        12 \n-1.034391 -1.046482 -1.036613 -1.248301 -1.136065 -1.114270 -1.194381 -1.092629 \n       14        15 \n-1.032473 -1.152880 \n\n\n\nUtiliser les fonctions residuals() ou resid()\n\n\nresiduals(reg.log)[1:10] \n\n         1          3          6          7          8          9         11 \n-0.2600485 -0.3014444 -0.2681746 -0.6660081 -0.5051157 -0.4651863 -0.5960334 \n        12         14         15 \n-0.4209207 -0.2528117 -0.5334106 \n\nresid(reg.log)[1:10]\n\n         1          3          6          7          8          9         11 \n-0.2600485 -0.3014444 -0.2681746 -0.6660081 -0.5051157 -0.4651863 -0.5960334 \n        12         14         15 \n-0.4209207 -0.2528117 -0.5334106 \n\n\nPour extraire les valeurs prédites de chaque observation, comme pour les résidus, il y a 2 options:\n\nUtiliser la commande reg$fitted.values\n\n\nreg.log$fitted.values[1:10]\n\n         1          3          6          7          8          9         11 \n0.03324736 0.04441766 0.03531996 0.19891115 0.11976901 0.10255116 0.16274611 \n        12         14         15 \n0.08477664 0.03145166 0.13260725 \n\n\n\nUtiliser les fonctions fitted() ou fitted.values()\n\n\nfitted(reg.log)[1:10] \n\n         1          3          6          7          8          9         11 \n0.03324736 0.04441766 0.03531996 0.19891115 0.11976901 0.10255116 0.16274611 \n        12         14         15 \n0.08477664 0.03145166 0.13260725 \n\nfitted.values(reg.log)[1:10]\n\n         1          3          6          7          8          9         11 \n0.03324736 0.04441766 0.03531996 0.19891115 0.11976901 0.10255116 0.16274611 \n        12         14         15 \n0.08477664 0.03145166 0.13260725 \n\n\nOn peut obtenir un tableau avec le résumé des coefficients (estimation, écart-type p-value, t-test) avec la fonction tidy() du package broom. Les bornes de l’intervalle de confiance à 95% peuvent être ajoutées en utilisant l’argument conf.int=TRUE. Et comme pour tout à l’heure, il faut ajouter l’argument exponentiate = TRUE pour avoir les OR. Pour un autre niveau de confiance, on peut ajouter l’argument conf.level = 0.99\n\ntab_summary &lt;- tidy(reg.log, conf.int = T, exponentiate = TRUE)\nhead(tab_summary)\n\n# A tibble: 6 × 7\n  term          estimate std.error statistic  p.value conf.low conf.high\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)     0.0182   0.309      -13.0  1.78e-38  0.00990    0.0332\n2 Gendermale      1.32     0.0946       2.96 3.11e- 3  1.10       1.59  \n3 Age             1.06     0.00347     16.5  2.72e-61  1.05       1.07  \n4 Race1Hispanic   0.747    0.211       -1.38 1.67e- 1  0.489      1.12  \n5 Race1Mexican    0.778    0.194       -1.29 1.95e- 1  0.529      1.13  \n6 Race1White      0.412    0.128       -6.90 5.15e-12  0.321      0.531",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Logistique</span>"
    ]
  },
  {
    "objectID": "6.RegressionLogistique.html#données-manquantes",
    "href": "6.RegressionLogistique.html#données-manquantes",
    "title": "8  Regression Logistique",
    "section": "8.6 Données manquantes",
    "text": "8.6 Données manquantes\nPar défaut, la fonction glm() supprime les observations pour lesquelles il y a une donnée manquante pour au moins une des variables du modèle.\nPour savoir combien d’observations ont été utilisées pour ajuster le modèle, on peut regarder la longueur du vecteur des résidus ou bien de celui des valeurs prédites\n\nlength(reg.log$residuals)\n\n[1] 5465\n\nlength(reg.log$fitted.values)\n\n[1] 5465\n\n\nAinsi dans cet exemple, sur les 7832 observations de notre jeu de données, seulement 7216 ont des données complètes sur les variables considérées et sont donc prises en compte pour ajuster le modèle.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Logistique</span>"
    ]
  },
  {
    "objectID": "6.RegressionLogistique.html#representation-graphique",
    "href": "6.RegressionLogistique.html#representation-graphique",
    "title": "8  Regression Logistique",
    "section": "8.7 Representation graphique",
    "text": "8.7 Representation graphique\nLa representation grahique est assez facile avec la fonction ggcoef_model du package GGally.\n\nlibrary(GGally)\nggcoef_model(reg.log, exponentiate = TRUE)\n\n\n\n\n\n\n\n\nOn peut également utliser le package forestmodel et la fonction forest_model .\n\nlibrary(forestmodel)\nforest_model(reg.log)\n\nWarning in recalculate_width_panels(panel_positions, mapped_text = mapped_text,\n: Unable to resize forest panel to be smaller than its heading; consider a\nsmaller text size",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Logistique</span>"
    ]
  },
  {
    "objectID": "6.RegressionLogistique.html#succesion-de-regression-logistiques-univariables",
    "href": "6.RegressionLogistique.html#succesion-de-regression-logistiques-univariables",
    "title": "8  Regression Logistique",
    "section": "8.8 Succesion de regression logistiques univariables",
    "text": "8.8 Succesion de regression logistiques univariables\nIl est possible d’effectuer rapidement une succession de regression logisitques univariées grâce à la fonction tbl_uvregresssion du package gtsummary.\n\ntbl_uvregression(data = NHANES, \n    y = Diabetes.lvl,\n    include = c(Gender, Age, Race1, Education, MaritalStatus),\n    method = glm,\n    method.args = list(family = binomial),\n    exponentiate = TRUE\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nN\nOR\n95% CI\np-value\n\n\n\n\nGender\n7,699\n\n\n\n\n\n\n\n\n    female\n\n\n—\n—\n\n\n\n\n    male\n\n\n1.11\n0.94, 1.31\n0.2\n\n\nAge\n7,699\n1.06\n1.05, 1.06\n&lt;0.001\n\n\nRace1\n7,699\n\n\n\n\n\n\n\n\n    Black\n\n\n—\n—\n\n\n\n\n    Hispanic\n\n\n0.72\n0.50, 1.02\n0.071\n\n\n    Mexican\n\n\n0.58\n0.42, 0.79\n&lt;0.001\n\n\n    White\n\n\n0.62\n0.50, 0.77\n&lt;0.001\n\n\n    Other\n\n\n0.75\n0.53, 1.03\n0.084\n\n\nEducation\n5,468\n\n\n\n\n\n\n\n\n    8th Grade\n\n\n—\n—\n\n\n\n\n    9 - 11th Grade\n\n\n0.49\n0.36, 0.68\n&lt;0.001\n\n\n    High School\n\n\n0.43\n0.32, 0.58\n&lt;0.001\n\n\n    Some College\n\n\n0.43\n0.32, 0.57\n&lt;0.001\n\n\n    College Grad\n\n\n0.28\n0.20, 0.37\n&lt;0.001\n\n\nMaritalStatus\n5,473\n\n\n\n\n\n\n\n\n    Divorced\n\n\n—\n—\n\n\n\n\n    LivePartner\n\n\n0.28\n0.17, 0.46\n&lt;0.001\n\n\n    Married\n\n\n0.74\n0.57, 0.97\n0.028\n\n\n    NeverMarried\n\n\n0.32\n0.22, 0.46\n&lt;0.001\n\n\n    Separated\n\n\n0.88\n0.50, 1.46\n0.6\n\n\n    Widowed\n\n\n1.69\n1.21, 2.37\n0.002\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Logistique</span>"
    ]
  },
  {
    "objectID": "6.RegressionLogistique.html#modèles-emboîtés",
    "href": "6.RegressionLogistique.html#modèles-emboîtés",
    "title": "8  Regression Logistique",
    "section": "8.9 Modèles emboîtés",
    "text": "8.9 Modèles emboîtés\nComme pour la regression linéaire, on peut utiliser la fonction update.\n\nreg.log.M2 &lt;- update(reg.log, .~.+ Work)\ntbl_regression(reg.log.M2,exponentiate = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nOR\n95% CI\np-value\n\n\n\n\nGender\n\n\n\n\n\n\n\n\n    female\n—\n—\n\n\n\n\n    male\n1.37\n1.14, 1.66\n&lt;0.001\n\n\nAge\n1.05\n1.05, 1.06\n&lt;0.001\n\n\nRace1\n\n\n\n\n\n\n\n\n    Black\n—\n—\n\n\n\n\n    Hispanic\n0.74\n0.48, 1.11\n0.2\n\n\n    Mexican\n0.79\n0.54, 1.15\n0.2\n\n\n    White\n0.41\n0.32, 0.53\n&lt;0.001\n\n\n    Other\n0.85\n0.58, 1.22\n0.4\n\n\nEducation\n\n\n\n\n\n\n\n\n    8th Grade\n—\n—\n\n\n\n\n    9 - 11th Grade\n0.68\n0.48, 0.98\n0.038\n\n\n    High School\n0.67\n0.48, 0.95\n0.024\n\n\n    Some College\n0.77\n0.56, 1.08\n0.13\n\n\n    College Grad\n0.52\n0.37, 0.74\n&lt;0.001\n\n\nMaritalStatus\n\n\n\n\n\n\n\n\n    Divorced\n—\n—\n\n\n\n\n    LivePartner\n0.48\n0.28, 0.80\n0.006\n\n\n    Married\n0.75\n0.56, 1.00\n0.043\n\n\n    NeverMarried\n0.66\n0.44, 0.97\n0.035\n\n\n    Separated\n0.90\n0.50, 1.55\n0.7\n\n\n    Widowed\n0.59\n0.41, 0.86\n0.006\n\n\nWork\n\n\n\n\n\n\n\n\n    Looking\n—\n—\n\n\n\n\n    NotWorking\n0.97\n0.58, 1.70\n&gt;0.9\n\n\n    Working\n0.72\n0.43, 1.25\n0.2\n\n\n\nAbbreviations: CI = Confidence Interval, OR = Odds Ratio",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Logistique</span>"
    ]
  },
  {
    "objectID": "6.RegressionLogistique.html#ressources",
    "href": "6.RegressionLogistique.html#ressources",
    "title": "8  Regression Logistique",
    "section": "8.10 Ressources",
    "text": "8.10 Ressources\n\nLe livre de joseph larmarrange Guide-R : https://larmarange.github.io/guide-R/analyses/regression-logistique-binaire.html",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Regression Logistique</span>"
    ]
  },
  {
    "objectID": "7.RegressionMultinomialeOrdinale.html",
    "href": "7.RegressionMultinomialeOrdinale.html",
    "title": "9  Régressions multinomiales et ordinales",
    "section": "",
    "text": "9.1 Import des données\nPour cette séance, nous allons utiliser le jeu de données NHANES disponible dans le package du même nom.  Il s’agit de données de santé provenant de l’enquête américaine National Health and Nutrition Examination Survey (NHANES). Il contient des données sociale, comportementales et de santé.   Une description des données est disponible dans le descriptif du package lien\nlibrary(NHANES)\ndata(\"NHANES\")\ndim(NHANES)\n\n[1] 10000    76\n\nkable(head(NHANES))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID\nSurveyYr\nGender\nAge\nAgeDecade\nAgeMonths\nRace1\nRace3\nEducation\nMaritalStatus\nHHIncome\nHHIncomeMid\nPoverty\nHomeRooms\nHomeOwn\nWork\nWeight\nLength\nHeadCirc\nHeight\nBMI\nBMICatUnder20yrs\nBMI_WHO\nPulse\nBPSysAve\nBPDiaAve\nBPSys1\nBPDia1\nBPSys2\nBPDia2\nBPSys3\nBPDia3\nTestosterone\nDirectChol\nTotChol\nUrineVol1\nUrineFlow1\nUrineVol2\nUrineFlow2\nDiabetes\nDiabetesAge\nHealthGen\nDaysPhysHlthBad\nDaysMentHlthBad\nLittleInterest\nDepressed\nnPregnancies\nnBabies\nAge1stBaby\nSleepHrsNight\nSleepTrouble\nPhysActive\nPhysActiveDays\nTVHrsDay\nCompHrsDay\nTVHrsDayChild\nCompHrsDayChild\nAlcohol12PlusYr\nAlcoholDay\nAlcoholYear\nSmokeNow\nSmoke100\nSmoke100n\nSmokeAge\nMarijuana\nAgeFirstMarij\nRegularMarij\nAgeRegMarij\nHardDrugs\nSexEver\nSexAge\nSexNumPartnLife\nSexNumPartYear\nSameSex\nSexOrientation\nPregnantNow\n\n\n\n\n51624\n2009_10\nmale\n34\n30-39\n409\nWhite\nNA\nHigh School\nMarried\n25000-34999\n30000\n1.36\n6\nOwn\nNotWorking\n87.4\nNA\nNA\n164.7\n32.22\nNA\n30.0_plus\n70\n113\n85\n114\n88\n114\n88\n112\n82\nNA\n1.29\n3.49\n352\nNA\nNA\nNA\nNo\nNA\nGood\n0\n15\nMost\nSeveral\nNA\nNA\nNA\n4\nYes\nNo\nNA\nNA\nNA\nNA\nNA\nYes\nNA\n0\nNo\nYes\nSmoker\n18\nYes\n17\nNo\nNA\nYes\nYes\n16\n8\n1\nNo\nHeterosexual\nNA\n\n\n51624\n2009_10\nmale\n34\n30-39\n409\nWhite\nNA\nHigh School\nMarried\n25000-34999\n30000\n1.36\n6\nOwn\nNotWorking\n87.4\nNA\nNA\n164.7\n32.22\nNA\n30.0_plus\n70\n113\n85\n114\n88\n114\n88\n112\n82\nNA\n1.29\n3.49\n352\nNA\nNA\nNA\nNo\nNA\nGood\n0\n15\nMost\nSeveral\nNA\nNA\nNA\n4\nYes\nNo\nNA\nNA\nNA\nNA\nNA\nYes\nNA\n0\nNo\nYes\nSmoker\n18\nYes\n17\nNo\nNA\nYes\nYes\n16\n8\n1\nNo\nHeterosexual\nNA\n\n\n51624\n2009_10\nmale\n34\n30-39\n409\nWhite\nNA\nHigh School\nMarried\n25000-34999\n30000\n1.36\n6\nOwn\nNotWorking\n87.4\nNA\nNA\n164.7\n32.22\nNA\n30.0_plus\n70\n113\n85\n114\n88\n114\n88\n112\n82\nNA\n1.29\n3.49\n352\nNA\nNA\nNA\nNo\nNA\nGood\n0\n15\nMost\nSeveral\nNA\nNA\nNA\n4\nYes\nNo\nNA\nNA\nNA\nNA\nNA\nYes\nNA\n0\nNo\nYes\nSmoker\n18\nYes\n17\nNo\nNA\nYes\nYes\n16\n8\n1\nNo\nHeterosexual\nNA\n\n\n51625\n2009_10\nmale\n4\n0-9\n49\nOther\nNA\nNA\nNA\n20000-24999\n22500\n1.07\n9\nOwn\nNA\n17.0\nNA\nNA\n105.4\n15.30\nNA\n12.0_18.5\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNo\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n4\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n51630\n2009_10\nfemale\n49\n40-49\n596\nWhite\nNA\nSome College\nLivePartner\n35000-44999\n40000\n1.91\n5\nRent\nNotWorking\n86.7\nNA\nNA\n168.4\n30.57\nNA\n30.0_plus\n86\n112\n75\n118\n82\n108\n74\n116\n76\nNA\n1.16\n6.70\n77\n0.094\nNA\nNA\nNo\nNA\nGood\n0\n10\nSeveral\nSeveral\n2\n2\n27\n8\nYes\nNo\nNA\nNA\nNA\nNA\nNA\nYes\n2\n20\nYes\nYes\nSmoker\n38\nYes\n18\nNo\nNA\nYes\nYes\n12\n10\n1\nYes\nHeterosexual\nNA\n\n\n51638\n2009_10\nmale\n9\n0-9\n115\nWhite\nNA\nNA\nNA\n75000-99999\n87500\n1.84\n6\nRent\nNA\n29.8\nNA\nNA\n133.1\n16.82\nNA\n12.0_18.5\n82\n86\n47\n84\n50\n84\n50\n88\n44\nNA\n1.34\n4.86\n123\n1.538\nNA\nNA\nNo\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nDans ces données il semble y avoir des doublons. Nous allons les supprimer en utilisant la fonction distinct() de dplyr. Cette fonction ne garde qu’une ligne pour un groupe de lignes qui sont absolument identiques\nNHANES &lt;- NHANES %&gt;% distinct()\ndim(NHANES)\n\n[1] 7832   76\nNous sommes passés de 10000 à 7155 observations\nRésumé des données\nsummary(NHANES)\n\n       ID           SurveyYr       Gender          Age          AgeDecade   \n Min.   :51624   2009_10:3568   female:3943   Min.   : 0.00    0-9   :1212  \n 1st Qu.:57388   2011_12:4264   male  :3889   1st Qu.:16.00    10-19 :1142  \n Median :62914                                Median :35.00    30-39 :1038  \n Mean   :62369                                Mean   :35.97    20-29 :1023  \n 3rd Qu.:67408                                3rd Qu.:54.00    40-49 :1010  \n Max.   :71915                                Max.   :80.00   (Other):2124  \n                                                              NA's   : 283  \n   AgeMonths          Race1           Race3               Education   \n Min.   :  0.0   Black   :1073   Asian   : 281   8th Grade     : 397  \n 1st Qu.:169.0   Hispanic: 538   Black   : 563   9 - 11th Grade: 712  \n Median :387.0   Mexican : 920   Hispanic: 317   High School   :1131  \n Mean   :403.1   White   :4626   Mexican : 451   Some College  :1695  \n 3rd Qu.:615.0   Other   : 675   White   :2510   College Grad  :1534  \n Max.   :959.0                   Other   : 142   NA's          :2363  \n NA's   :4271                    NA's    :3568                        \n      MaritalStatus         HHIncome     HHIncomeMid        Poverty     \n Divorced    : 516   more 99999 :1588   Min.   :  2500   Min.   :0.000  \n LivePartner : 438   75000-99999: 809   1st Qu.: 22500   1st Qu.:1.130  \n Married     :2940   25000-34999: 784   Median : 50000   Median :2.400  \n NeverMarried:1048   35000-44999: 691   Mean   : 54862   Mean   :2.664  \n Separated   : 148   45000-54999: 596   3rd Qu.: 87500   3rd Qu.:4.500  \n Widowed     : 384   (Other)    :2711   Max.   :100000   Max.   :5.000  \n NA's        :2358   NA's       : 653   NA's   :653      NA's   :578    \n   HomeRooms       HomeOwn             Work          Weight      \n Min.   : 1.000   Own  :4845   Looking   : 244   Min.   :  2.80  \n 1st Qu.: 5.000   Rent :2753   NotWorking:2290   1st Qu.: 54.35  \n Median : 6.000   Other: 184   Working   :3376   Median : 71.60  \n Mean   : 6.173   NA's :  50   NA's      :1922   Mean   : 69.67  \n 3rd Qu.: 7.000                                  3rd Qu.: 87.90  \n Max.   :13.000                                  Max.   :230.70  \n NA's   :54                                      NA's   :61      \n     Length          HeadCirc         Height           BMI       \n Min.   : 47.10   Min.   :34.20   Min.   : 83.6   Min.   :12.88  \n 1st Qu.: 75.15   1st Qu.:39.50   1st Qu.:155.8   1st Qu.:21.40  \n Median : 87.05   Median :41.30   Median :165.4   Median :25.83  \n Mean   : 84.89   Mean   :41.10   Mean   :160.9   Mean   :26.52  \n 3rd Qu.: 95.80   3rd Qu.:42.98   3rd Qu.:173.9   3rd Qu.:30.64  \n Max.   :112.20   Max.   :45.40   Max.   :200.4   Max.   :81.25  \n NA's   :7334     NA's   :7750    NA's   :317     NA's   :327    \n    BMICatUnder20yrs         BMI_WHO         Pulse           BPSysAve    \n UnderWeight:  47    12.0_18.5   :1070   Min.   : 40.00   Min.   : 76.0  \n NormWeight : 709    18.5_to_24.9:2261   1st Qu.: 66.00   1st Qu.:106.0  \n OverWeight : 180    25.0_to_29.9:2067   Median : 72.00   Median :116.0  \n Obese      : 197    30.0_plus   :2081   Mean   : 73.58   Mean   :118.1  \n NA's       :6699    NA's        : 353   3rd Qu.: 82.00   3rd Qu.:127.0  \n                                         Max.   :136.00   Max.   :226.0  \n                                         NA's   :1236     NA's   :1246   \n    BPDiaAve          BPSys1         BPDia1          BPSys2     \n Min.   :  0.00   Min.   : 72    Min.   :  0.0   Min.   : 76.0  \n 1st Qu.: 60.00   1st Qu.:106    1st Qu.: 60.0   1st Qu.:106.0  \n Median : 68.00   Median :116    Median : 68.0   Median :116.0  \n Mean   : 67.03   Mean   :119    Mean   : 67.9   Mean   :118.4  \n 3rd Qu.: 76.00   3rd Qu.:128    3rd Qu.: 76.0   3rd Qu.:128.0  \n Max.   :116.00   Max.   :232    Max.   :118.0   Max.   :226.0  \n NA's   :1246     NA's   :1497   NA's   :1497    NA's   :1404   \n     BPDia2           BPSys3          BPDia3        Testosterone    \n Min.   :  0.00   Min.   : 76.0   Min.   :  0.00   Min.   :   0.25  \n 1st Qu.: 60.00   1st Qu.:106.0   1st Qu.: 60.00   1st Qu.:  17.53  \n Median : 68.00   Median :116.0   Median : 68.00   Median :  40.69  \n Mean   : 67.19   Mean   :117.9   Mean   : 66.83   Mean   : 193.72  \n 3rd Qu.: 76.00   3rd Qu.:126.0   3rd Qu.: 76.00   3rd Qu.: 352.32  \n Max.   :118.00   Max.   :226.0   Max.   :116.00   Max.   :1795.60  \n NA's   :1404     NA's   :1400    NA's   :1400     NA's   :4354     \n   DirectChol       TotChol         UrineVol1       UrineFlow1     \n Min.   :0.390   Min.   : 1.530   Min.   :  0.0   Min.   : 0.0000  \n 1st Qu.:1.090   1st Qu.: 4.060   1st Qu.: 49.0   1st Qu.: 0.3970  \n Median :1.290   Median : 4.730   Median : 92.0   Median : 0.6820  \n Mean   :1.359   Mean   : 4.841   Mean   :117.1   Mean   : 0.9649  \n 3rd Qu.:1.580   3rd Qu.: 5.480   3rd Qu.:162.0   3rd Qu.: 1.2130  \n Max.   :4.030   Max.   :13.650   Max.   :510.0   Max.   :17.1670  \n NA's   :1296    NA's   :1296     NA's   :865     NA's   :1340     \n   UrineVol2       UrineFlow2     Diabetes     DiabetesAge        HealthGen   \n Min.   :  0.0   Min.   : 0.000   No  :7077   Min.   : 1.00   Excellent: 661  \n 1st Qu.: 50.0   1st Qu.: 0.482   Yes : 622   1st Qu.:40.00   Vgood    :1848  \n Median : 92.5   Median : 0.765   NA's: 133   Median :50.00   Good     :2272  \n Mean   :119.5   Mean   : 1.154               Mean   :49.07   Fair     : 829  \n 3rd Qu.:171.8   3rd Qu.: 1.507               3rd Qu.:60.00   Poor     : 155  \n Max.   :409.0   Max.   :13.692               Max.   :80.00   NA's     :2067  \n NA's   :6670    NA's   :6671                 NA's   :7315                    \n DaysPhysHlthBad  DaysMentHlthBad  LittleInterest   Depressed   \n Min.   : 0.000   Min.   : 0.000   None   :3837   None   :3937  \n 1st Qu.: 0.000   1st Qu.: 0.000   Several: 869   Several: 783  \n Median : 0.000   Median : 0.000   Most   : 343   Most   : 331  \n Mean   : 3.423   Mean   : 4.112   NA's   :2783   NA's   :2781  \n 3rd Qu.: 3.000   3rd Qu.: 4.000                                \n Max.   :30.000   Max.   :30.000                                \n NA's   :2074     NA's   :2072                                  \n  nPregnancies       nBabies         Age1stBaby    SleepHrsNight   \n Min.   : 1.000   Min.   : 0.000   Min.   :14.00   Min.   : 2.000  \n 1st Qu.: 2.000   1st Qu.: 2.000   1st Qu.:19.00   1st Qu.: 6.000  \n Median : 3.000   Median : 2.000   Median :22.00   Median : 7.000  \n Mean   : 3.087   Mean   : 2.503   Mean   :22.48   Mean   : 6.904  \n 3rd Qu.: 4.000   3rd Qu.: 3.000   3rd Qu.:25.00   3rd Qu.: 8.000  \n Max.   :32.000   Max.   :12.000   Max.   :39.00   Max.   :12.000  \n NA's   :5840     NA's   :5986     NA's   :6375    NA's   :1935    \n SleepTrouble PhysActive  PhysActiveDays       TVHrsDay        CompHrsDay  \n No  :4430    No  :2853   Min.   :1.000   2_hr     :1082   0_to_1_hr:1194  \n Yes :1481    Yes :3521   1st Qu.:2.000   1_hr     : 741   0_hrs    : 953  \n NA's:1921    NA's:1458   Median :3.000   3_hr     : 727   1_hr     : 844  \n                          Mean   :3.753   0_to_1_hr: 526   2_hr     : 491  \n                          3rd Qu.:5.000   More_4_hr: 524   3_hr     : 298  \n                          Max.   :7.000   (Other)  : 528   (Other)  : 352  \n                          NA's   :4019    NA's     :3704   NA's     :3700  \n TVHrsDayChild   CompHrsDayChild Alcohol12PlusYr   AlcoholDay    \n Min.   :0.000   Min.   :0.000   No  :1087       Min.   : 1.000  \n 1st Qu.:1.000   1st Qu.:0.000   Yes :3892       1st Qu.: 1.000  \n Median :2.000   Median :1.000   NA's:2853       Median : 2.000  \n Mean   :1.979   Mean   :2.255                   Mean   : 2.947  \n 3rd Qu.:3.000   3rd Qu.:6.000                   3rd Qu.: 3.000  \n Max.   :6.000   Max.   :6.000                   Max.   :82.000  \n NA's   :7298    NA's   :7298                    NA's   :4160    \n  AlcoholYear     SmokeNow    Smoke100         Smoke100n       SmokeAge    \n Min.   :  0.00   No  :1307   No  :3055   Non-Smoker:3055   Min.   : 6.00  \n 1st Qu.:  3.00   Yes :1116   Yes :2423   Smoker    :2423   1st Qu.:15.00  \n Median : 24.00   NA's:5409   NA's:2354   NA's      :2354   Median :17.00  \n Mean   : 73.33                                             Mean   :17.75  \n 3rd Qu.:104.00                                             3rd Qu.:19.00  \n Max.   :364.00                                             Max.   :72.00  \n NA's   :3388                                               NA's   :5507   \n Marijuana   AgeFirstMarij   RegularMarij  AgeRegMarij    HardDrugs  \n No  :1573   Min.   : 1.00   No  :2679    Min.   : 5.00   No  :3547  \n Yes :2096   1st Qu.:15.00   Yes : 990    1st Qu.:15.00   Yes : 764  \n NA's:4163   Median :16.00   NA's:4163    Median :17.00   NA's:3521  \n             Mean   :17.02                Mean   :17.65              \n             3rd Qu.:18.00                3rd Qu.:19.00              \n             Max.   :48.00                Max.   :52.00              \n             NA's   :5737                 NA's   :6842               \n SexEver         SexAge      SexNumPartnLife  SexNumPartYear   SameSex    \n No  : 175   Min.   : 9.00   Min.   :   0.0   Min.   : 0.000   No  :4000  \n Yes :4137   1st Qu.:15.00   1st Qu.:   2.0   1st Qu.: 1.000   Yes : 312  \n NA's:3520   Median :17.00   Median :   5.0   Median : 1.000   NA's:3520  \n             Mean   :17.41   Mean   :  15.4   Mean   : 1.327              \n             3rd Qu.:19.00   3rd Qu.:  12.0   3rd Qu.: 1.000              \n             Max.   :50.00   Max.   :2000.0   Max.   :69.000              \n             NA's   :3699    NA's   :3552     NA's   :4172                \n      SexOrientation  PregnantNow  \n Bisexual    :  91   Yes    :  54  \n Heterosexual:3426   No     :1197  \n Homosexual  :  70   Unknown:  41  \n NA's        :4245   NA's   :6540",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Régressions multinomiales et ordinales</span>"
    ]
  },
  {
    "objectID": "7.RegressionMultinomialeOrdinale.html#régression-polytomique-nominale-multinomiale",
    "href": "7.RegressionMultinomialeOrdinale.html#régression-polytomique-nominale-multinomiale",
    "title": "9  Régressions multinomiales et ordinales",
    "section": "9.2 Régression polytomique nominale / multinomiale",
    "text": "9.2 Régression polytomique nominale / multinomiale\nLe modèle polytomique nominal, aussi appelé modèle multinomial permet de généraliser la régression logistique au cas ou \\(Y\\) a plus de 2 modalités. Il considère qu’il n’y a pas de hiérarchies entre les différentes catégories. Ainsi, pour une modalité \\(k\\) de Y, on modélise \\[logit(\\mathbb{p}(Y=k)) = log \\left( \\frac{\\mathbb{P}(Y=k | X)}{\\mathbb{P}(Y=Y_{ref} | X)} \\right) = \\beta_{0k}+\\beta_{1k}X_1 + ... + \\beta_{pk}X_p\\] avec $Y_{ref} la modalité de référence de Y  Si \\(Y\\) à \\(K\\) modalité, cela revient à modéliser \\(K-1\\) régressions logistiques.  \nPour illustrer cette partie, nous allons éudier la variable BMI_WHO qui comporte 4 modalités correspondant à souspoids, poids normal, surpoids et obésité.\n\ntable(NHANES$BMI_WHO, useNA = \"ifany\")\n\n\n   12.0_18.5 18.5_to_24.9 25.0_to_29.9    30.0_plus         &lt;NA&gt; \n        1070         2261         2067         2081          353 \n\n\nComme nous faisons un modèle multinomial, nous n’allons pas considérer les catégories comme ordonnées.   Pour les variables explicatives, nous allons prendre les mêmes que dans la séance précédente : l’âge, le sexe, l’ethnicité, le niveau d’éducation et le statut marital et le revenu.   Comme pour la régression linéaire, il ne faut pas de données manquantes, nous allons donc travailler sur cas complet\n\ndataReg &lt;- na.omit(NHANES %&gt;% select(c(BMI_WHO,  Gender , Age, Race1, Education, MaritalStatus, HHIncomeMid)))\n\nIl n’y a pas de fonction en R base pour réaliser une régression multinomiale, il faut donc importer un package. 2 packages sont majoritairement utilisés :  - nnet avec sa fonction multinial() et  - VGAM avec sa fonction vglm()  Je vais ici présenter le package VGAM\n\n9.2.1 Modélisation avec le package VGAM\n Attention :  La fonction vglm() utilise la dernière catégorie comme référence\n\nlevels(dataReg$BMI_WHO)\n\n[1] \"12.0_18.5\"    \"18.5_to_24.9\" \"25.0_to_29.9\" \"30.0_plus\"   \n\n\nIci 30.0_plus est utilisée comme modalité de référence  On peut changer la référence, par exemple “18.5_to_24.9” en réordonnant les modalités\n\nreg &lt;- vglm(BMI_WHO ~ Gender + Age + Race1 + Education + MaritalStatus + HHIncomeMid, data=dataReg, family = multinomial)\nsummary(reg)\n\n\nCall:\nvglm(formula = BMI_WHO ~ Gender + Age + Race1 + Education + MaritalStatus + \n    HHIncomeMid, family = multinomial, data = dataReg)\n\nCoefficients: \n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept):1               -2.213e+00  9.149e-01      NA       NA    \n(Intercept):2               -1.059e+00  2.775e-01  -3.818 0.000135 ***\n(Intercept):3               -1.230e+00  2.483e-01  -4.954 7.26e-07 ***\nGendermale:1                -1.041e+00  2.751e-01  -3.783 0.000155 ***\nGendermale:2                -2.041e-01  7.482e-02  -2.728 0.006373 ** \nGendermale:3                 3.035e-01  7.069e-02   4.294 1.76e-05 ***\nAge:1                       -1.424e-02  9.221e-03  -1.544 0.122616    \nAge:2                       -7.847e-03  2.640e-03  -2.972 0.002954 ** \nAge:3                        4.778e-03  2.472e-03   1.933 0.053211 .  \nRace1Hispanic:1             -1.437e+01  3.703e+02      NA       NA    \nRace1Hispanic:2              3.838e-01  1.876e-01   2.046 0.040777 *  \nRace1Hispanic:3              5.488e-01  1.659e-01   3.307 0.000942 ***\nRace1Mexican:1              -5.094e-01  5.977e-01  -0.852 0.394060    \nRace1Mexican:2               3.168e-02  1.767e-01   0.179 0.857711    \nRace1Mexican:3               4.201e-01  1.502e-01   2.797 0.005151 ** \nRace1White:1                 4.299e-01  3.335e-01   1.289 0.197328    \nRace1White:2                 8.103e-01  1.184e-01   6.844 7.71e-12 ***\nRace1White:3                 5.365e-01  1.077e-01   4.981 6.31e-07 ***\nRace1Other:1                 1.340e+00  4.551e-01   2.943 0.003246 ** \nRace1Other:2                 1.567e+00  1.739e-01   9.009  &lt; 2e-16 ***\nRace1Other:3                 8.897e-01  1.747e-01   5.091 3.56e-07 ***\nEducation9 - 11th Grade:1   -1.479e-01  7.195e-01  -0.205 0.837187    \nEducation9 - 11th Grade:2    1.286e-01  1.910e-01   0.673 0.500846    \nEducation9 - 11th Grade:3    1.214e-02  1.626e-01   0.075 0.940513    \nEducationHigh School:1       3.826e-01  6.534e-01   0.586 0.558169    \nEducationHigh School:2       2.488e-02  1.814e-01   0.137 0.890935    \nEducationHigh School:3      -5.283e-02  1.543e-01  -0.342 0.731998    \nEducationSome College:1     -1.660e-01  6.572e-01  -0.253 0.800552    \nEducationSome College:2     -2.447e-02  1.780e-01  -0.138 0.890630    \nEducationSome College:3     -2.843e-01  1.530e-01  -1.858 0.063202 .  \nEducationCollege Grad:1      1.844e-01  6.755e-01   0.273 0.784887    \nEducationCollege Grad:2      4.160e-01  1.857e-01   2.240 0.025069 *  \nEducationCollege Grad:3      1.144e-01  1.619e-01   0.706 0.479989    \nMaritalStatusLivePartner:1   2.856e-01  4.853e-01   0.588 0.556232    \nMaritalStatusLivePartner:2   5.630e-01  1.896e-01   2.969 0.002988 ** \nMaritalStatusLivePartner:3   4.876e-01  1.714e-01   2.845 0.004437 ** \nMaritalStatusMarried:1      -1.154e+00  3.920e-01  -2.945 0.003235 ** \nMaritalStatusMarried:2       3.142e-01  1.366e-01   2.300 0.021472 *  \nMaritalStatusMarried:3       1.081e-01  1.221e-01   0.886 0.375703    \nMaritalStatusNeverMarried:1  2.607e-01  4.040e-01   0.645 0.518664    \nMaritalStatusNeverMarried:2  6.397e-01  1.564e-01   4.091 4.29e-05 ***\nMaritalStatusNeverMarried:3  1.189e-01  1.467e-01   0.811 0.417583    \nMaritalStatusSeparated:1    -2.725e-01  7.921e-01  -0.344 0.730847    \nMaritalStatusSeparated:2     4.554e-01  2.575e-01   1.768 0.077000 .  \nMaritalStatusSeparated:3    -9.038e-03  2.455e-01  -0.037 0.970634    \nMaritalStatusWidowed:1      -2.133e-01  5.510e-01  -0.387 0.698605    \nMaritalStatusWidowed:2       2.102e-01  1.999e-01   1.052 0.292851    \nMaritalStatusWidowed:3       1.764e-01  1.745e-01   1.011 0.311981    \nHHIncomeMid:1                1.703e-06  4.104e-06   0.415 0.678250    \nHHIncomeMid:2                1.683e-06  1.304e-06   1.290 0.197007    \nHHIncomeMid:3                4.228e-06  1.249e-06   3.384 0.000714 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nNames of linear predictors: log(mu[,1]/mu[,4]), log(mu[,2]/mu[,4]), \nlog(mu[,3]/mu[,4])\n\nResidual deviance: 10987.81 on 14745 degrees of freedom\n\nLog-likelihood: -5493.905 on 14745 degrees of freedom\n\nNumber of Fisher scoring iterations: 17 \n\nWarning: Hauck-Donner effect detected in the following estimate(s):\n'(Intercept):1', 'Race1Hispanic:1'\n\n\nReference group is level  4  of the response\n\n\n Attention :  La fonction vglm() utilise la dernière catégorie comme référence  On peut changer la référence, par exemple “18.5_to_24.9” en réordonnant spécifiant le numéro de la modalité de référence avec l’argument family = multinomial(refLevel = )\n\nreg &lt;- vglm(BMI_WHO ~ Gender + Age + Race1 + Education + MaritalStatus + HHIncomeMid, data=dataReg, family = multinomial(refLevel = 2))\nsummary(reg)\n\n\nCall:\nvglm(formula = BMI_WHO ~ Gender + Age + Race1 + Education + MaritalStatus + \n    HHIncomeMid, family = multinomial(refLevel = 2), data = dataReg)\n\nCoefficients: \n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept):1               -1.154e+00  9.235e-01  -1.249 0.211483    \n(Intercept):2               -1.707e-01  2.871e-01  -0.594 0.552181    \n(Intercept):3                1.059e+00  2.775e-01   3.818 0.000135 ***\nGendermale:1                -8.365e-01  2.758e-01  -3.033 0.002419 ** \nGendermale:2                 5.076e-01  7.558e-02   6.716 1.86e-11 ***\nGendermale:3                 2.041e-01  7.482e-02   2.728 0.006373 ** \nAge:1                       -6.390e-03  9.256e-03  -0.690 0.489958    \nAge:2                        1.262e-02  2.660e-03   4.745 2.08e-06 ***\nAge:3                        7.847e-03  2.640e-03   2.972 0.002954 ** \nRace1Hispanic:1             -1.475e+01  3.703e+02      NA       NA    \nRace1Hispanic:2              1.650e-01  1.967e-01   0.839 0.401511    \nRace1Hispanic:3             -3.838e-01  1.876e-01  -2.046 0.040777 *  \nRace1Mexican:1              -5.411e-01  6.070e-01  -0.891 0.372712    \nRace1Mexican:2               3.884e-01  1.881e-01   2.065 0.038905 *  \nRace1Mexican:3              -3.168e-02  1.767e-01  -0.179 0.857711    \nRace1White:1                -3.804e-01  3.400e-01  -1.119 0.263209    \nRace1White:2                -2.738e-01  1.300e-01  -2.107 0.035148 *  \nRace1White:3                -8.103e-01  1.184e-01  -6.844 7.71e-12 ***\nRace1Other:1                -2.276e-01  4.522e-01  -0.503 0.614753    \nRace1Other:2                -6.775e-01  1.725e-01  -3.927 8.61e-05 ***\nRace1Other:3                -1.567e+00  1.739e-01  -9.009  &lt; 2e-16 ***\nEducation9 - 11th Grade:1   -2.764e-01  7.244e-01  -0.382 0.702778    \nEducation9 - 11th Grade:2   -1.164e-01  1.922e-01  -0.606 0.544649    \nEducation9 - 11th Grade:3   -1.286e-01  1.910e-01  -0.673 0.500846    \nEducationHigh School:1       3.577e-01  6.582e-01   0.543 0.586808    \nEducationHigh School:2      -7.771e-02  1.828e-01  -0.425 0.670732    \nEducationHigh School:3      -2.488e-02  1.814e-01  -0.137 0.890935    \nEducationSome College:1     -1.416e-01  6.615e-01  -0.214 0.830565    \nEducationSome College:2     -2.598e-01  1.800e-01  -1.443 0.148985    \nEducationSome College:3      2.447e-02  1.780e-01   0.138 0.890630    \nEducationCollege Grad:1     -2.316e-01  6.789e-01  -0.341 0.733017    \nEducationCollege Grad:2     -3.016e-01  1.852e-01  -1.629 0.103397    \nEducationCollege Grad:3     -4.160e-01  1.857e-01  -2.240 0.025069 *  \nMaritalStatusLivePartner:1  -2.774e-01  4.902e-01  -0.566 0.571389    \nMaritalStatusLivePartner:2  -7.541e-02  1.897e-01  -0.398 0.690994    \nMaritalStatusLivePartner:3  -5.630e-01  1.896e-01  -2.969 0.002988 ** \nMaritalStatusMarried:1      -1.469e+00  3.978e-01  -3.691 0.000223 ***\nMaritalStatusMarried:2      -2.061e-01  1.426e-01  -1.445 0.148508    \nMaritalStatusMarried:3      -3.142e-01  1.366e-01  -2.300 0.021472 *  \nMaritalStatusNeverMarried:1 -3.790e-01  4.092e-01  -0.926 0.354338    \nMaritalStatusNeverMarried:2 -5.208e-01  1.636e-01  -3.183 0.001458 ** \nMaritalStatusNeverMarried:3 -6.397e-01  1.564e-01  -4.091 4.29e-05 ***\nMaritalStatusSeparated:1    -7.279e-01  8.010e-01  -0.909 0.363513    \nMaritalStatusSeparated:2    -4.644e-01  2.777e-01  -1.672 0.094485 .  \nMaritalStatusSeparated:3    -4.554e-01  2.575e-01  -1.768 0.077000 .  \nMaritalStatusWidowed:1      -4.236e-01  5.607e-01  -0.755 0.449999    \nMaritalStatusWidowed:2      -3.381e-02  2.061e-01  -0.164 0.869713    \nMaritalStatusWidowed:3      -2.102e-01  1.999e-01  -1.052 0.292851    \nHHIncomeMid:1                1.963e-08  4.111e-06   0.005 0.996190    \nHHIncomeMid:2                2.545e-06  1.321e-06   1.926 0.054107 .  \nHHIncomeMid:3               -1.683e-06  1.304e-06  -1.290 0.197007    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nNames of linear predictors: log(mu[,1]/mu[,2]), log(mu[,3]/mu[,2]), \nlog(mu[,4]/mu[,2])\n\nResidual deviance: 10987.81 on 14745 degrees of freedom\n\nLog-likelihood: -5493.905 on 14745 degrees of freedom\n\nNumber of Fisher scoring iterations: 17 \n\nWarning: Hauck-Donner effect detected in the following estimate(s):\n'Race1Hispanic:1'\n\n\nReference group is level  2  of the response\n\n\nRemarque : Il est parfois conseiller de modifier le format du dataset avant d’utiliser la fonction vglm()\n\nVoici comment créer ce tableau de fréquences :\n\nmyfreq &lt;- dataReg %&gt;%\n  group_by(Gender , Age, Race1, Education, MaritalStatus, HHIncomeMid) %&gt;%\n  summarise(Y0 = sum(BMI_WHO==\"12.0_18.5\"),\n            Y1 = sum(BMI_WHO==\"18.5_to_24.9\"),\n            Y2 = sum(BMI_WHO==\"25.0_to_29.9\"),\n            Y3 = sum(BMI_WHO==\"30.0_plus\"))\n\n`summarise()` has grouped output by 'Gender', 'Age', 'Race1', 'Education',\n'MaritalStatus'. You can override using the `.groups` argument.\n\n\nEn pratique, les estimations ne changent pas mais les degrés de libertés sont différents. Parfois, on peut obtenir une erreur si le dataset n’a pas ce format.\n\n\n9.2.2 Les tests\n\nTest de nullité de chaque coefficient\nDans la sortie de summary(), on a la p-valeur associée au test de nullité du coefficient (associé à la modalité et non pas à la variable pour les variables catégorielles).\n\n\nTest de l’effet global d’une variable\nPour les variables continues, le test de l’effet global est le même que celui de nullité du coefficient donné dans la fonction summary()   Pour les variables catégorielles, on peut tester si elle un un effet sur la probabilité d’observer Y=Yref sachant les autres variables dans le modèle avec le test de type III. On l’obtient avec la fonction anova() ( Avec un ‘a’ minuscule , à ne pas confondre avec Anova() du package car utilisée pour la régression logistique. Il s’agit d’un recodage de la fonction anova() de base pour le package VGAM)\n\nanova(reg, type = 3)\n\nAnalysis of Deviance Table (Type III tests: each term added last)\n\nModel: 'multinomial', 'VGAMcategorical'\n\nLink: 'multilogitlink'\n\nResponse: BMI_WHO\n\n              Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nGender         3   64.555     14748      11052 6.244e-14 ***\nAge            3   24.977     14748      11013 1.561e-05 ***\nRace1         12  145.812     14757      11134 &lt; 2.2e-16 ***\nEducation     12   35.762     14757      11024 0.0003538 ***\nMaritalStatus 15   51.026     14760      11039 8.174e-06 ***\nHHIncomeMid    3   11.576     14748      10999 0.0089846 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nTest de nullité de tous les coefficients\nLe test du rapport de vraissemblance permet de tester la nullité de tous les coefficients (sauf l’intercept). Il est obtenu avec la fonction lrtest_vglm() du package VGAM\n\nlrtest_vglm(reg)\n\nLikelihood ratio test\n\nModel 1: BMI_WHO ~ Gender + Age + Race1 + Education + MaritalStatus + \n    HHIncomeMid\nModel 2: BMI_WHO ~ 1\n    #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1 14745 -5493.9                         \n2 14793 -5701.8 48 415.84  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n9.2.3 Odds-ratio\nOn obtient les odds-ratio en passant à l’exponentielle les coefficients obtenus.\n\nexp(coef(reg))\n\n              (Intercept):1               (Intercept):2 \n               3.154122e-01                8.430974e-01 \n              (Intercept):3                Gendermale:1 \n               2.884927e+00                4.332054e-01 \n               Gendermale:2                Gendermale:3 \n               1.661299e+00                1.226418e+00 \n                      Age:1                       Age:2 \n               9.936304e-01                1.012705e+00 \n                      Age:3             Race1Hispanic:1 \n               1.007878e+00                3.910247e-07 \n            Race1Hispanic:2             Race1Hispanic:3 \n               1.179377e+00                6.812758e-01 \n             Race1Mexican:1              Race1Mexican:2 \n               5.820965e-01                1.474650e+00 \n             Race1Mexican:3                Race1White:1 \n               9.688126e-01                6.836143e-01 \n               Race1White:2                Race1White:3 \n               7.604954e-01                4.447414e-01 \n               Race1Other:1                Race1Other:2 \n               7.964648e-01                5.079013e-01 \n               Race1Other:3   Education9 - 11th Grade:1 \n               2.086389e-01                7.584995e-01 \n  Education9 - 11th Grade:2   Education9 - 11th Grade:3 \n               8.900998e-01                8.793622e-01 \n     EducationHigh School:1      EducationHigh School:2 \n               1.430054e+00                9.252339e-01 \n     EducationHigh School:3     EducationSome College:1 \n               9.754312e-01                8.680117e-01 \n    EducationSome College:2     EducationSome College:3 \n               7.712196e-01                1.024772e+00 \n    EducationCollege Grad:1     EducationCollege Grad:2 \n               7.932746e-01                7.396337e-01 \n    EducationCollege Grad:3  MaritalStatusLivePartner:1 \n               6.597003e-01                7.577248e-01 \n MaritalStatusLivePartner:2  MaritalStatusLivePartner:3 \n               9.273626e-01                5.694772e-01 \n     MaritalStatusMarried:1      MaritalStatusMarried:2 \n               2.302652e-01                8.137787e-01 \n     MaritalStatusMarried:3 MaritalStatusNeverMarried:1 \n               7.303696e-01                6.845630e-01 \nMaritalStatusNeverMarried:2 MaritalStatusNeverMarried:3 \n               5.940539e-01                5.274411e-01 \n   MaritalStatusSeparated:1    MaritalStatusSeparated:2 \n               4.829409e-01                6.284936e-01 \n   MaritalStatusSeparated:3      MaritalStatusWidowed:1 \n               6.341996e-01                6.547036e-01 \n     MaritalStatusWidowed:2      MaritalStatusWidowed:3 \n               9.667559e-01                8.103986e-01 \n              HHIncomeMid:1               HHIncomeMid:2 \n               1.000000e+00                1.000003e+00 \n              HHIncomeMid:3 \n               9.999983e-01 \n\n\nPour obtenir les intervalles de confiance des odds-ratio, on passe à l’exponentielle les intervalles de confiance des coefficients. Ceux-ci peuvent être extraits en utilisant la fonction confint(), qui par défaut donne les IC à 95%\n\nconfint(reg) # IC 95%\n\n                                    2.5 %        97.5 %\n(Intercept):1               -2.963845e+00  6.560948e-01\n(Intercept):2               -7.333561e-01  3.920105e-01\n(Intercept):3                5.155561e-01  1.603443e+00\nGendermale:1                -1.377071e+00 -2.960159e-01\nGendermale:2                 3.594726e-01  6.557269e-01\nGendermale:3                 5.745813e-02  3.507367e-01\nAge:1                       -2.453118e-02  1.175114e-02\nAge:2                        7.410613e-03  1.783931e-02\nAge:3                        2.672820e-03  1.302060e-02\nRace1Hispanic:1             -7.406081e+02  7.110991e+02\nRace1Hispanic:2             -2.204681e-01  5.504416e-01\nRace1Hispanic:3             -7.514757e-01 -1.610050e-02\nRace1Mexican:1              -1.730897e+00  6.486589e-01\nRace1Mexican:2               1.979125e-02  7.570495e-01\nRace1Mexican:3              -3.780511e-01  3.146828e-01\nRace1White:1                -1.046673e+00  2.859497e-01\nRace1White:2                -5.285069e-01 -1.906345e-02\nRace1White:3                -1.042306e+00 -5.782188e-01\nRace1Other:1                -1.113789e+00  6.586441e-01\nRace1Other:2                -1.015608e+00 -3.393283e-01\nRace1Other:3                -1.908076e+00 -1.226224e+00\nEducation9 - 11th Grade:1   -1.696219e+00  1.143393e+00\nEducation9 - 11th Grade:2   -4.930863e-01  2.602428e-01\nEducation9 - 11th Grade:3   -5.028673e-01  2.457506e-01\nEducationHigh School:1      -9.323422e-01  1.647766e+00\nEducationHigh School:2      -4.359548e-01  2.805375e-01\nEducationHigh School:3      -3.804409e-01  3.306896e-01\nEducationSome College:1     -1.438108e+00  1.155008e+00\nEducationSome College:2     -6.126019e-01  9.303766e-02\nEducationSome College:3     -3.243148e-01  3.732549e-01\nEducationCollege Grad:1     -1.562221e+00  1.099049e+00\nEducationCollege Grad:2     -6.645649e-01  6.136457e-02\nEducationCollege Grad:3     -7.798817e-01 -5.205756e-02\nMaritalStatusLivePartner:1  -1.238135e+00  6.832649e-01\nMaritalStatusLivePartner:2  -4.472338e-01  2.964126e-01\nMaritalStatusLivePartner:3  -9.347262e-01 -1.913468e-01\nMaritalStatusMarried:1      -2.248233e+00 -6.888147e-01\nMaritalStatusMarried:2      -4.856054e-01  7.347187e-02\nMaritalStatusMarried:3      -5.820061e-01 -4.640303e-02\nMaritalStatusNeverMarried:1 -1.180929e+00  4.229802e-01\nMaritalStatusNeverMarried:2 -8.414773e-01 -2.000932e-01\nMaritalStatusNeverMarried:3 -9.461784e-01 -3.332577e-01\nMaritalStatusSeparated:1    -2.297791e+00  8.420692e-01\nMaritalStatusSeparated:2    -1.008781e+00  7.992241e-02\nMaritalStatusSeparated:3    -9.601247e-01  4.934145e-02\nMaritalStatusWidowed:1      -1.522551e+00  6.754061e-01\nMaritalStatusWidowed:2      -4.378067e-01  3.701881e-01\nMaritalStatusWidowed:3      -6.019453e-01  1.814872e-01\nHHIncomeMid:1               -8.037426e-06  8.076686e-06\nHHIncomeMid:2               -4.490196e-08  5.134194e-06\nHHIncomeMid:3               -4.239636e-06  8.737812e-07\n\nconfint(reg, level = 0.99) # IC 99%\n\n                                    0.5 %        99.5 %\n(Intercept):1               -3.532578e+00  1.224828e+00\n(Intercept):2               -9.101641e-01  5.688184e-01\n(Intercept):3                3.446366e-01  1.774363e+00\nGendermale:1                -1.546917e+00 -1.261699e-01\nGendermale:2                 3.129276e-01  7.022719e-01\nGendermale:3                 1.138072e-02  3.968141e-01\nAge:1                       -3.023155e-02  1.745151e-02\nAge:2                        5.772146e-03  1.947778e-02\nAge:3                        1.047066e-03  1.464635e-02\nRace1Hispanic:1             -9.686878e+02  9.391788e+02\nRace1Hispanic:2             -3.415868e-01  6.715602e-01\nRace1Hispanic:3             -8.670115e-01  9.943531e-02\nRace1Mexican:1              -2.104753e+00  1.022514e+00\nRace1Mexican:2              -9.604041e-02  8.728812e-01\nRace1Mexican:3              -4.868875e-01  4.235192e-01\nRace1White:1                -1.256043e+00  4.953198e-01\nRace1White:2                -6.085463e-01  6.097592e-02\nRace1White:3                -1.115219e+00 -5.053054e-01\nRace1Other:1                -1.392258e+00  9.371135e-01\nRace1Other:2                -1.121859e+00 -2.330771e-01\nRace1Other:3                -2.015203e+00 -1.119097e+00\nEducation9 - 11th Grade:1   -2.142355e+00  1.589529e+00\nEducation9 - 11th Grade:2   -6.114428e-01  3.785994e-01\nEducation9 - 11th Grade:3   -6.204837e-01  3.633670e-01\nEducationHigh School:1      -1.337707e+00  2.053131e+00\nEducationHigh School:2      -5.485239e-01  3.931065e-01\nEducationHigh School:3      -4.921676e-01  4.424163e-01\nEducationSome College:1     -1.845516e+00  1.562416e+00\nEducationSome College:2     -7.234659e-01  2.039017e-01\nEducationSome College:3     -4.339110e-01  4.828511e-01\nEducationCollege Grad:1     -1.980337e+00  1.517165e+00\nEducationCollege Grad:2     -7.786167e-01  1.754164e-01\nEducationCollege Grad:3     -8.942311e-01  6.229190e-02\nMaritalStatusLivePartner:1  -1.540009e+00  9.851387e-01\nMaritalStatusLivePartner:2  -5.640691e-01  4.132479e-01\nMaritalStatusLivePartner:3  -1.051520e+00 -7.455345e-02\nMaritalStatusMarried:1      -2.493235e+00 -4.438123e-01\nMaritalStatusMarried:2      -5.734428e-01  1.613093e-01\nMaritalStatusMarried:3      -6.661554e-01  3.774630e-02\nMaritalStatusNeverMarried:1 -1.432922e+00  6.749726e-01\nMaritalStatusNeverMarried:2 -9.422460e-01 -9.932442e-02\nMaritalStatusNeverMarried:3 -1.042475e+00 -2.369609e-01\nMaritalStatusSeparated:1    -2.791099e+00  1.335377e+00\nMaritalStatusSeparated:2    -1.179829e+00  2.509701e-01\nMaritalStatusSeparated:3    -1.118723e+00  2.079401e-01\nMaritalStatusWidowed:1      -1.867876e+00  1.020730e+00\nMaritalStatusWidowed:2      -5.647518e-01  4.971333e-01\nMaritalStatusWidowed:3      -7.250314e-01  3.045734e-01\nHHIncomeMid:1               -1.056914e-05  1.060840e-05\nHHIncomeMid:2               -8.585969e-07  5.947889e-06\nHHIncomeMid:3               -5.043012e-06  1.677157e-06\n\n\n\nexp(confint(reg))\n\n                                    2.5 %    97.5 %\n(Intercept):1                5.162007e-02 1.9272512\n(Intercept):2                4.802943e-01 1.4799533\n(Intercept):3                1.674569e+00 4.9701168\nGendermale:1                 2.523165e-01 0.7437756\nGendermale:2                 1.432574e+00 1.9265425\nGendermale:3                 1.059141e+00 1.4201134\nAge:1                        9.757673e-01 1.0118205\nAge:2                        1.007438e+00 1.0179994\nAge:3                        1.002676e+00 1.0131057\nRace1Hispanic:1             2.272702e-322       Inf\nRace1Hispanic:2              8.021432e-01 1.7340185\nRace1Hispanic:3              4.716700e-01 0.9840284\nRace1Mexican:1               1.771254e-01 1.9129737\nRace1Mexican:2               1.019988e+00 2.1319765\nRace1Mexican:3               6.851955e-01 1.3698248\nRace1White:1                 3.511041e-01 1.3310255\nRace1White:2                 5.894844e-01 0.9811171\nRace1White:3                 3.526406e-01 0.5608965\nRace1Other:1                 3.283127e-01 1.9321707\nRace1Other:2                 3.621821e-01 0.7122486\nRace1Other:3                 1.483656e-01 0.2933983\nEducation9 - 11th Grade:1    1.833755e-01 3.1373961\nEducation9 - 11th Grade:2    6.107386e-01 1.2972450\nEducation9 - 11th Grade:3    6.047941e-01 1.2785806\nEducationHigh School:1       3.936307e-01 5.1953614\nEducationHigh School:2       6.466470e-01 1.3238411\nEducationHigh School:3       6.835600e-01 1.3919277\nEducationSome College:1      2.373765e-01 3.1740479\nEducationSome College:2      5.419390e-01 1.0975031\nEducationSome College:3      7.230226e-01 1.4524545\nEducationCollege Grad:1      2.096699e-01 3.0013110\nEducationCollege Grad:2      5.144973e-01 1.0632865\nEducationCollege Grad:3      4.584603e-01 0.9492742\nMaritalStatusLivePartner:1   2.899244e-01 1.9803327\nMaritalStatusLivePartner:2   6.393944e-01 1.3450250\nMaritalStatusLivePartner:3   3.926934e-01 0.8258461\nMaritalStatusMarried:1       1.055856e-01 0.5021710\nMaritalStatusMarried:2       6.153246e-01 1.0762383\nMaritalStatusMarried:3       5.587763e-01 0.9546571\nMaritalStatusNeverMarried:1  3.069933e-01 1.5265040\nMaritalStatusNeverMarried:2  4.310732e-01 0.8186545\nMaritalStatusNeverMarried:3  3.882218e-01 0.7165855\nMaritalStatusSeparated:1     1.004805e-01 2.3211649\nMaritalStatusSeparated:2     3.646632e-01 1.0832030\nMaritalStatusSeparated:3     3.828451e-01 1.0505790\nMaritalStatusWidowed:1       2.181546e-01 1.9648307\nMaritalStatusWidowed:2       6.454506e-01 1.4480069\nMaritalStatusWidowed:3       5.477451e-01 1.1989992\nHHIncomeMid:1                9.999920e-01 1.0000081\nHHIncomeMid:2                1.000000e+00 1.0000051\nHHIncomeMid:3                9.999958e-01 1.0000009\n\n\n\n\n9.2.4 Interprétation\nLes odds-ratio de Male2 et Male3 sont supérieurs à 1 (et les intervalles de confiance à 95% ne comprennent pas 1). Cela signifie que les hommes on une probabilité plus grande que les femmes d’être dans les catégories d’IMC 25.0_to_29.9 et 30.0_plus plutôt que dans 18.5_to_24.9.\n\n\n9.2.5 Représentation graphique des odds-ratio\nLa fonction tidy() du package broom qui permet d’obtenir un dataset avec les coefficients et les IC n’est pas applicable à un objet créé avec vglm(). La fonction suivante permet d’obtenir un dataset similaire\n\ntidy.vglm &lt;- function(x, conf.int=FALSE, conf.level=0.95) {\n    co &lt;- as.data.frame(coef(summary(x)))\n    names(co) &lt;- c(\"estimate\",\"std.error\",\"statistic\",\"p.value\")\n    if (conf.int) {\n        qq &lt;- qnorm((1+conf.level)/2)\n        co &lt;- transform(co,\n                        conf.low=estimate-qq*std.error,\n                        conf.high=estimate+qq*std.error)\n    }\n    co &lt;- data.frame(term=rownames(co),co)\n    rownames(co) &lt;- NULL\n    return(co)\n}\n\nCette fonction contient les coefficients en log, on va donc modifier le dataset pour avoir les odds.\n\ntab_summary &lt;- tidy.vglm(reg, conf.int = T) %&gt;% \n  mutate(estimate = exp(estimate),\n         conf.low = exp(conf.low),\n         conf.high = exp(conf.high))\nhead(tab_summary)\n\n           term  estimate  std.error  statistic      p.value   conf.low\n1 (Intercept):1 0.3154122 0.92347092 -1.2494979 2.114830e-01 0.05162007\n2 (Intercept):2 0.8430974 0.28708861 -0.5944952 5.521809e-01 0.48029435\n3 (Intercept):3 2.8849274 0.27752736  3.8176407 1.347340e-04 1.67456946\n4  Gendermale:1 0.4332054 0.27578440 -3.0333238 2.418759e-03 0.25231653\n5  Gendermale:2 1.6612989 0.07557648  6.7163716 1.863054e-11 1.43257362\n6  Gendermale:3 1.2264176 0.07481734  2.7279428 6.373067e-03 1.05914092\n  conf.high\n1 1.9272512\n2 1.4799533\n3 4.9701168\n4 0.7437756\n5 1.9265425\n6 1.4201134\n\n\nEn utilisant across() pour appliquer la même fonction à plusieurs colonnes\n\ntab_summary &lt;- tidy.vglm(reg, conf.int = T) %&gt;% \n  mutate(across(c(estimate, conf.low, conf.high), ~ exp(.x)))\nhead(tab_summary)\n\n           term  estimate  std.error  statistic      p.value   conf.low\n1 (Intercept):1 0.3154122 0.92347092 -1.2494979 2.114830e-01 0.05162007\n2 (Intercept):2 0.8430974 0.28708861 -0.5944952 5.521809e-01 0.48029435\n3 (Intercept):3 2.8849274 0.27752736  3.8176407 1.347340e-04 1.67456946\n4  Gendermale:1 0.4332054 0.27578440 -3.0333238 2.418759e-03 0.25231653\n5  Gendermale:2 1.6612989 0.07557648  6.7163716 1.863054e-11 1.43257362\n6  Gendermale:3 1.2264176 0.07481734  2.7279428 6.373067e-03 1.05914092\n  conf.high\n1 1.9272512\n2 1.4799533\n3 4.9701168\n4 0.7437756\n5 1.9265425\n6 1.4201134\n\n\n\nggplot(tab_summary, aes(x = estimate, y = term)) +\n  geom_point(size = 2) +  # Ajouter les points pour les coefficients\n  geom_errorbar(aes(xmin = conf.low, xmax = conf.high), width = 0.2) +  # Ajouter les barres d'erreur pour les intervalles de confiance\n  geom_vline(xintercept = 1, col = \"red\") + # Ajout de la ligne des 1 \n  labs(x = \"Coefficients\", y = \"Estimation\") +  \n  theme_minimal()  # Utiliser un thème minimaliste\n\n\n\n\n\n\n\n\n\n\n9.2.6 Package nnet\nOn ne va pas développer sur la modélisation avec le package nnet et sa fonction multinom(). Nous montrons juste comment l’utiliser\n\nlibrary(nnet)\nreg_bis &lt;- multinom(BMI_WHO ~ Gender + Age + Race1 + Education + MaritalStatus + HHIncomeMid, data = dataReg)\n\n# weights:  72 (51 variable)\ninitial  value 6837.203789 \niter  10 value 5716.584189\niter  20 value 5596.150853\niter  30 value 5513.550718\niter  40 value 5498.723498\niter  50 value 5494.420026\niter  60 value 5493.917196\niter  70 value 5493.905381\niter  70 value 5493.905353\niter  70 value 5493.905353\nfinal  value 5493.905353 \nconverged\n\nsummary(reg_bis)\n\nCall:\nmultinom(formula = BMI_WHO ~ Gender + Age + Race1 + Education + \n    MaritalStatus + HHIncomeMid, data = dataReg)\n\nCoefficients:\n             (Intercept) Gendermale         Age Race1Hispanic Race1Mexican\n18.5_to_24.9   1.1526524   0.836460 0.006399762      12.19910    0.5413734\n25.0_to_29.9   0.9819812   1.344058 0.019024571      12.36409    0.9297898\n30.0_plus      2.2121414   1.040558 0.014246524      11.81531    0.5096836\n             Race1White Race1Other Education9 - 11th Grade EducationHigh School\n18.5_to_24.9  0.3805556  0.2278622               0.2766490           -0.3574001\n25.0_to_29.9  0.1067713 -0.4496017               0.1602347           -0.4351050\n30.0_plus    -0.4297095 -1.3392899               0.1481070           -0.3822619\n             EducationSome College EducationCollege Grad\n18.5_to_24.9             0.1418673            0.23186994\n25.0_to_29.9            -0.1179104           -0.06972595\n30.0_plus                0.1663507           -0.18408587\n             MaritalStatusLivePartner MaritalStatusMarried\n18.5_to_24.9                0.2780744             1.468967\n25.0_to_29.9                0.2026586             1.262892\n30.0_plus                  -0.2849558             1.154758\n             MaritalStatusNeverMarried MaritalStatusSeparated\n18.5_to_24.9                 0.3796277              0.7293578\n25.0_to_29.9                -0.1411607              0.2649036\n30.0_plus                   -0.2600925              0.2739596\n             MaritalStatusWidowed   HHIncomeMid\n18.5_to_24.9            0.4240156 -2.293040e-08\n25.0_to_29.9            0.3901964  2.521723e-06\n30.0_plus               0.2137804 -1.705949e-06\n\nStd. Errors:\n              (Intercept)   Gendermale          Age Race1Hispanic Race1Mexican\n18.5_to_24.9 1.064880e-05 4.050036e-06 0.0007522358  6.329892e-07 8.703142e-07\n25.0_to_29.9 9.436201e-06 4.131585e-06 0.0006861739  6.500789e-07 1.068271e-06\n30.0_plus    9.525103e-06 3.809335e-06 0.0006713469  6.346448e-07 1.059728e-06\n               Race1White   Race1Other Education9 - 11th Grade\n18.5_to_24.9 6.961470e-06 6.873464e-07            2.553424e-06\n25.0_to_29.9 5.884328e-06 4.918833e-07            2.374378e-06\n30.0_plus    5.759613e-06 4.263695e-07            2.338489e-06\n             EducationHigh School EducationSome College EducationCollege Grad\n18.5_to_24.9         3.301460e-06          2.970002e-06          4.953387e-08\n25.0_to_29.9         2.964138e-06          2.317769e-06          1.971110e-07\n30.0_plus            2.965835e-06          2.553744e-06          1.787342e-07\n             MaritalStatusLivePartner MaritalStatusMarried\n18.5_to_24.9             3.720628e-07         4.705344e-06\n25.0_to_29.9             3.133170e-07         4.144233e-06\n30.0_plus                3.087044e-07         3.895121e-06\n             MaritalStatusNeverMarried MaritalStatusSeparated\n18.5_to_24.9              7.103012e-07           4.618356e-07\n25.0_to_29.9              3.798569e-07           3.582405e-07\n30.0_plus                 6.063098e-07           4.268117e-07\n             MaritalStatusWidowed  HHIncomeMid\n18.5_to_24.9         2.617475e-06 2.033373e-06\n25.0_to_29.9         2.601932e-06 2.033272e-06\n30.0_plus            2.563671e-06 2.036681e-06\n\nResidual Deviance: 10987.81 \nAIC: 11089.81 \n\n\nL’avantage d’utiliser ce package est pour la représentation graphique. Le package ggstats qui propose des jolis graphiques notamment pour les forrest plot propose la fonction ggcoef_multinom() qui permet d’avoir un forrest plot des coefficients obtenus avec la fonction multinom(). Je n’ai pas l’impression que cette fonction puisse être utilisée sur un objet obtenu avec vglm().\n\nggstats::ggcoef_multinom(reg_bis, exponentiate = T)\n\nWarning: `ggcoef_multicomponents()` was deprecated in ggstats 0.9.0.\nℹ Please use `ggcoef_dodged()` instead.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Régressions multinomiales et ordinales</span>"
    ]
  },
  {
    "objectID": "7.RegressionMultinomialeOrdinale.html#régression-polytomique-ordinale",
    "href": "7.RegressionMultinomialeOrdinale.html#régression-polytomique-ordinale",
    "title": "9  Régressions multinomiales et ordinales",
    "section": "9.3 Régression polytomique ordinale",
    "text": "9.3 Régression polytomique ordinale\nLorsque la variable Y est catégorielles mais avec des catégories ordonnées, on peut vouloir tenir compte de cet ordre et réaliser une régression polytomique ordinale.   Comme pour la régression multinomiale, il n’y a pas de fonction en R base, mais plusieurs packages proposent des fonctions pour réaliser une régression polytomique ordinale. Les plus couramment utilisés sont :  - package MASS avec la fonction polr()  - package VGAM avec la fonction vglm() comme pour la régression multinomiale   Ici, nous allons présenter le package VGAM. La fonction vglm() modélise \\(\\mathbb{P}(Y \\leq j)\\).  \nNous allons reprendre l’exemple de la régression multinomiale, mais en considérant cette fois-ci que les catégories de BMI sont ordonnées. Pour cet exemple, nous allons retirer la catégorie “12.0_18.5” et ainsi ne garder que les catégories “normal”, “surpoids” et “obésité”\n\ndataRegOrd &lt;- dataReg %&gt;% filter(BMI_WHO!=\"12.0_18.5\")\n\nSi on ne veut pas avoir de warnings, il est préférable d’indiquer à R que les catégories sont ordonnées, en utilisant la fonction ordered()\n\ndataRegOrd$BMI_WHO &lt;- ordered(dataRegOrd$BMI_WHO, levels = c(\"18.5_to_24.9\", \"25.0_to_29.9\", \"30.0_plus\"))\n\n\n9.3.1 Modèle à odds proportionnels\nLe modèle à odds proporionnels est un modèle courrament utilisé pour tenir compte de la hiérarchie des catégories. Il s’écrit \\[ log\\left( \\frac{\\mathbb{P}(Y\\leq j)}{\\mathbb{P}(Y&gt;j)}\\right) = \\beta_{0j}+\\beta_1X_1 + ... + \\beta_pX_p\\] Ce modèle fait l’hypothèse d’égalité des pentes. Si cette hypothèse n’est pas vérifiée, on fait un modèle multinomial.  On a un intercept par modalité de Y (sauf pour la modalité de référence), mais ensuite un seul coefficient par (modalité des variables) X.  Chaque \\(\\beta\\) correspond à l’augmentation du log odds d’avoir une modalité de Y inférieure ou égale à \\(j\\) quand on a la modalité de la variable X du coefficient comparé à la modalité de référence de X (ou quand X augmente de 1 si X est continue).   La fonction vglm() s’utilise comme pour la régression multinomiale, mais en changeant l’argument family.  Pour ajuster un modèle à catégories adjacentes, on utilise family = cumulative(link = \"logitlink\", parallel = TRUE)\n\nregOrd &lt;- vglm(BMI_WHO ~ Gender + Age + Race1 + Education + MaritalStatus + HHIncomeMid, data=dataRegOrd, family = cumulative(link = \"logitlink\", parallel = TRUE))\n\nRemarque : parallel=T indique que l’on fait l’hypothèse d’égalité des pentes, ou odds proportionnel. Si cette hypohèse n’est pas vérifiée, on ne peut pas interpréter ce modèle (nous verrons ensuite comment tester cette hypothèse).\n\nsummary(regOrd)\n\n\nCall:\nvglm(formula = BMI_WHO ~ Gender + Age + Race1 + Education + MaritalStatus + \n    HHIncomeMid, family = cumulative(link = \"logitlink\", parallel = TRUE), \n    data = dataRegOrd)\n\nCoefficients: \n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept):1             -1.591e+00  1.989e-01  -7.996 1.28e-15 ***\n(Intercept):2             -9.474e-02  1.976e-01  -0.479  0.63160    \nGendermale                -1.196e-01  5.447e-02  -2.195  0.02816 *  \nAge                       -5.232e-03  1.917e-03  -2.730  0.00634 ** \nRace1Hispanic              3.771e-01  1.334e-01   2.826  0.00471 ** \nRace1Mexican               1.513e-01  1.230e-01   1.230  0.21877    \nRace1White                 6.617e-01  8.606e-02   7.689 1.48e-14 ***\nRace1Other                 1.233e+00  1.261e-01   9.774  &lt; 2e-16 ***\nEducation9 - 11th Grade    6.766e-02  1.323e-01   0.511  0.60903    \nEducationHigh School      -2.292e-02  1.257e-01  -0.182  0.85527    \nEducationSome College     -8.710e-02  1.239e-01  -0.703  0.48218    \nEducationCollege Grad      2.540e-01  1.296e-01   1.960  0.05003 .  \nMaritalStatusLivePartner   4.235e-01  1.349e-01   3.140  0.00169 ** \nMaritalStatusMarried       2.437e-01  9.797e-02   2.487  0.01287 *  \nMaritalStatusNeverMarried  4.804e-01  1.142e-01   4.207 2.59e-05 ***\nMaritalStatusSeparated     2.901e-01  1.908e-01   1.521  0.12838    \nMaritalStatusWidowed       1.714e-01  1.414e-01   1.212  0.22545    \nHHIncomeMid                1.392e-06  9.565e-07   1.455  0.14572    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nNames of linear predictors: logitlink(P[Y&lt;=1]), logitlink(P[Y&lt;=2])\n\nResidual deviance: 10390.19 on 9694 degrees of freedom\n\nLog-likelihood: -5195.096 on 9694 degrees of freedom\n\nNumber of Fisher scoring iterations: 4 \n\nNo Hauck-Donner effect found in any of the estimates\n\n\nExponentiated coefficients:\n               Gendermale                       Age             Race1Hispanic \n                0.8873060                 0.9947816                 1.4580166 \n             Race1Mexican                Race1White                Race1Other \n                1.1633624                 1.9381227                 3.4306750 \n  Education9 - 11th Grade      EducationHigh School     EducationSome College \n                1.0700063                 0.9773370                 0.9165826 \n    EducationCollege Grad  MaritalStatusLivePartner      MaritalStatusMarried \n                1.2891668                 1.5273084                 1.2759249 \nMaritalStatusNeverMarried    MaritalStatusSeparated      MaritalStatusWidowed \n                1.6166560                 1.3366252                 1.1869143 \n              HHIncomeMid \n                1.0000014 \n\n\nRemarque 2 : Dans cette sortie on voit bien que l’on a modélisé \\(\\mathbb{P}(Y \\leq j)\\). Il faut faire attention car certaines fonctions (notamment le package MASS) modélisent \\(\\mathbb{P}(Y &gt; j)\\). Cette modélisation peut se faire en ajoutant reverse=TRUE dans family = cumulative(link = “logitlink”, parallel = TRUE, reverse = T), mais l’interprétation des coefficients est alors différente. En effet, le coefficient de \\(x\\) correspondra au log odds d’être dans une catégorie supérieure à \\(j\\) et non plus au log-odds d’être dans une catégorie inférieure ou égale à \\(j\\). Voir (lien)[https://stats.oarc.ucla.edu/r/faq/ologit-coefficients/] pour plus de détails.\n  Remarque 3 : Comme c’est encore la fonction vglm(), la remarque concernant le format du dataset développée dans la partie sur la régression multinomiale s’applique.\n\n\n9.3.2 Odds-ratio\nComme pour les régressions logistiques et multinomiales, on obtient les odds-ratio des coefficients et des intervalles de confiance en passant à l’exponentielle\n\nexp(coef(regOrd))\n\n            (Intercept):1             (Intercept):2                Gendermale \n                0.2037869                 0.9096124                 0.8873060 \n                      Age             Race1Hispanic              Race1Mexican \n                0.9947816                 1.4580166                 1.1633624 \n               Race1White                Race1Other   Education9 - 11th Grade \n                1.9381227                 3.4306750                 1.0700063 \n     EducationHigh School     EducationSome College     EducationCollege Grad \n                0.9773370                 0.9165826                 1.2891668 \n MaritalStatusLivePartner      MaritalStatusMarried MaritalStatusNeverMarried \n                1.5273084                 1.2759249                 1.6166560 \n   MaritalStatusSeparated      MaritalStatusWidowed               HHIncomeMid \n                1.3366252                 1.1869143                 1.0000014 \n\nexp(confint(regOrd))\n\n                              2.5 %    97.5 %\n(Intercept):1             0.1379890 0.3009596\n(Intercept):2             0.6175477 1.3398070\nGendermale                0.7974570 0.9872782\nAge                       0.9910516 0.9985257\nRace1Hispanic             1.1225227 1.8937813\nRace1Mexican              0.9140810 1.4806261\nRace1White                1.6372975 2.2942194\nRace1Other                2.6792810 4.3927947\nEducation9 - 11th Grade   0.8256102 1.3867482\nEducationHigh School      0.7639565 1.2503168\nEducationSome College     0.7189107 1.1686064\nEducationCollege Grad     0.9999709 1.6619993\nMaritalStatusLivePartner  1.1725634 1.9893772\nMaritalStatusMarried      1.0530174 1.5460184\nMaritalStatusNeverMarried 1.2924736 2.0221507\nMaritalStatusSeparated    0.9195659 1.9428373\nMaritalStatusWidowed      0.8996852 1.5658428\nHHIncomeMid               0.9999995 1.0000033\n\n\n\n\n9.3.3 Interprétation\nL’odds-ratio de Male est inférieur à 1 (et son interval de confiance à 95% ne contient pas 1). Cela signifie que pour un homme, la probabilité d’être dans une catégories inférieure ou égale à j, est plus faible que pour une femme .  Pour un homme, l’odds d’être en IMC normal VS en surpoids ou obèse est plus faible que pour une femme de 0.89.\n Attention :  Normalement je ne devrais pas interpréter avant d’avoir vérifier l’égalité des pentes. Je le fais ici juste pour l’exemple, en supposant que l’hypothèse est vérifiée.\n\n\n9.3.4 Représentation graphique\nPour obtenir un dataset avec les coefficients et leurs IC, on utilise la fonction tidy.vglm() définie dans la partie sur la régression multinomiale. Cette fonction contient les coefficients en log, on va donc modifier le dataset pour avoir les odds-ratio.\n\ntab_summary &lt;- tidy.vglm(regOrd, conf.int = T) %&gt;% \n  mutate(across(c(estimate, conf.low, conf.high), ~ exp(.x)))\nhead(tab_summary)\n\n           term  estimate   std.error  statistic      p.value  conf.low\n1 (Intercept):1 0.2037869 0.198932790 -7.9960696 1.284537e-15 0.1379890\n2 (Intercept):2 0.9096124 0.197586408 -0.4794695 6.316047e-01 0.6175477\n3    Gendermale 0.8873060 0.054471389 -2.1950132 2.816265e-02 0.7974570\n4           Age 0.9947816 0.001916706 -2.7296998 6.339201e-03 0.9910516\n5 Race1Hispanic 1.4580166 0.133420044  2.8262397 4.709800e-03 1.1225227\n6  Race1Mexican 1.1633624 0.123038274  1.2298160 2.187660e-01 0.9140810\n  conf.high\n1 0.3009596\n2 1.3398070\n3 0.9872782\n4 0.9985257\n5 1.8937813\n6 1.4806261\n\n\n\nggplot(tab_summary, aes(x = estimate, y = term)) +\n  geom_point(size = 2) +  # Ajouter les points pour les coefficients\n  geom_errorbar(aes(xmin = conf.low, xmax = conf.high), width = 0.2) +  # Ajouter les barres d'erreur pour les intervalles de confiance\n  geom_vline(xintercept = 1, col = \"red\") + # Ajout de la ligne des 1\n  labs(x = \"Coefficients\", y = \"Estimation\") +  \n  theme_minimal()  # Utiliser un thème minimaliste\n\n\n\n\n\n\n\n\n Attention :  De même que pour l’interprétation, normalement je ne devrais pas faire le graphique avant d’avoir vérifier l’égalité des pentes. Je le fais ici juste pour l’exemple, en supposant que l’hypothèse est vérifiée.\n\n\n9.3.5 Test d’égalité des pentes\nPour tester l’hypothèse d’égalité des pentes, on ajuste un modèle sans cette hypothèse parallel = FALSE et on compare les deux modèles. Comme il s’agit de modèles emboîtés, on peut faire un test anova.\n\nregOrdFALSE &lt;- vglm(BMI_WHO ~ Gender + Age + Race1 + Education + MaritalStatus + HHIncomeMid, data=dataRegOrd, family = cumulative(link = \"logitlink\", parallel = FALSE))\n\n\nanova(regOrd, regOrdFALSE, type = 1)\n\nAnalysis of Deviance Table\n\nModel 1: BMI_WHO ~ Gender + Age + Race1 + Education + MaritalStatus + \n    HHIncomeMid\nModel 2: BMI_WHO ~ Gender + Age + Race1 + Education + MaritalStatus + \n    HHIncomeMid\n  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    \n1      9694      10390                          \n2      9678      10278 16    112.7 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOn peut aussi faire manuellement un test du rapport de vraisemblance\n\ng2.prop = 2*(logLik(regOrdFALSE) - logLik(regOrd))\ndf.prop = df.residual(regOrd) - df.residual(regOrdFALSE)\n1 - pchisq(g2.prop, df.prop)\n\n[1] 1.110223e-16\n\n\nIci on rejette l’hypothèse d’égalité des pentes et on ne peut donc pas faire un modèle à odds proportionnels.\n\n\n9.3.6 Tests\nLes tests de nullité globale du modèle et de significativité des variables sont les mêmes que pour la régression multinomiale.   Nullité de tous les coefficients par le test du rapport de vraisemblance\n\nlrtest_vglm(regOrd)\n\nLikelihood ratio test\n\nModel 1: BMI_WHO ~ Gender + Age + Race1 + Education + MaritalStatus + \n    HHIncomeMid\nModel 2: BMI_WHO ~ 1\n   #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1 9694 -5195.1                         \n2 9710 -5309.3 16 228.38  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nEffet global de chaque variable\n\nanova(regOrd, type = 3) # A ne pas confondre avec Anova()\n\nAnalysis of Deviance Table (Type III tests: each term added last)\n\nModel: 'cumulative', 'VGAMordinal', 'VGAMcategorical'\n\nLinks: 'logitlink'\n\nResponse: BMI_WHO\n\n              Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    \nGender         1    4.800      9695      10395  0.028459 *  \nAge            1    7.425      9695      10398  0.006433 ** \nRace1          4  123.451      9698      10514 &lt; 2.2e-16 ***\nEducation      4   24.378      9698      10415 6.708e-05 ***\nMaritalStatus  5   19.732      9699      10410  0.001403 ** \nHHIncomeMid    1    2.115      9695      10392  0.145815    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Régressions multinomiales et ordinales</span>"
    ]
  },
  {
    "objectID": "7.RegressionMultinomialeOrdinale.html#ressources",
    "href": "7.RegressionMultinomialeOrdinale.html#ressources",
    "title": "9  Régressions multinomiales et ordinales",
    "section": "9.4 Ressources",
    "text": "9.4 Ressources\nRégression logistique binaire, multinomiale et ordinale, J. Larmarange  \n Régression logistique  - Le livre de joseph larmarrange Guide-R : https://larmarange.github.io/guide-R/analyses/regression-logistique-binaire.html  \n Modèles polytomiques nominal et ordinal   - https://online.stat.psu.edu/stat504/lesson/8/8.5  - Quelques modèles logistiques polytomiques, Laurent Rouvière",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Régressions multinomiales et ordinales</span>"
    ]
  },
  {
    "objectID": "8.Initiation_Fonctions_Boucles.html",
    "href": "8.Initiation_Fonctions_Boucles.html",
    "title": "10  Fonctions, conditions et boucles",
    "section": "",
    "text": "10.1 Fonctions\nNous allons voir comment définir des fonctions en R. Depuis le début, nous avons utilisé de nombreuses fonctions qui sont existantes en R de base ou qui ont été définies dans des packages. Mais il est aussi possible de créer nos propres fonctions.  Définir des fonctions permettra souvent d’automatiser du code et d’éviter de nombreux copier-coller.   La syntaxe pour écrire une fonction est la suivante : \\[ \\textit{f &lt;- function(arg1, arg2, ...)}\\{\\newline\n\\text{code de la fonction}\\}\\] Par exemple, on va écrire une fonction qui pour chaque élément d’un vecteur renvoie le carré\nfct_carre &lt;- function(vec){\n  # Argument : un vercteur\n  # Sortie : Un vecteur dont chaque entrée est le carré du vecteur passé en argument\n  return(vec^2)\n}\nfct_carre(c(1,2,3,4,5))\n\n[1]  1  4  9 16 25\nOn précise l’objet de sortie de la fonction avec la fonction return().  Remarque : Si on ne met pas de return(), la fonction renverra le dernier objet modifié, mais il est préférable, surtout quand la fonction est longue de préciser bien préciser l’objet de sortie avec return()\nfct_carre2 &lt;- function(vec){\n  # Argument : un vercteur\n  # Sortie : Un vecteur dont chaque entrée est le carré du vecteur passé en argument\n  vec^2\n}\nfct_carre2(c(1,2,3,4,5))\n\n[1]  1  4  9 16 25\nUne fonction peut prendre autant d’arguments que l’on veut. Il est aussi possible de définir des valeurs par défaut pour tous ou certains d’entre eux. Cela évite à l’utilisateur de préciser tous les arguments si certains prennent souvent une certaine valeur. Pour cela, on définira d’abord les arguments qui n’ont pas de valeur par défaut et ensuite ceux dont on précise une valeur par défaut avec “=”. \\[ \\textit{function}\\text{(arg1, arg2, arg3=valeur_def_arg3, arg4 = valeur_def_arg4)}\\{\\}\\] Par exemple, on va définir une fonction qui renvoie un certain exposant d’un vecteur. Par défaut l’exposant sera “2”, mais on peut choisir celui que l’on veut\nfct_exposant &lt;- function(vec, exposant = 2){\n  return(vec^exposant)\n}\nAinsi, si je ne précise que mon vecteur en argument de la fonction, j’obtiens son carré\nfct_exposant(c(1,2,3,4,5))\n\n[1]  1  4  9 16 25\nMais si je précise l’argument exposant = 3, j’obtiens son cube\nfct_exposant(c(1,2,3,4,5), 3)\n\n[1]   1   8  27  64 125\nRemarque : Comme pour les fonctions prédéfinies, on n’est pas obligé de préciser les noms des arguments si on les rentre dans l’ordre dans lequel ils sont définis, mais on peut le faire et ainsi les rentrer dans l’ordre que l’on souhaite\nfct_exposant(exposant = 3, vec = c(1,2,3,4,5))\n\n[1]   1   8  27  64 125\nRemarque 2 : Les arguments par défaut sont utilisés dans de nombreuses fonctions que l’on utilise régulièrement. On peut les voir dans les aides des fonctions.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Fonctions, conditions et boucles</span>"
    ]
  },
  {
    "objectID": "8.Initiation_Fonctions_Boucles.html#conditions",
    "href": "8.Initiation_Fonctions_Boucles.html#conditions",
    "title": "10  Fonctions, conditions et boucles",
    "section": "10.2 Conditions",
    "text": "10.2 Conditions\nNous utilisons souvent des tests conditionnels pour affecter une certaine valeur à un objet selon ses caractéristiques.\n\n10.2.1 Rappel des fonctions ifelse() et case_when()\nNous avons déjà vu les fonctions ifelse() et case_when().  ifelse() permet d’attribuer une valeur ou une autre selon qu’une condition est vérifiée ou non \\[\\textit{ifelse }(\\text{ condition, valeur si vérifiée, valeur si non vérifiée})\\]\n\nx &lt;- 3\nifelse(x&gt;=5, \"Grand\", \"Petit\")\n\n[1] \"Petit\"\n\n\ncase_when() est utilisée pour généraliser le ifelse à plusieurs tests conditionnels \\[\\textit{case_when }(\\text{condition1 ~ valeur si cond1 vérifiée,}\\newline \\text{condition2 ~ valeur si condition 2 vérifiée,} \\newline \\cdot \\cdot \\cdot \\text{,} \\newline \\text{TRUE ~ valeur si aucune des condition précédentes n'est vérifiée})\\]\n\nx &lt;- 3\ndplyr::case_when(x&lt;0 ~ \"Négatif\",\n                 x==0 ~ \"Nul\",\n                 x&gt;0 & x&lt;=5 ~ \"]0,5]\",\n                 x&lt;=10 ~ \"]5, 10]\",\n                 T ~ \"Sup 10\")\n\n[1] \"]0,5]\"\n\n\nRappel : Les conditions sont évaluées dans l’ordre d’apparition, donc la condition 4 est testée que si 1, 2 et 3 sont fausses, c’est pourquoi je n’ai pas à tester “x&gt;5 & x&lt;=10”. De même, dans ma troisième condition, je pourrais supprimer le test “x&gt;0”\n\n\n10.2.2 Les conditions if, else if et else\nLes fonctions précédentes sont très utile si on veut attribuer une valeur fixe, mais si on veut faire des opération plus complexes selon qu’une condition est vérifiée ou non, ces fonctions ne sont plus adaptées.  Dans ce cas, on va avoir recours aux conditions if, else if et else.   Pour débuter un test conditionnel et tester une première condition on utilise if \\[\\textit{if}\\text{ (condition1)\\{taitement a effectuer si cond1 est vraie\\}}\\] Ensuite, pour continuer le même test conditionnel mais tester une autre condition, on utilise else if \\[\\textit{else if}\\text{ (condition2)\\{taitement a effectuer si cond 2 est vraie mais pas cond 1\\}} \\newline\n\\textit{else if}\\text{ (condition3)\\{taitement a effectuer si cond 3 est vraie mais pas cond 1 ni cond 2\\}} \\newline \\cdot \\cdot \\cdot \\]\nPour finir un test conditionnel, et ainsi effectué le traitement défini dans le cas ou aucune des conditions précédentes n’est vérifiée, on utilise else \\[\\textit{else}\\text{\\{traitement à effectuer si aucune des conditions n'est vérifiée\\}}\\]\n\nchoix = c(\"mixed\", \"female\", \"male\")\nselection  &lt;- choix[1]\n\nlibrary(NHANES)\ndata(\"NHANES\")\n\nplot_BMI_age &lt;- function(selection){\n  if(!(selection%in%choix)){\n  print(\"Erreur : vous devez selectionner un élément parmi les éléments du vecteur choix\")\n  }\n  else if(selection==\"mixed\"){\n    ggplot(NHANES, aes(x = Age, y = BMI))+\n      geom_point()+\n      geom_smooth(method = \"lm\", col = \"red\")\n  }\n  else{\n    dat &lt;- filter(NHANES, Gender==selection)\n    ggplot(dat, aes(x = Age, y = BMI))+\n      geom_point() +\n      geom_smooth(method = \"lm\", col = \"red\")\n  }\n}\n\nplot_BMI_age(selection)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 366 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 366 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\nplot_BMI_age(choix[2])\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 179 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 179 rows containing missing values or values outside the scale range\n(`geom_point()`).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Fonctions, conditions et boucles</span>"
    ]
  },
  {
    "objectID": "8.Initiation_Fonctions_Boucles.html#boucles",
    "href": "8.Initiation_Fonctions_Boucles.html#boucles",
    "title": "10  Fonctions, conditions et boucles",
    "section": "10.3 Boucles",
    "text": "10.3 Boucles\nDans les fonctions, il sera souvent nécéssaire d’utiliser des boucles. Celles-ci peuvent aussi être utilisées en dehors de fonction, mais c’est plus rare   Il existe deux types de boucles : for et while. En pratique, l’utilisation des boucles while est découragée car elle peut résulter sur une boucle infinie.\n\n10.3.1 Boucles while\nComme son nom l’indique, une boucle while permet d’executer un code tant qu’une condtion est remplie .\n\\[\nWhile (Conditions)\\text{\\{code à exécuter tant que la condition est remplie\\}}\n\\]\nPar exemple, imaginons un sac de 9 boules bleues et 1 boule rouge. Je pioche une boule et tant que je pioche une boule bleue, je continue de piocher une boule. en algorithmique on peut ecrire cela domme ceci :\n\nInitialisation\nPioche une Boule\nLa variable Boule prend la valeur de la boule piochée\nBoucle\nTant que Boule == ‘Bleue’\nPioche une boule\nLa variable Boule prend la valeur de la boule piochée\nFin de tant que\n\nAttention aux boucles infinie !\nPar sa construction, si la condition est toujours vraie alors la boucle ne s’arrêtera pas. Il faut donc s’assurer que la condition peut bien etre remplie dans le code à exécuter. Si je n’ai pas de boule rouge dans mon sac et que je lance la boucle alors je piocherai des boules à l’infinie.\n\nExemple simple dans R :\n\n#Initialisation \nx &lt;- 0 \ni &lt;- 0\nwhile(x &lt; 100){ # Tant que x est plus petit que 100\n x &lt;- x+10 \n i &lt;- i +1\n}\nx\n\n[1] 100\n\ni # nombre d'iteration\n\n[1] 10\n\n\nExemple plus concret mais qui dans les faits ne se fait pas comme ça :\nCréer une colone Overweigth qui prend la valeur True si BMI &gt; 25.\n\ni &lt;- 1 # Indice des lignes \nOverweight &lt;- rep(NA, nrow(NHANES))\nwhile (i &lt;= nrow(NHANES)){ #Tant que i est inferieur ou égal au nombre de ligne  \n  if(is.na(NHANES$BMI_WHO[i])) {}\n  else if(NHANES$BMI_WHO[i] %in% c(\"25.0_to_29.9\", \"30.0_plus\")) {\n    Overweight[i] &lt;- TRUE\n  }\n  else{\n    Overweight[i] &lt;- FALSE\n  }\n  i &lt;- i+1 # On passe à la ligne suivante \n}\nprint(Overweight[(nrow(NHANES)-10):nrow(NHANES)])\n\n [1] FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE    NA  TRUE  TRUE  TRUE\n\n\n\n\n10.3.2 Boucles for\nLes boucles for permettent d’itérer sur plusieurs éléments d’un vecteur ou d’une list.  \\[\\textit{for (i = 1:10)}\\text{\\{code à exécuter sur chaque i allant de 1 à 10\\}}\\]Cette méthode est utilisé lorsque l’on travaille avec les indexations.   On peut également itérer directement sur les éléments d’un vecteur \\[ \\textit{for (x in } \\text{ c(14,25,64,13))\\{code à exécuter sur chaque élément du vecteur c(14,25,64,13) \\}}\\]\n Exemple on affiche le rythme cardiaque moyen par catégorie d’IMC dans le dataset NHANES\n\nBMIcat &lt;- levels(NHANES$BMI_WHO)\n\nfor(x in BMIcat){\n  data &lt;- NHANES %&gt;% filter(BMI_WHO==x)\n  meanPulse &lt;-  mean(data$Pulse, na.rm = T)\n  print(paste(\"Mean pulse of people with BMI in\", x, \":\", meanPulse))\n}\n\n[1] \"Mean pulse of people with BMI in 12.0_18.5 : 79.4790528233151\"\n[1] \"Mean pulse of people with BMI in 18.5_to_24.9 : 73.5532544378698\"\n[1] \"Mean pulse of people with BMI in 25.0_to_29.9 : 71.4819749216301\"\n[1] \"Mean pulse of people with BMI in 30.0_plus : 74.3102930127723\"\n\n\nParfois on préfère travailler avec les indexations  Exemple : On crée un vecteur Overweight qui indique si la personne est un sur-poids ou en obésité avec des booléen TRUE FALSE.  Au départ on ne sait pas quelles valeurs va prendre le vecteur, on initialise un vecteur de taille le nombre d’individus dans NHANES avec que des NA, puis pour chaque individu, on regarde sa catégorie de BMI et on met à jour l’entrée correspondant à l’individu dans le vecteur Overweight\n\nOverweight &lt;- rep(NA, nrow(NHANES))\nfor (i in 1:nrow(NHANES)){\n  if(is.na(NHANES$BMI_WHO[i])) {}\n  else if(NHANES$BMI_WHO[i] %in% c(\"25.0_to_29.9\", \"30.0_plus\")) {\n    Overweight[i] &lt;- TRUE\n  }\n  else{\n    Overweight[i] &lt;- FALSE\n  }\n}\nprint(Overweight[1:100])\n\n  [1]  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE\n [13]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE  TRUE\n [25]  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE\n [37]  TRUE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE\n [49]  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE\n [61]    NA FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE\n [73]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE  TRUE\n [85]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE\n [97] FALSE FALSE FALSE FALSE\n\n\n\nNHANES &lt;- NHANES %&gt;% \n  mutate(Overweight = case_when(is.na(BMI_WHO) ~ NA,\n                                 NHANES$BMI_WHO %in% c(\"25.0_to_29.9\", \"30.0_plus\") ~ T,\n                                 T ~ F))",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Fonctions, conditions et boucles</span>"
    ]
  },
  {
    "objectID": "8.Initiation_Fonctions_Boucles.html#les-fonctions-apply",
    "href": "8.Initiation_Fonctions_Boucles.html#les-fonctions-apply",
    "title": "10  Fonctions, conditions et boucles",
    "section": "10.4 Les fonctions apply",
    "text": "10.4 Les fonctions apply\nEn R, il est souvent recommendé d’utilisé les fonctions apply plutôt que de faire des boucles for. Ces fonctions sont plus optimales et permettent donc de réduire le temps de calcul.  Il existe 5 fonctions apply : apply(), lapply(), sapply(), mapply() et tapply()  Ces fonctions diffère dans le type d’objet qu’elles prennent en argument, et qu’elles retournent, mais leur principe est le même. Elles prennent en argument un objet sur lequel itérer et une fonction qui est la fonction à effectuer sur chaque élément de l’objet.   - lapply() : s’utilise pour une list ou un vecteur et retourne une list - sapply() : s’utilise pour pour une list ou un vecteur et retourne un vecteur - apply() : s’utilse pour une matrice ou un dataset, et retourne un vecteur - mapply() : prend en premier argument une fonction, puis autant de vecteurs que nécessaire - tapply() :\n\n10.4.1 lapply() et sapply()\nCes fonctions s’utilsent lorsque l’on veut appliquer une fonction à chaque élément d’une list ou d’un vecteur \\[\\textit{sapply}\\text{(vecteur, nom de la fonction, éventuellement autres arguments de la fonction)}\\] La fonction peut soit être une fonction définie en R ou une fonction que l’on a préalablement définie.   Si la fonction prend d’autres argument qu’un élément de vecteur, on les précise après la virgule du nom de la fonction, dans un vecteur s’il y en a plusieurs   Exemple : on refait le calcul du vecteur Overweight obtenu dans l’exemple de la boucle for, qui indique si une personne est en surpoids ou obésité ou non\n\nfct_overweight &lt;- function(x){\n  if (is.na(x)) NA\n  else if (x %in% c(\"25.0_to_29.9\", \"30.0_plus\")) {\n    TRUE\n  }\n  else{\n    FALSE\n  }\n}\n#sapply on otient un vecteur\nOverweight_apply &lt;- sapply(NHANES$BMI_WHO, fct_overweight)\nprint(Overweight_apply[1:100])\n\n  [1]  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE\n [13]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE  TRUE\n [25]  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE\n [37]  TRUE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE\n [49]  TRUE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE\n [61]    NA FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE\n [73]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE  TRUE  TRUE\n [85]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE FALSE\n [97] FALSE FALSE FALSE FALSE\n\nidentical(Overweight, Overweight_apply) # Vérification que c'est le même vecteur que celui avec la boucle for\n\n[1] TRUE\n\n#lapply on obtient une list\nOverweight_lapply &lt;- lapply(NHANES$BMI_WHO, fct_overweight)\nprint(Overweight_lapply[1:10])\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\n[[3]]\n[1] TRUE\n\n[[4]]\n[1] FALSE\n\n[[5]]\n[1] TRUE\n\n[[6]]\n[1] FALSE\n\n[[7]]\n[1] FALSE\n\n[[8]]\n[1] TRUE\n\n[[9]]\n[1] TRUE\n\n[[10]]\n[1] TRUE\n\n\nExemple en ajoutant un argument fixe à une fonction : on veut calculer l’IMC moyen du dataset en ignorant les données manquantes. On doit donc rajouter l’argument na.rm=T de la fonction mean()\n\nmeanBMI &lt;- lapply(NHANES$BMI, mean, na.rm=T)\nprint(meanBMI[1:10])\n\n[[1]]\n[1] 32.22\n\n[[2]]\n[1] 32.22\n\n[[3]]\n[1] 32.22\n\n[[4]]\n[1] 15.3\n\n[[5]]\n[1] 30.57\n\n[[6]]\n[1] 16.82\n\n[[7]]\n[1] 20.64\n\n[[8]]\n[1] 27.24\n\n[[9]]\n[1] 27.24\n\n[[10]]\n[1] 27.24\n\n\n\n\n10.4.2 apply()\nLa fonction apply() prend au moins 3 arguments : un dataset ou une matrice, puis MARGIN = 1 ou 2 et enfin la fonction à itérer.  L’argument MARGIN permet de spécifier si on veut appliquer la fonction à chaque ligne (MARGIN = 1) ou à chaque colonne (MARGIN = 2)   Pour l’exemple, nous allons travailler sur le sous-ensemble de données qui contient les variables sur la pression artérielle.\n\ndata &lt;- NHANES %&gt;% select(starts_with(\"BP\"))\nhead(data)\n\n# A tibble: 6 × 8\n  BPSysAve BPDiaAve BPSys1 BPDia1 BPSys2 BPDia2 BPSys3 BPDia3\n     &lt;int&gt;    &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;\n1      113       85    114     88    114     88    112     82\n2      113       85    114     88    114     88    112     82\n3      113       85    114     88    114     88    112     82\n4       NA       NA     NA     NA     NA     NA     NA     NA\n5      112       75    118     82    108     74    116     76\n6       86       47     84     50     84     50     88     44\n\n\nPour chaque individu, calcul de la moyenne des mesures de pression artérielle\n\nmean_rows &lt;- apply(data, MARGIN = 1, mean, na.rm=T)\nprint(mean_rows[1:100])\n\n  [1]  99.5000  99.5000  99.5000      NaN  95.1250  66.6250  74.0000  89.2500\n  [9]  89.2500  89.2500  88.7500  89.7500 109.8750  85.5000 105.0000 104.2500\n [17]  76.2500 101.6667 126.0000 100.0000  82.5000  82.5000 104.6250  66.8750\n [25]  66.8750 116.0000  72.3750  98.8750 115.7500 115.7500  99.3750  92.6250\n [33]  74.2500  74.2500 107.7500  85.0000  85.0000  81.0000  90.8750  90.8750\n [41] 103.8750 103.8750 103.8750 103.8750  80.2500  81.2500  86.5000  94.7500\n [49]  95.8750  91.3750  91.3750  75.5000  75.5000 114.6250  70.0000  96.5000\n [57]      NaN 114.7500 114.7500 114.7500      NaN  73.0000  93.8750  92.2500\n [65]  92.2500  98.1250  98.1250  98.1250  58.6250      NaN      NaN  97.6250\n [73]  97.6250  84.7500      NaN  83.6250  83.6250  83.6250  96.8750  99.7500\n [81]  99.7500  99.7500  89.2500  89.2500  89.2500  89.2500  81.2500  81.2500\n [89]  87.8750 129.2500 129.2500  97.1250 102.2500  91.6250 113.6250  98.2500\n [97]  86.1250      NaN  80.0000  88.6250\n\n\nPour chaque mesure de pression artérielle, calcul de la moyenne de tous les individus\n\nmean_cols &lt;- apply(data, MARGIN = 2, mean, na.rm=T)\nprint(mean_cols)\n\n BPSysAve  BPDiaAve    BPSys1    BPDia1    BPSys2    BPDia2    BPSys3    BPDia3 \n118.15495  67.48006 119.09020  68.27826 118.47576  67.66455 117.92923  67.29874 \n\n\n\n\n10.4.3 mapply()\nLa fonction mapply() permet d’appliquer une fonction qui prend plusieurs vecteurs en arguments à des vecteurs que l’on spécifie.   La fonction mapply() fonctionne dans l’ordre inverse : son premier argument est la fonction à itérer, puis on peut mettre autant de vecteurs que d’arguments de la fonction. Le premier vecteur est considéré comme étant le premier argument de la fonction, le deuxième vecteur le deuxième argument, etc…\n\na &lt;- c(80, 65, 89, 23, 21)\nb &lt;- c(10, 30, 8, 75, 70)\nc &lt;- c(10,5, 3, 2, 9)\nmapply(sum, a, b, c)\n\n[1] 100 100 100 100 100\n\n\nAutre exemple de mapply : calculer l’IMC à partir des données du poids et de la taille\n\nimc &lt;- mapply(function(x,y) round(x/(y/100)^2, 2), NHANES$Weight, NHANES$Height) # round permet d'arrondir le résultat\nprint(imc[1:100])\n\n  [1] 32.22 32.22 32.22 15.30 30.57 16.82 20.64 27.24 27.24 27.24 23.67 23.69\n [13] 26.03 19.20 26.22 26.60 27.40 28.54 25.84 24.74 19.73 19.73 20.66 36.32\n [25] 36.32 35.84 24.32 25.95 31.43 31.43 27.18 21.00 25.79 25.79 29.13 30.60\n [37] 30.60 23.34 22.85 22.85 26.46 26.46 26.46 26.46 25.45 21.16 46.69 20.15\n [49] 27.06 37.33 37.33 15.59 15.59 25.54 24.98 22.63 14.35 37.92 37.92 37.92\n [61]    NA 18.16 25.52 28.96 28.96 32.49 32.49 32.49 18.35 16.24 16.24 28.48\n [73] 28.48 19.41 36.28 25.87 25.87 25.87 28.60 21.03 21.03 21.03 30.90 30.90\n [85] 30.90 30.90 31.51 31.51 27.74 27.25 27.25 24.53 29.83 22.81 29.27 17.87\n [97] 20.39 15.18 17.24 18.62\n\nprint(NHANES$BMI[1:100])\n\n  [1] 32.22 32.22 32.22 15.30 30.57 16.82 20.64 27.24 27.24 27.24 23.67 23.69\n [13] 26.03 19.20 26.22 26.60 27.40 28.54 25.84 24.74 19.73 19.73 20.66 36.32\n [25] 36.32 35.84 24.32 25.95 31.43 31.43 27.18 21.00 25.79 25.79 29.13 30.60\n [37] 30.60 23.34 22.85 22.85 26.46 26.46 26.46 26.46 25.45 21.16 46.69 20.15\n [49] 27.06 37.33 37.33 15.59 15.59 25.54 24.98 22.63 14.35 37.92 37.92 37.92\n [61]    NA 18.16 25.52 28.96 28.96 32.49 32.49 32.49 18.35 16.24 16.24 28.48\n [73] 28.48 19.41 36.28 25.87 25.87 25.87 28.60 21.03 21.03 21.03 30.90 30.90\n [85] 30.90 30.90 31.51 31.51 27.74 27.25 27.25 24.53 29.83 22.81 29.27 17.87\n [97] 20.39 15.18 17.24 18.62\n\nimc[1:100]==NHANES$BMI[1:100]\n\n  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [61]   NA TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [76] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [91] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\n\n\n\n10.4.4 tapply()\nLa fonction tapply() permet d’appliquer une fonction sur un vecteur par groupes définis par les catégories d’un autre vecteur. Le premier argument est le vecteur de données sur lequel appliquer la fonction. Le deuxième argument est le vecteur qui définit à quel groupe appartient chaque élément du vecteur passé en premier argument. Le troisième argument est la fonction à appliquer. Le deuxième vecteur est donc un vecteur de class facteur \\[ tapply(\\text{vecteur, vecteur de class facteur, fonction})\\]   Par exemple, on peut vouloir calculer le rythme cardiaque moyen dans chaque catégorie d’IMC\n\ntapply(NHANES$Pulse, NHANES$BMI_WHO, mean, na.rm=T)\n\n   12.0_18.5 18.5_to_24.9 25.0_to_29.9    30.0_plus \n    79.47905     73.55325     71.48197     74.31029 \n\n\nAutre exemple : déterminer la proportion de personnes ayant du diabètes en fonction du niveau de santé général perçu\n\ntapply(NHANES$Diabetes==\"Yes\", NHANES$HealthGen, mean, na.rm=T)\n\n Excellent      Vgood       Good       Fair       Poor \n0.03530752 0.04434678 0.10013532 0.19801980 0.39037433 \n\n\nRemarque : pour calculer la proportion, on utilise NHANES$Diabetes==“Yes” qui crée un vecteur TRUE FALSE en fonction de si la réponse est “Yes”, puis on calule la moyenne de TRUE",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Fonctions, conditions et boucles</span>"
    ]
  },
  {
    "objectID": "8.Initiation_Fonctions_Boucles.html#exercices",
    "href": "8.Initiation_Fonctions_Boucles.html#exercices",
    "title": "10  Fonctions, conditions et boucles",
    "section": "10.5 Exercices",
    "text": "10.5 Exercices\nExercice 1 : Obtenir un barplot pour chaque variable catégorielle de NHANES  Indication : a) créer une fonction pour obtenir le barplot  b) Créer un vecteur des noms de colonnes de classe facteur dans NHANES (avec une fonction apply)  c) Utiliser une fonction apply pour obtenir un graphique pour chaque variable\n  Exercice 2 : Obtenir pour chaque variable catégorielle de NHANES, le tableau du nombre d’individus dans chaque catégorie, y compris les NA  \nExercice 3 : Obtenir un barplot qui indique la santé perçu pour chacun des niveau de revenu en utilisant la fonction tapply()\n Exercice 4 : Obtenir le niveau moyen de cholesterol total par niveau d’éducation",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Fonctions, conditions et boucles</span>"
    ]
  }
]